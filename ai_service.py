# ai_service.py (ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™” ë²„ì „ + Gemini ê±°ë˜ ì„ íƒ ë¶„ì„ + ì„±ê³µë…¸íŠ¸ ë¶„ì„)
"""
Re:Mind 3.1 - Gemini AI ê¸°ë°˜ íˆ¬ì ì‹¬ë¦¬ ë¶„ì„ ì„œë¹„ìŠ¤ (ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™” + ëª¨ë“  ê±°ë˜ ë³µê¸° ì§€ì› + ì„±ê³µ ê²½í—˜ í•™ìŠµ)
"""

import json
import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime
import re
from typing import List, Dict, Any, Optional
import pickle
import hashlib

# Gemini API ì„í¬íŠ¸
try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False
    if 'gemini_import_error_shown' not in st.session_state:
        st.error("ğŸš¨ google-generativeai íŒ¨í‚¤ì§€ê°€ í•„ìš”í•©ë‹ˆë‹¤. 'pip install google-generativeai'ë¡œ ì„¤ì¹˜í•´ì£¼ì„¸ìš”.")
        st.session_state.gemini_import_error_shown = True

# ì„ íƒì  ì„í¬íŠ¸
try:
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.metrics.pairwise import cosine_similarity
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False

__all__ = [
    "check_gemini_api",
    "setup_gemini_api", 
    "test_gemini_connection",
    "create_embedding",
    "create_embeddings_batch",
    "preprocess_embeddings_cache",
    "find_similar_experiences_ai",
    "generate_personalized_coaching",
    "analyze_trading_pattern_with_ai",
    "find_similar_trades",
    "analyze_trade_with_ai",
    "ReMinDKoreanEngine",
    "generate_ai_coaching_tip",
    "generate_investment_charter",
    "analyze_trading_psychology",
    # ìƒˆë¡œ ì¶”ê°€ëœ í•¨ìˆ˜ë“¤
    "gemini_select_and_analyze_trades",
    "analyze_trade_reflection",
    "get_ai_success_principle",  # ìƒˆë¡œ ì¶”ê°€
    # í•˜ìœ„ í˜¸í™˜ì„±
    "check_api_key",
    "call_openai_api"
]

# Gemini API ì„¤ì • ë° ê´€ë¦¬
def check_gemini_api():
    """Gemini API í‚¤ í™•ì¸"""
    return GEMINI_AVAILABLE and hasattr(st.session_state, 'gemini_api_key') and bool(st.session_state.gemini_api_key)

def setup_gemini_api():
    """Gemini API ì„¤ì •"""
    if not GEMINI_AVAILABLE:
        return False
    
    if hasattr(st.session_state, 'gemini_api_key') and st.session_state.gemini_api_key:
        try:
            genai.configure(api_key=st.session_state.gemini_api_key)
            return True
        except Exception as e:
            st.error(f"Gemini API ì„¤ì • ì˜¤ë¥˜: {str(e)}")
            return False
    return False

def test_gemini_connection():
    """Gemini ì—°ê²° í…ŒìŠ¤íŠ¸"""
    if not check_gemini_api() or not setup_gemini_api():
        return False
    
    try:
        model = genai.GenerativeModel('gemini-1.5-flash')
        response = model.generate_content("ì•ˆë…•í•˜ì„¸ìš”. ì—°ê²° í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤.")
        return bool(response.text)
    except Exception as e:
        st.error(f"Gemini ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
        return False

# ==================== ìƒˆë¡œ ì¶”ê°€ëœ í•¨ìˆ˜ë“¤ ====================

def get_ai_success_principle(trade_data: dict, success_note: str, user_type: str) -> dict:
    """ì„±ê³µ ê±°ë˜ì—ì„œ ì¬ì‚¬ìš© ê°€ëŠ¥í•œ ì„±ê³µ ì›ì¹™ì„ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜"""
    if not check_gemini_api() or not setup_gemini_api():
        return {
            'success': False,
            'message': 'Gemini APIê°€ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'
        }
    
    try:
        # ê±°ë˜ ì •ë³´ êµ¬ì„±
        trade_info = f"""
        ì„±ê³µ ê±°ë˜ ì •ë³´:
        - ì¢…ëª©: {trade_data.get('ì¢…ëª©ëª…', '')}
        - ê±°ë˜êµ¬ë¶„: {trade_data.get('ê±°ë˜êµ¬ë¶„', '')}
        - ìˆ˜ëŸ‰: {trade_data.get('ìˆ˜ëŸ‰', 0):,}ì£¼
        - ê°€ê²©: {trade_data.get('ê°€ê²©', 0):,}ì›
        - ê±°ë˜ì¼ì‹œ: {trade_data.get('ê±°ë˜ì¼ì‹œ', '')}
        - ìˆ˜ìµë¥ : +{trade_data.get('ìˆ˜ìµë¥ ', 0):.1f}%
        """
        
        # ì‚¬ìš©ì ìœ í˜•ë³„ ë¶„ì„ í¬ì»¤ìŠ¤
        if user_type == "ê¹€êµ­ë¯¼":
            focus = "ë³´ìˆ˜ì  íˆ¬ììì˜ ì„±ê³µ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ ì‹ ì¤‘í•˜ê³  ì•ˆì •ì ì¸ íˆ¬ì ì›ì¹™ì„"
        else:  # ë°•íˆ¬ì
            focus = "ì ê·¹ì  íˆ¬ììì˜ ì„±ê³µ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ ê¸°íšŒ í¬ì°©ê³¼ ë¦¬ìŠ¤í¬ ê´€ë¦¬ë¥¼ ê· í˜• ì¡ì€ íˆ¬ì ì›ì¹™ì„"
        
        prompt = f"""
        ë‹¹ì‹ ì€ ì „ë¬¸ íˆ¬ì ë¶„ì„ê°€ì…ë‹ˆë‹¤. {user_type} íˆ¬ììì˜ ì„±ê³µí•œ ê±°ë˜ ê²½í—˜ì„ ë¶„ì„í•˜ì—¬ ì¬ì‚¬ìš© ê°€ëŠ¥í•œ íˆ¬ì ì›ì¹™ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”.

        {trade_info}

        ì‚¬ìš©ìì˜ ì„±ê³µë…¸íŠ¸:
        "{success_note}"

        {focus} ë‹¤ìŒ í˜•ì‹ì˜ JSONìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:

        {{
            "principle": "ì´ ì„±ê³µ ê²½í—˜ì—ì„œ ì–»ì„ ìˆ˜ ìˆëŠ”, ë‹¤ë¥¸ íˆ¬ìì—ë„ ì ìš© ê°€ëŠ¥í•œ ì¼ë°˜í™”ëœ ì„±ê³µ ì›ì¹™ í•œ ë¬¸ì¥",
            "analysis": {{
                "success_factor": "ì´ ê±°ë˜ê°€ ì„±ê³µí•œ í•µì‹¬ ìš”ì¸",
                "accuracy": 0.0~1.0 ì‚¬ì´ì˜ íŒë‹¨ ì •í™•ë„,
                "reproducibility": "ì´ ì„±ê³µ íŒ¨í„´ì˜ ì¬í˜„ ê°€ëŠ¥ì„± (ë†’ìŒ/ë³´í†µ/ë‚®ìŒ)",
                "insights": {{
                    "strengths": ["ì´ ì„±ê³µ ê²½í—˜ì—ì„œ ì˜í•œ ì ë“¤"],
                    "lessons": ["ë‹¤ë¥¸ íˆ¬ìì— ì ìš©í•  ìˆ˜ ìˆëŠ” êµí›ˆë“¤"]
                }},
                "coaching_advice": "ì´ ì„±ê³µ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ í•œ í–¥í›„ íˆ¬ì ì¡°ì–¸ (3-4ë¬¸ì¥)"
            }}
        }}

        ì›ì¹™ ì¶”ì¶œ ì‹œ ë‹¤ìŒ ì‚¬í•­ì„ ê³ ë ¤í•´ì£¼ì„¸ìš”:
        1. êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ì›ì¹™
        2. ë‹¤ë¥¸ ì¢…ëª©/ìƒí™©ì—ë„ ì ìš© ê°€ëŠ¥í•œ ì¼ë°˜ì„±
        3. ê°ê´€ì ì´ê³  ì¸¡ì • ê°€ëŠ¥í•œ ê¸°ì¤€
        4. ê°œì¸ì˜ íˆ¬ì ì„±í–¥ ë°˜ì˜

        JSON í˜•ì‹ì„ ì •í™•íˆ ì§€ì¼œì„œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
        """
        
        model = genai.GenerativeModel('gemini-1.5-flash')
        response = model.generate_content(prompt)
        
        # JSON íŒŒì‹± ì‹œë„
        try:
            response_text = response.text.strip()
            if response_text.startswith('```json'):
                response_text = response_text[7:]
            if response_text.endswith('```'):
                response_text = response_text[:-3]
            
            analysis_result = json.loads(response_text)
            
            return {
                'success': True,
                'principle': analysis_result.get('principle', ''),
                'analysis': analysis_result.get('analysis', {}),
                'raw_response': response.text
            }
            
        except json.JSONDecodeError:
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë¶„ì„ ì œê³µ
            return {
                'success': True,
                'principle': 'ë°ì´í„° ê¸°ë°˜ì˜ ì‹ ì¤‘í•œ ë¶„ì„ì„ í†µí•´ íˆ¬ì ê²°ì •ì„ ë‚´ë¦°ë‹¤',
                'analysis': {
                    'success_factor': 'ì²´ê³„ì  ë¶„ì„',
                    'accuracy': 0.7,
                    'reproducibility': 'ë³´í†µ',
                    'insights': {
                        'strengths': ['ì„±ê³µ ê²½í—˜ ë³µê¸°'],
                        'lessons': ['ì§€ì†ì ì¸ í•™ìŠµì˜ ì¤‘ìš”ì„±']
                    },
                    'coaching_advice': 'ì„±ê³µ ê²½í—˜ì„ ì²´ê³„ì ìœ¼ë¡œ ë¶„ì„í•˜ì—¬ ì¬í˜„ ê°€ëŠ¥í•œ íˆ¬ì ì›ì¹™ì„ ë§Œë“¤ì–´ë‚˜ê°€ì„¸ìš”.'
                },
                'raw_response': response.text
            }
            
    except Exception as e:
        return {
            'success': False,
            'message': f'ì„±ê³µ ì›ì¹™ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
        }

def gemini_select_and_analyze_trades(current_trade: dict, user_data: pd.DataFrame, user_type: str) -> dict:
    """Gemini AIê°€ ì§ì ‘ ìœ ì‚¬ ê±°ë˜ë¥¼ ì„ íƒí•˜ê³  ë¶„ì„í•˜ëŠ” í•¨ìˆ˜"""
    if not check_gemini_api() or not setup_gemini_api():
        return {
            'method': 'error',
            'analysis': 'Gemini APIê°€ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'
        }
    
    if user_data.empty:
        return {
            'method': 'error',
            'analysis': 'ë¶„ì„í•  ê³¼ê±° ê±°ë˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.'
        }
    
    try:
        # í˜„ì¬ ê±°ë˜ ì •ë³´ êµ¬ì„±
        current_trade_text = f"""
        í˜„ì¬ ê³„íš ì¤‘ì¸ ê±°ë˜:
        - ì¢…ëª©: {current_trade.get('stock_name', '')}
        - ê±°ë˜ìœ í˜•: {current_trade.get('trade_type', '')}
        - ìˆ˜ëŸ‰: {current_trade.get('quantity', 0):,}ì£¼
        - ê°€ê²©: {current_trade.get('price', 0):,}ì›
        - ì´ì•¡: {current_trade.get('quantity', 0) * current_trade.get('price', 0):,}ì›
        """
        
        # ê³¼ê±° ê±°ë˜ ë°ì´í„°ë¥¼ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜ (ìµœê·¼ 20ê°œë§Œ)
        recent_trades = user_data.head(20) if len(user_data) > 20 else user_data
        trades_text = ""
        
        for idx, trade in recent_trades.iterrows():
            trade_date = trade.get('ê±°ë˜ì¼ì‹œ', '')
            if hasattr(trade_date, 'strftime'):
                trade_date = trade_date.strftime('%Y-%m-%d')
            
            trades_text += f"""
            ê±°ë˜ #{idx}:
            - ë‚ ì§œ: {trade_date}
            - ì¢…ëª©: {trade.get('ì¢…ëª©ëª…', '')}
            - ê±°ë˜êµ¬ë¶„: {trade.get('ê±°ë˜êµ¬ë¶„', '')}
            - ìˆ˜ëŸ‰: {trade.get('ìˆ˜ëŸ‰', 0):,}ì£¼
            - ê°€ê²©: {trade.get('ê°€ê²©', 0):,}ì›
            - ìˆ˜ìµë¥ : {trade.get('ìˆ˜ìµë¥ ', 0):.1f}%
            - ê°ì •íƒœê·¸: {trade.get('ê°ì •íƒœê·¸', '')}
            - ë©”ëª¨: "{trade.get('ë©”ëª¨', '')}"
            - ê¸°ìˆ ë¶„ì„: {trade.get('ê¸°ìˆ ë¶„ì„', '')}
            - ë‰´ìŠ¤ë¶„ì„: {trade.get('ë‰´ìŠ¤ë¶„ì„', '')}
            - ê°ì •ë¶„ì„: {trade.get('ê°ì •ë¶„ì„', '')}
            """
        
        # Geminiì—ê²Œ ìœ ì‚¬ ê±°ë˜ ì„ íƒ ë° ë¶„ì„ ìš”ì²­
        prompt = f"""
        ë‹¹ì‹ ì€ ì „ë¬¸ íˆ¬ì ë¶„ì„ê°€ì…ë‹ˆë‹¤. {user_type} íˆ¬ììì˜ í˜„ì¬ ê±°ë˜ ê³„íšì„ ë¶„ì„í•˜ê³ , ê³¼ê±° ê±°ë˜ ì¤‘ì—ì„œ ê°€ì¥ ìœ ì‚¬í•œ 3ê°œë¥¼ ì„ íƒí•´ì„œ ìœ„í—˜ë„ë¥¼ í‰ê°€í•´ì£¼ì„¸ìš”.

        {current_trade_text}

        ê³¼ê±° ê±°ë˜ ë‚´ì—­:
        {trades_text}

        ë‹¤ìŒ í˜•ì‹ì˜ JSONìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”:
        {{
            "selected_trades": [
                {{
                    "ê±°ë˜ì¼ì‹œ": "ë‚ ì§œ",
                    "ì¢…ëª©ëª…": "ì¢…ëª©ëª…",
                    "ê±°ë˜êµ¬ë¶„": "ë§¤ìˆ˜/ë§¤ë„",
                    "ìˆ˜ëŸ‰": ìˆ˜ëŸ‰,
                    "ê°€ê²©": ê°€ê²©,
                    "ìˆ˜ìµë¥ ": ìˆ˜ìµë¥ ,
                    "ê°ì •íƒœê·¸": "ê°ì •íƒœê·¸",
                    "ë©”ëª¨": "ë©”ëª¨ë‚´ìš©",
                    "similarity_reason": "ì´ ê±°ë˜ë¥¼ ì„ íƒí•œ ì´ìœ  (í•œ ë¬¸ì¥)",
                    "gemini_summary": "ì´ ê±°ë˜ì˜ í•µì‹¬ êµí›ˆ (í•œ ë¬¸ì¥)"
                }},
                // 3ê°œ ê±°ë˜ ì„ íƒ
            ],
            "pattern_analysis": "ì„ íƒëœ 3ê°œ ê±°ë˜ì˜ ê³µí†µ íŒ¨í„´ ë¶„ì„ (2-3ë¬¸ì¥)",
            "risk_assessment": "í˜„ì¬ ê±°ë˜ì˜ ìœ„í—˜ë„ í‰ê°€ (ë†’ìŒ/ë³´í†µ/ë‚®ìŒ)ì™€ ê·¸ ì´ìœ ",
            "recommendation": "êµ¬ì²´ì ì¸ ê¶Œê³ ì‚¬í•­ (3-4ë¬¸ì¥)",
            "alternative_strategy": "ëŒ€ì•ˆ ì „ëµ ì œì•ˆ (2-3ë¬¸ì¥)"
        }}

        ì„ íƒ ê¸°ì¤€:
        1. ë™ì¼ ì¢…ëª© ìš°ì„ 
        2. ë™ì¼ ê±°ë˜ìœ í˜• (ë§¤ìˆ˜/ë§¤ë„) ê³ ë ¤
        3. ìœ ì‚¬í•œ ê°ì • ìƒíƒœ
        4. ìœ ì‚¬í•œ ì‹œì¥ ìƒí™©
        5. êµí›ˆì´ ë  ë§Œí•œ ê²°ê³¼ (íŠ¹íˆ ì†ì‹¤ ê²½í—˜)

        JSON í˜•ì‹ì„ ì •í™•íˆ ì§€ì¼œì„œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
        """
        
        model = genai.GenerativeModel('gemini-1.5-flash')
        response = model.generate_content(prompt)
        
        # JSON íŒŒì‹± ì‹œë„
        try:
            # JSON ì‘ë‹µì—ì„œ ì‹¤ì œ JSON ë¶€ë¶„ ì¶”ì¶œ
            response_text = response.text.strip()
            if response_text.startswith('```json'):
                response_text = response_text[7:]
            if response_text.endswith('```'):
                response_text = response_text[:-3]
            
            analysis_result = json.loads(response_text)
            analysis_result['method'] = 'gemini_selection'
            return analysis_result
            
        except json.JSONDecodeError:
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ í…ìŠ¤íŠ¸ ì‘ë‹µ ë°˜í™˜
            return {
                'method': 'gemini_text',
                'analysis': response.text
            }
            
    except Exception as e:
        return {
            'method': 'error',
            'analysis': f'Gemini ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
        }

def analyze_trade_reflection(trade_data: dict, reflection_text: str, user_type: str) -> dict:
    """ê±°ë˜ ë³µê¸° ë¶„ì„ (ë§¤ìˆ˜/ë§¤ë„ ëª¨ë‘ ì§€ì›)"""
    if not check_gemini_api() or not setup_gemini_api():
        return {
            'success': False,
            'message': 'Gemini APIê°€ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'
        }
    
    try:
        # ê±°ë˜ ìœ í˜• í™•ì¸
        trade_type = trade_data.get('ê±°ë˜êµ¬ë¶„', '')
        is_buy = trade_type == 'ë§¤ìˆ˜'
        is_sell = trade_type == 'ë§¤ë„'
        
        # ê±°ë˜ ì •ë³´ êµ¬ì„±
        trade_info = f"""
        ê±°ë˜ ì •ë³´:
        - ì¢…ëª©: {trade_data.get('ì¢…ëª©ëª…', '')}
        - ê±°ë˜êµ¬ë¶„: {trade_type}
        - ìˆ˜ëŸ‰: {trade_data.get('ìˆ˜ëŸ‰', 0):,}ì£¼
        - ê°€ê²©: {trade_data.get('ê°€ê²©', 0):,}ì›
        - ê±°ë˜ì¼ì‹œ: {trade_data.get('ê±°ë˜ì¼ì‹œ', '')}
        """
        
        if 'ìˆ˜ìµë¥ ' in trade_data:
            profit_loss = trade_data['ìˆ˜ìµë¥ ']
            if profit_loss > 0:
                trade_info += f"\n- ìˆ˜ìµë¥ : +{profit_loss:.1f}%"
            elif profit_loss < 0:
                trade_info += f"\n- ì†ì‹¤ë¥ : {profit_loss:.1f}%"
            else:
                trade_info += f"\n- ìˆ˜ìµë¥ : 0%"
        
        # ì‚¬ìš©ì ìœ í˜•ë³„ ë¶„ì„ í¬ì»¤ìŠ¤
        if user_type == "ê¹€êµ­ë¯¼":
            focus = "ê³µí¬ë§¤ë„ íŒ¨í„´ê³¼ ë³´ìˆ˜ì  íˆ¬ì ê´€ì ì—ì„œ"
        else:  # ë°•íˆ¬ì
            focus = "FOMO ë§¤ìˆ˜ íŒ¨í„´ê³¼ ì ê·¹ì  íˆ¬ì ê´€ì ì—ì„œ"
        
        prompt = f"""
        ë‹¹ì‹ ì€ ì „ë¬¸ íˆ¬ì ì‹¬ë¦¬ ë¶„ì„ê°€ì…ë‹ˆë‹¤. {user_type} íˆ¬ììì˜ ê±°ë˜ ë³µê¸°ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.

        {trade_info}

        ì‚¬ìš©ìì˜ ë³µê¸° ë‚´ìš©:
        "{reflection_text}"

        {focus} ë‹¤ìŒ í˜•ì‹ì˜ JSONìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:

        {{
            "emotion_analysis": {{
                "primary_emotion": "ì£¼ìš” ê°ì • (ê³µí¬/ìš•ì‹¬/ë¶ˆì•ˆ/í™•ì‹ /í•©ë¦¬ì  ì¤‘ í•˜ë‚˜)",
                "emotion_intensity": 1~10ì  ì‚¬ì´,
                "emotion_keywords": ["ê°ì§€ëœ", "ê°ì •", "í‚¤ì›Œë“œë“¤"]
            }},
            "pattern_recognition": {{
                "trading_pattern": "ê±°ë˜ íŒ¨í„´ ë¶„ë¥˜ (ê³µí¬ë§¤ë„/ì¶”ê²©ë§¤ìˆ˜/ë³µìˆ˜ë§¤ë§¤/ê³¼ì‹ ë§¤ë§¤/í•©ë¦¬ì íˆ¬ì)",
                "confidence": 0.0~1.0 ì‚¬ì´ ê°’,
                "pattern_description": "íŒ¨í„´ì— ëŒ€í•œ ì„¤ëª…"
            }},
            "insights": {{
                "strengths": ["ì´ ê±°ë˜ì—ì„œ ì˜í•œ ì ë“¤"],
                "weaknesses": ["ê°œì„ ì´ í•„ìš”í•œ ì ë“¤"],
                "lessons": ["í•µì‹¬ êµí›ˆë“¤"]
            }},
            "ai_hashtags": ["#ê´€ë ¨", "#í•´ì‹œíƒœê·¸ë“¤"],
            "coaching_advice": "ê°œì¸í™”ëœ ì¡°ì–¸ (3-4ë¬¸ì¥)"
        }}

        ë¶„ì„ì€ {'ë§¤ìˆ˜ ê²°ì •' if is_buy else 'ë§¤ë„ ê²°ì •'}ì˜ ì‹¬ë¦¬ì  ë°°ê²½ì— ì§‘ì¤‘í•´ì£¼ì„¸ìš”.
        JSON í˜•ì‹ì„ ì •í™•íˆ ì§€ì¼œì„œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
        """
        
        model = genai.GenerativeModel('gemini-1.5-flash')
        response = model.generate_content(prompt)
        
        # JSON íŒŒì‹± ì‹œë„
        try:
            response_text = response.text.strip()
            if response_text.startswith('```json'):
                response_text = response_text[7:]
            if response_text.endswith('```'):
                response_text = response_text[:-3]
            
            analysis_result = json.loads(response_text)
            
            return {
                'success': True,
                'analysis': analysis_result,
                'raw_response': response.text
            }
            
        except json.JSONDecodeError:
            # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë¶„ì„ ì œê³µ
            return {
                'success': True,
                'analysis': {
                    'emotion_analysis': {
                        'primary_emotion': 'ì¤‘ë¦½',
                        'emotion_intensity': 5,
                        'emotion_keywords': []
                    },
                    'pattern_recognition': {
                        'trading_pattern': 'í•©ë¦¬ì íˆ¬ì',
                        'confidence': 0.5,
                        'pattern_description': 'ë¶„ì„ì´ ì–´ë ¤ìš´ ê±°ë˜ì…ë‹ˆë‹¤.'
                    },
                    'insights': {
                        'strengths': ['ë³µê¸°ë¥¼ í†µí•œ ìê¸°ë°˜ì„±'],
                        'weaknesses': ['ë” êµ¬ì²´ì ì¸ ë¶„ì„ í•„ìš”'],
                        'lessons': ['ì§€ì†ì ì¸ ë³µê¸°ì˜ ì¤‘ìš”ì„±']
                    },
                    'ai_hashtags': ['#ë³µê¸°', '#ì„±ì¥'],
                    'coaching_advice': 'ê³„ì†í•´ì„œ ê±°ë˜ë¥¼ ë³µê¸°í•˜ê³  íŒ¨í„´ì„ ë¶„ì„í•´ë³´ì„¸ìš”.'
                },
                'raw_response': response.text
            }
            
    except Exception as e:
        return {
            'success': False,
            'message': f'ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'
        }

# ==================== ê¸°ì¡´ í•¨ìˆ˜ë“¤ (ê·¸ëŒ€ë¡œ ìœ ì§€) ====================

# ì„ë² ë”© ê´€ë ¨ í•¨ìˆ˜ë“¤ (ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”)
def create_embedding(text: str) -> Optional[List[float]]:
    """ë‹¨ì¼ í…ìŠ¤íŠ¸ë¥¼ Gemini ì„ë² ë”© APIë¡œ ë²¡í„°í™”"""
    if not check_gemini_api() or not setup_gemini_api():
        return None
    
    try:
        result = genai.embed_content(
            model="models/text-embedding-004",
            content=[text],  # APIëŠ” ë‹¨ì¼ í…ìŠ¤íŠ¸ë„ ë¦¬ìŠ¤íŠ¸ë¡œ ë°›ìŠµë‹ˆë‹¤
            task_type="semantic_similarity"
        )
        return result['embedding'][0] if result['embedding'] else None
    except Exception as e:
        st.error(f"ì„ë² ë”© ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return None

def create_embeddings_batch(texts: List[str], batch_size: int = 100) -> Optional[List[List[float]]]:
    """í…ìŠ¤íŠ¸ ëª©ë¡ì„ Gemini ì„ë² ë”© APIë¡œ ë°°ì¹˜ ì²˜ë¦¬"""
    if not texts or not check_gemini_api() or not setup_gemini_api():
        return None
    
    all_embeddings = []
    
    # í° ë°°ì¹˜ë¥¼ ì‘ì€ ì²­í¬ë¡œ ë‚˜ëˆ„ì–´ ì²˜ë¦¬
    for i in range(0, len(texts), batch_size):
        batch_texts = texts[i:i + batch_size]
        
        try:
            result = genai.embed_content(
                model="models/text-embedding-004",
                content=batch_texts,
                task_type="semantic_similarity"
            )
            
            if result and 'embedding' in result:
                all_embeddings.extend(result['embedding'])
                
                # í”„ë¡œê·¸ë ˆìŠ¤ í‘œì‹œ (streamlit í™˜ê²½)
                if 'embedding_progress' in st.session_state:
                    progress = min(1.0, (i + batch_size) / len(texts))
                    st.session_state.embedding_progress.progress(progress)
                    
        except Exception as e:
            st.error(f"ë°°ì¹˜ ì„ë² ë”© ìƒì„± ì˜¤ë¥˜ (ë°°ì¹˜ {i//batch_size + 1}): {str(e)}")
            # ì‹¤íŒ¨í•œ ë°°ì¹˜ëŠ” Noneìœ¼ë¡œ ì±„ì›€
            all_embeddings.extend([None] * len(batch_texts))
    
    return all_embeddings if all_embeddings else None

def generate_text_for_embedding(trade_row: pd.Series) -> str:
    """ê±°ë˜ ë°ì´í„°ì—ì„œ ì„ë² ë”©ìš© í…ìŠ¤íŠ¸ ìƒì„±"""
    parts = []
    
    # ê¸°ë³¸ ì •ë³´
    if 'ì¢…ëª©ëª…' in trade_row and pd.notna(trade_row['ì¢…ëª©ëª…']):
        parts.append(f"ì¢…ëª©: {trade_row['ì¢…ëª©ëª…']}")
    
    if 'ê±°ë˜êµ¬ë¶„' in trade_row and pd.notna(trade_row['ê±°ë˜êµ¬ë¶„']):
        parts.append(f"ê±°ë˜: {trade_row['ê±°ë˜êµ¬ë¶„']}")
    
    # ê°ì • ì •ë³´
    if 'ê°ì •íƒœê·¸' in trade_row and pd.notna(trade_row['ê°ì •íƒœê·¸']):
        parts.append(f"ê°ì •: {trade_row['ê°ì •íƒœê·¸']}")
    
    # ë©”ëª¨
    if 'ë©”ëª¨' in trade_row and pd.notna(trade_row['ë©”ëª¨']):
        memo = str(trade_row['ë©”ëª¨']).strip()
        if memo and memo != '':
            parts.append(f"ë©”ëª¨: {memo}")
    
    # ë¶„ì„ ì •ë³´
    for col in ['ê¸°ìˆ ë¶„ì„', 'ë‰´ìŠ¤ë¶„ì„', 'ê°ì •ë¶„ì„']:
        if col in trade_row and pd.notna(trade_row[col]):
            content = str(trade_row[col]).strip()
            if content and content != '':
                parts.append(f"{col}: {content}")
    
    # ìˆ˜ìµë¥  ì •ë³´
    if 'ìˆ˜ìµë¥ ' in trade_row and pd.notna(trade_row['ìˆ˜ìµë¥ ']):
        profit = float(trade_row['ìˆ˜ìµë¥ '])
        if profit > 0:
            parts.append(f"ìˆ˜ìµ: +{profit:.1f}%")
        elif profit < 0:
            parts.append(f"ì†ì‹¤: {profit:.1f}%")
    
    return " | ".join(parts) if parts else "ê±°ë˜ ì •ë³´ ì—†ìŒ"

@st.cache_data(ttl=3600, show_spinner=False)  # 1ì‹œê°„ ìºì‹œ
def preprocess_embeddings_cache(user_data: pd.DataFrame, user_id: str) -> pd.DataFrame:
    """ê±°ë˜ ë°ì´í„°ì— ëŒ€í•œ ì„ë² ë”©ì„ ë¯¸ë¦¬ ìƒì„±í•˜ê³  ìºì‹œ"""
    if user_data.empty:
        return user_data
    
    # ë°ì´í„° ë³µì‚¬ë³¸ ìƒì„±
    df = user_data.copy()
    
    # ì„ë² ë”© ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ì¶”ê°€
    if 'embedding' not in df.columns:
        df['embedding'] = None
    
    # ì„ë² ë”©ì´ í•„ìš”í•œ í–‰ ì°¾ê¸°
    needs_embedding_mask = df['embedding'].isnull() | df['embedding'].apply(lambda x: x is None or (isinstance(x, list) and len(x) == 0))
    needs_embedding = df[needs_embedding_mask]
    
    if needs_embedding.empty:
        return df
    
    # í”„ë¡œê·¸ë ˆìŠ¤ ë°” ì„¤ì •
    if check_gemini_api():
        progress_container = st.container()
        with progress_container:
            st.info(f"ğŸ’¾ {len(needs_embedding)}ê°œ ê±°ë˜ ë°ì´í„°ì˜ ì„ë² ë”©ì„ ìƒì„±í•˜ê³  ìˆìŠµë‹ˆë‹¤...")
            progress_bar = st.progress(0)
            st.session_state.embedding_progress = progress_bar
        
        # ì„ë² ë”©ìš© í…ìŠ¤íŠ¸ ì¤€ë¹„
        texts_to_embed = [generate_text_for_embedding(row) for _, row in needs_embedding.iterrows()]
        
        # ë°°ì¹˜ ì„ë² ë”© ìƒì„±
        embeddings = create_embeddings_batch(texts_to_embed)
        
        if embeddings:
            # DataFrameì— ì„ë² ë”© ì—…ë°ì´íŠ¸
            df.loc[needs_embedding.index, 'embedding'] = embeddings
            progress_container.success(f"âœ… {len(needs_embedding)}ê°œ ì„ë² ë”© ìƒì„± ì™„ë£Œ!")
        else:
            progress_container.error("âŒ ì„ë² ë”© ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤.")
        
        # í”„ë¡œê·¸ë ˆìŠ¤ ë°” ì •ë¦¬
        if 'embedding_progress' in st.session_state:
            del st.session_state.embedding_progress
    
    return df

def calculate_cosine_similarity(embedding1: List[float], embedding2: List[float]) -> float:
    """ë‘ ì„ë² ë”© ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
    try:
        vec1 = np.array(embedding1).reshape(1, -1)
        vec2 = np.array(embedding2).reshape(1, -1)
        
        dot_product = np.dot(vec1, vec2.T)[0, 0]
        norm1 = np.linalg.norm(vec1)
        norm2 = np.linalg.norm(vec2)
        
        if norm1 == 0 or norm2 == 0:
            return 0.0
        
        similarity = dot_product / (norm1 * norm2)
        return float(similarity)
    except Exception:
        return 0.0

def find_similar_experiences_ai(current_situation: str, user_data: pd.DataFrame, top_k: int = 5) -> List[Dict]:
    """AI ì„ë² ë”©ì„ ì‚¬ìš©í•œ ìœ ì‚¬ ê²½í—˜ ì°¾ê¸° (ë°°ì¹˜ ì²˜ë¦¬ëœ ë°ì´í„° ì‚¬ìš©)"""
    if user_data.empty or not check_gemini_api():
        return []
    
    # 1. í˜„ì¬ ìƒí™©ì„ ì„ë² ë”©ìœ¼ë¡œ ë³€í™˜ (ë‹¨ì¼ í˜¸ì¶œ)
    current_embedding = create_embedding(current_situation)
    if not current_embedding:
        return []
    
    # 2. ì„ë² ë”©ì´ ìˆëŠ” ê³¼ê±° ê±°ë˜ë§Œ í•„í„°ë§
    valid_trades = user_data[
        user_data['embedding'].notna() & 
        user_data['embedding'].apply(lambda x: isinstance(x, list) and len(x) > 0)
    ]
    
    if valid_trades.empty:
        return []
    
    # 3. ìºì‹œëœ ê³¼ê±° ê±°ë˜ ì„ë² ë”©ì„ ê°€ì ¸ì™€ ìœ ì‚¬ë„ ê³„ì‚°
    similar_experiences = []
    
    for idx, trade in valid_trades.iterrows():
        trade_embedding = trade['embedding']
        
        similarity = calculate_cosine_similarity(current_embedding, trade_embedding)
        
        if similarity > 0.2:  # ì„ê³„ê°’
            similar_experiences.append({
                'trade_data': trade.to_dict(),
                'similarity': similarity,
                'date': str(trade.get('ê±°ë˜ì¼ì‹œ', 'ë‚ ì§œ ì •ë³´ ì—†ìŒ')),
                'result': float(trade.get('ìˆ˜ìµë¥ ', 0))
            })
    
    # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìƒìœ„ kê°œ ë°˜í™˜
    similar_experiences.sort(key=lambda x: x['similarity'], reverse=True)
    return similar_experiences[:top_k]

# ê¸°ì¡´ Gemini ê¸°ë°˜ ë¶„ì„ í•¨ìˆ˜ë“¤ (ê·¸ëŒ€ë¡œ ìœ ì§€)
def generate_personalized_coaching(current_situation: str, similar_experiences: List[Dict], user_type: str) -> str:
    """ê°œì¸í™”ëœ AI ì½”ì¹­ ë©”ì‹œì§€ ìƒì„±"""
    if not check_gemini_api() or not setup_gemini_api():
        return "âš ï¸ Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤. ì‚¬ì´ë“œë°”ì—ì„œ API í‚¤ë¥¼ ì„¤ì •í•´ì£¼ì„¸ìš”."
    
    try:
        # ìœ ì‚¬ ê²½í—˜ë“¤ì„ í”„ë¡¬í”„íŠ¸ì— í¬í•¨í•  í˜•íƒœë¡œ ë³€í™˜
        experiences_text = ""
        for i, exp in enumerate(similar_experiences[:3], 1):
            trade = exp['trade_data']
            experiences_text += f"""
            ê²½í—˜ {i} (ìœ ì‚¬ë„: {exp['similarity']*100:.1f}%):
            - ì¢…ëª©: {trade.get('ì¢…ëª©ëª…', '')}
            - ê±°ë˜: {trade.get('ê±°ë˜êµ¬ë¶„', '')}
            - ìˆ˜ìµë¥ : {trade.get('ìˆ˜ìµë¥ ', 0)}%
            - ê°ì •ìƒíƒœ: {trade.get('ê°ì •íƒœê·¸', '')}
            - ë‹¹ì‹œ ë©”ëª¨: "{trade.get('ë©”ëª¨', '')}"
            """
        
        # ì‚¬ìš©ì ìœ í˜•ë³„ ë§ì¶¤ í”„ë¡¬í”„íŠ¸
        if user_type == "ê¹€êµ­ë¯¼":
            persona_context = "ê³µí¬ë§¤ë„ ì„±í–¥ì´ ê°•í•œ ë³´ìˆ˜ì  íˆ¬ìì"
            coaching_focus = "ê°ì •ì  íŒë‹¨ì„ í”¼í•˜ê³  ë°ì´í„° ê¸°ë°˜ì˜ ëƒ‰ì •í•œ ë¶„ì„ì„ í†µí•œ íˆ¬ì ê²°ì •"
        else:  # ë°•íˆ¬ì
            persona_context = "FOMO(Fear of Missing Out) ì„±í–¥ì´ ê°•í•œ ì ê·¹ì  íˆ¬ìì"
            coaching_focus = "ì¶©ë™ì  ë§¤ìˆ˜ë¥¼ í”¼í•˜ê³  ì‹ ì¤‘í•œ ë¶„ì„ì„ í†µí•œ íˆ¬ì ê²°ì •"
        
        prompt = f"""
        ë‹¹ì‹ ì€ í•œêµ­ì˜ ì „ë¬¸ íˆ¬ì ì‹¬ë¦¬ ì½”ì¹˜ì…ë‹ˆë‹¤. {persona_context}ì¸ íˆ¬ììì—ê²Œ ì¡°ì–¸ì„ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.
        
        í˜„ì¬ íˆ¬ì ìƒí™©:
        {current_situation}
        
        ì´ íˆ¬ììì˜ ê³¼ê±° ìœ ì‚¬ ê²½í—˜ë“¤:
        {experiences_text}
        
        ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì¡°ì–¸í•´ì£¼ì„¸ìš”:
        
        ## ğŸ” íŒ¨í„´ ë¶„ì„
        ê³¼ê±° ìœ ì‚¬ ê±°ë˜ë“¤ì˜ ê³µí†µì ê³¼ ê²°ê³¼ë¥¼ 2-3ë¬¸ì¥ìœ¼ë¡œ ë¶„ì„
        
        ## â“ ìê¸° ì„±ì°° ì§ˆë¬¸
        í˜„ì¬ ê²°ì •ì„ ë‚´ë¦¬ê¸° ì „ ìŠ¤ìŠ¤ë¡œì—ê²Œ ë¬¼ì–´ë´ì•¼ í•  3ê°€ì§€ í•µì‹¬ ì§ˆë¬¸
        
        ## ğŸ’¡ êµ¬ì²´ì  ì¡°ì–¸
        {coaching_focus}ë¥¼ ìœ„í•œ 3-4ê°€ì§€ ì‹¤í–‰ ê°€ëŠ¥í•œ ì¡°ì–¸
        
        ## ğŸ¯ 24ì‹œê°„ ì•¡ì…˜ í”Œëœ
        ì˜¤ëŠ˜ ë‹¹ì¥ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” 1-2ê°€ì§€ êµ¬ì²´ì  í–‰ë™
        
        ë‹µë³€ì€ ì¹œê·¼í•˜ë©´ì„œë„ ì „ë¬¸ì ì¸ í†¤ìœ¼ë¡œ, íˆ¬ììì˜ ì„±í–¥ì„ ê³ ë ¤í•˜ì—¬ í•œêµ­ì–´ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
        """
        
        model = genai.GenerativeModel('gemini-1.5-flash')
        response = model.generate_content(prompt)
        
        return response.text
        
    except Exception as e:
        return f"AI ì½”ì¹­ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def analyze_trading_pattern_with_ai(user_data: pd.DataFrame, user_type: str) -> Dict[str, Any]:
    """AIë¥¼ í™œìš©í•œ ì¢…í•©ì ì¸ ê±°ë˜ íŒ¨í„´ ë¶„ì„"""
    if user_data.empty or not check_gemini_api():
        return {}
    
    try:
        # ê±°ë˜ ë°ì´í„° ìš”ì•½ ìƒì„±
        total_trades = len(user_data)
        avg_return = user_data['ìˆ˜ìµë¥ '].mean()
        losing_trades = user_data[user_data['ìˆ˜ìµë¥ '] < 0]
        winning_trades = user_data[user_data['ìˆ˜ìµë¥ '] > 0]
        emotion_distribution = user_data['ê°ì •íƒœê·¸'].value_counts().to_dict()
        
        # ê°ì •ë³„ ì„±ê³¼ ë¶„ì„
        emotion_performance = user_data.groupby('ê°ì •íƒœê·¸')['ìˆ˜ìµë¥ '].agg(['mean', 'count']).round(2)
        
        # ìµœê·¼ 10ê°œ ê±°ë˜ ë¶„ì„
        recent_trades = user_data.tail(10)
        recent_context = ""
        for _, trade in recent_trades.iterrows():
            recent_context += f"""
            - {trade.get('ê±°ë˜ì¼ì‹œ', '')}: {trade.get('ì¢…ëª©ëª…', '')} ({trade.get('ê±°ë˜êµ¬ë¶„', '')})
              ê°ì •: {trade.get('ê°ì •íƒœê·¸', '')}, ìˆ˜ìµë¥ : {trade.get('ìˆ˜ìµë¥ ', 0)}%
              ë©”ëª¨: "{trade.get('ë©”ëª¨', '')}"
            """
        
        prompt = f"""
        ë‹¹ì‹ ì€ í•œêµ­ì˜ ì „ë¬¸ íˆ¬ì ë¶„ì„ê°€ì…ë‹ˆë‹¤. {user_type} íˆ¬ììì˜ ê±°ë˜ íŒ¨í„´ì„ ì¢…í•© ë¶„ì„í•´ì£¼ì„¸ìš”.
        
        ## ê±°ë˜ ë°ì´í„° ìš”ì•½
        - ì´ ê±°ë˜ íšŸìˆ˜: {total_trades}íšŒ
        - í‰ê·  ìˆ˜ìµë¥ : {avg_return:.1f}%
        - ìˆ˜ìµ ê±°ë˜: {len(winning_trades)}íšŒ ({len(winning_trades)/total_trades*100:.1f}%)
        - ì†ì‹¤ ê±°ë˜: {len(losing_trades)}íšŒ ({len(losing_trades)/total_trades*100:.1f}%)
        - ê°ì •ë³„ ê±°ë˜ ë¶„í¬: {emotion_distribution}
        
        ## ê°ì •ë³„ ì„±ê³¼ ë¶„ì„
        {emotion_performance.to_string()}
        
        ## ìµœê·¼ 10ê°œ ê±°ë˜ íŒ¨í„´
        {recent_context}
        
        ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ìƒì„¸ ë¶„ì„í•´ì£¼ì„¸ìš”:
        
        ### ğŸ¯ í•µì‹¬ íˆ¬ì íŒ¨í„´
        - ì£¼ìš” ê°•ì  2ê°€ì§€
        - ì£¼ìš” ì•½ì  2ê°€ì§€
        - íŠ¹ì´í•œ íŒ¨í„´ì´ë‚˜ ìŠµê´€
        
        ### ğŸ“Š ê°ì •ë³„ ì„±ê³¼ ë¶„ì„
        - ê°€ì¥ ìˆ˜ìµì„±ì´ ë†’ì€ ê°ì • ìƒíƒœ
        - ê°€ì¥ ìœ„í—˜í•œ ê°ì • ìƒíƒœ
        - ê°ì • ê´€ë¦¬ ê°œì„ ì 
        
        ### âš ï¸ ìœ„í—˜ ì‹ í˜¸ ê°ì§€
        - ê±°ë˜ ì¤‘ë‹¨ì„ ê³ ë ¤í•´ì•¼ í•˜ëŠ” 3ê°€ì§€ ì‹ í˜¸
        - ê° ì‹ í˜¸ì— ëŒ€í•œ êµ¬ì²´ì  ê¸°ì¤€
        
        ### ğŸ’ ê°œì„  ì „ëµ
        - ì¦‰ì‹œ ì ìš© ê°€ëŠ¥í•œ 3ê°€ì§€ ê°œì„ ì±…
        - ì¤‘ì¥ê¸° ëª©í‘œ 2ê°€ì§€
        
        ### ğŸ“‹ ë§ì¶¤í˜• íˆ¬ì ì›ì¹™
        - ì´ íˆ¬ììì—ê²Œ íŠ¹íˆ ì¤‘ìš”í•œ 3ê°€ì§€ ê·œì¹™
        - ê° ê·œì¹™ì˜ ê·¼ê±°
        
        ë¶„ì„ì€ ë°ì´í„°ì— ê·¼ê±°í•˜ì—¬ êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•œ ë‚´ìš©ìœ¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
        """
        
        model = genai.GenerativeModel('gemini-1.5-flash')
        response = model.generate_content(prompt)
        
        return {
            'analysis': response.text,
            'total_trades': total_trades,
            'avg_return': avg_return,
            'win_rate': len(winning_trades)/total_trades*100,
            'loss_rate': len(losing_trades)/total_trades*100,
            'emotion_distribution': emotion_distribution,
            'emotion_performance': emotion_performance.to_dict()
        }
        
    except Exception as e:
        return {'error': f"íŒ¨í„´ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}"}

def generate_investment_charter(user_data: pd.DataFrame, user_type: str) -> str:
    """ê°œì¸í™”ëœ íˆ¬ì í—Œì¥ ìƒì„±"""
    if user_data.empty or not check_gemini_api():
        return "íˆ¬ì í—Œì¥ì„ ìƒì„±í•˜ê¸° ìœ„í•´ì„œëŠ” ì¶©ë¶„í•œ ê±°ë˜ ë°ì´í„°ì™€ Gemini APIê°€ í•„ìš”í•©ë‹ˆë‹¤."
    
    try:
        # ë°ì´í„° ë¶„ì„
        pattern_analysis = analyze_trading_pattern_with_ai(user_data, user_type)
        
        if 'error' in pattern_analysis:
            return f"í—Œì¥ ìƒì„± ì¤‘ ì˜¤ë¥˜: {pattern_analysis['error']}"
        
        # ì†ì‹¤ì´ í° ê°ì • íŒ¨í„´ ì‹ë³„
        losing_emotions = user_data[user_data['ìˆ˜ìµë¥ '] < -5].groupby('ê°ì •íƒœê·¸')['ìˆ˜ìµë¥ '].agg(['mean', 'count'])
        
        prompt = f"""
        ë‹¹ì‹ ì€ íˆ¬ì í—Œì¥ ì‘ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤. {user_type} íˆ¬ììë¥¼ ìœ„í•œ ê°œì¸í™”ëœ íˆ¬ì í—Œì¥ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
        
        íˆ¬ìì í”„ë¡œí•„:
        - ì´ ê±°ë˜: {pattern_analysis.get('total_trades', 0)}íšŒ
        - í‰ê·  ìˆ˜ìµë¥ : {pattern_analysis.get('avg_return', 0):.1f}%
        - ìŠ¹ë¥ : {pattern_analysis.get('win_rate', 0):.1f}%
        
        ì£¼ìš” ìœ„í—˜ ê°ì •:
        {losing_emotions.to_string() if not losing_emotions.empty else "íŠ¹ë³„í•œ ìœ„í—˜ íŒ¨í„´ ì—†ìŒ"}
        
        ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ íˆ¬ì í—Œì¥ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:
        
        # ğŸ“œ {user_type}ë‹˜ì˜ ê°œì¸ íˆ¬ì í—Œì¥
        
        ## ğŸ¯ íˆ¬ì ì² í•™
        ë‚˜ì˜ íˆ¬ì ìŠ¤íƒ€ì¼ê³¼ ëª©í‘œë¥¼ ëª…í™•íˆ ì„ ì–¸
        
        ## âš–ï¸ í•µì‹¬ ì›ì¹™ (5ê°€ì§€)
        1. ê°ì • ê´€ë¦¬ ì›ì¹™
        2. ë¦¬ìŠ¤í¬ ê´€ë¦¬ ì›ì¹™  
        3. ê±°ë˜ ì‹¤í–‰ ì›ì¹™
        4. ì •ë³´ ìˆ˜ì§‘ ì›ì¹™
        5. ì„±ê³¼ í‰ê°€ ì›ì¹™
        
        ## ğŸš« ì ˆëŒ€ ê¸ˆì§€ ì‚¬í•­ (3ê°€ì§€)
        ì´ íˆ¬ììê°€ ì ˆëŒ€ í•˜ì§€ ë§ì•„ì•¼ í•  í–‰ë™ë“¤
        
        ## â° ê±°ë˜ ì¤‘ë‹¨ ê¸°ì¤€
        ì–¸ì œ íˆ¬ìë¥¼ ë©ˆì¶”ê³  ëƒ‰ì •í•´ì•¼ í•˜ëŠ”ì§€
        
        ## ğŸ“Š ì •ê¸° ì ê²€ ê³„íš
        ì–¸ì œ, ì–´ë–»ê²Œ ì´ í—Œì¥ì„ ê²€í† í•  ê²ƒì¸ì§€
        
        ## âœï¸ ì„œëª…
        ì‘ì„±ì¼: {datetime.now().strftime('%Yë…„ %mì›” %dì¼')}
        íˆ¬ìì: {user_type}
        
        ê° í•­ëª©ì€ ì´ íˆ¬ììì˜ ì‹¤ì œ ë°ì´í„°ì™€ íŒ¨í„´ì„ ë°˜ì˜í•˜ì—¬ êµ¬ì²´ì ì´ê³  ì‹¤í–‰ ê°€ëŠ¥í•˜ê²Œ ì‘ì„±í•´ì£¼ì„¸ìš”.
        """
        
        model = genai.GenerativeModel('gemini-1.5-flash')
        response = model.generate_content(prompt)
        
        return response.text
        
    except Exception as e:
        return f"íˆ¬ì í—Œì¥ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}"

def analyze_trading_psychology(user_input: str, user_data: pd.DataFrame, user_type: str) -> str:
    """ê±°ë˜ ì‹¬ë¦¬ ìƒíƒœ ë¶„ì„"""
    if not check_gemini_api():
        return "ì‹¬ë¦¬ ë¶„ì„ì„ ìœ„í•´ Gemini APIê°€ í•„ìš”í•©ë‹ˆë‹¤."
    
    try:
        # ìµœê·¼ ê±°ë˜ íŒ¨í„´
        recent_emotions = user_data.tail(10)['ê°ì •íƒœê·¸'].value_counts().to_dict() if not user_data.empty else {}
        recent_returns = user_data.tail(5)['ìˆ˜ìµë¥ '].tolist() if not user_data.empty else []
        
        prompt = f"""
        ë‹¹ì‹ ì€ íˆ¬ì ì‹¬ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. {user_type} íˆ¬ììì˜ í˜„ì¬ ì‹¬ë¦¬ ìƒíƒœë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.
        
        íˆ¬ììì˜ í˜„ì¬ ìƒê°/ê³ ë¯¼:
        "{user_input}"
        
        ìµœê·¼ ê±°ë˜ì—ì„œì˜ ê°ì • íŒ¨í„´:
        {recent_emotions}
        
        ìµœê·¼ 5íšŒ ê±°ë˜ ìˆ˜ìµë¥ :
        {recent_returns}
        
        ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:
        
        ## ğŸ§  í˜„ì¬ ì‹¬ë¦¬ ìƒíƒœ ì§„ë‹¨
        - ì£¼ìš” ê°ì •: (ë¶ˆì•ˆ/ìš•ì‹¬/ê³µí¬/ìì‹ ê° ë“±)
        - ìœ„í—˜ë„: (ë‚®ìŒ/ë³´í†µ/ë†’ìŒ/ë§¤ìš°ë†’ìŒ)
        - íŒë‹¨ë ¥ ìƒíƒœ: ë¶„ì„
        
        ## ğŸ” ì‹¬ë¦¬ì  í¸í–¥ ì²´í¬
        - ì¸ì§€í¸í–¥ ì—¬ë¶€ (í™•ì¦í¸í–¥, ì†ì‹¤íšŒí”¼í¸í–¥ ë“±)
        - ê°ì •ì  ì˜ì‚¬ê²°ì • ìœ„í—˜ë„
        
        ## ğŸ’Š ì²˜ë°©ì „
        - ì¦‰ì‹œ ì‹¤í–‰í•  ë©˜íƒˆ ê´€ë¦¬ë²• 2ê°€ì§€
        - 24ì‹œê°„ ë‚´ í”¼í•´ì•¼ í•  í–‰ë™ 3ê°€ì§€
        - ì¥ê¸°ì  ì‹¬ë¦¬ í›ˆë ¨ ë°©ë²• 1ê°€ì§€
        
        ## ğŸ¯ ë‹¤ìŒ ê±°ë˜ ê¶Œì¥ì‚¬í•­
        í˜„ì¬ ì‹¬ë¦¬ ìƒíƒœë¥¼ ê³ ë ¤í•œ êµ¬ì²´ì  í–‰ë™ ì§€ì¹¨
        
        ë¶„ì„ì€ ê³µê°ì ì´ë©´ì„œë„ ê°ê´€ì ìœ¼ë¡œ, ì‹¤ìš©ì ì¸ ì¡°ì–¸ ìœ„ì£¼ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
        """
        
        model = genai.GenerativeModel('gemini-1.5-flash')
        response = model.generate_content(prompt)
        
        return response.text
        
    except Exception as e:
        return f"ì‹¬ë¦¬ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}"

# ê¸°ì¡´ í˜¸í™˜ì„± í•¨ìˆ˜ë“¤ (ìµœì í™”ëœ ë²„ì „)
def find_similar_trades(current_trade, csv_data, similarity_threshold=0.3):
    """ê¸°ì¡´ ìœ ì‚¬ ê±°ë˜ ì°¾ê¸° í•¨ìˆ˜ (ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™” + í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€)"""
    if csv_data.empty:
        return []
    
    # ì„ë² ë”©ì´ ì¤€ë¹„ëœ ë°ì´í„° ì‚¬ìš© (ë¹ ë¥¸ ê²½ë¡œ)
    if 'embedding' in csv_data.columns and check_gemini_api():
        current_situation = f"""
        ì¢…ëª©: {current_trade.get('ì¢…ëª©', '')}
        ê±°ë˜êµ¬ë¶„: {current_trade.get('ê±°ë˜ìœ í˜•', '')}
        ìˆ˜ëŸ‰: {current_trade.get('ìˆ˜ëŸ‰', '')}ì£¼
        ê°€ê²©: {current_trade.get('ê°€ê²©', '')}ì›
        """
        
        similar_experiences = find_similar_experiences_ai(current_situation, csv_data, top_k=5)
        if similar_experiences:
            return similar_experiences
    
    # ê¸°ë³¸ í‚¤ì›Œë“œ ë§¤ì¹­ ë°©ì‹ (í´ë°±)
    similar_trades = []
    current_stock = current_trade.get('ì¢…ëª©', '')
    current_type = current_trade.get('ê±°ë˜ìœ í˜•', '')
    
    for _, trade in csv_data.iterrows():
        similarity_score = 0
        similarity_reasons = []
        
        # ì¢…ëª©ëª… ìœ ì‚¬ë„
        if str(trade.get('ì¢…ëª©ëª…', '')) == current_stock:
            similarity_score += 0.4
            similarity_reasons.append(f"ë™ì¼ ì¢…ëª© ({current_stock})")
        
        # ê±°ë˜ êµ¬ë¶„ ìœ ì‚¬ë„
        if str(trade.get('ê±°ë˜êµ¬ë¶„', '')) == current_type:
            similarity_score += 0.3
            similarity_reasons.append(f"ë™ì¼ ê±°ë˜ìœ í˜• ({current_type})")
        
        # ê°ì • íŒ¨í„´ ìœ ì‚¬ë„
        emotion_tag = trade.get('ê°ì •íƒœê·¸', '')
        if emotion_tag and any(keyword in emotion_tag for keyword in ['#ê³µí¬', '#íŒ¨ë‹‰', '#ì¶”ê²©ë§¤ìˆ˜', '#ìš•ì‹¬']):
            similarity_score += 0.3
            similarity_reasons.append(f"ìœ„í—˜ ê°ì •íŒ¨í„´ ({emotion_tag})")
        
        if similarity_score >= similarity_threshold:
            similar_trades.append({
                'trade_data': trade.to_dict(),
                'similarity': similarity_score,
                'reasons': similarity_reasons,
                'date': str(trade.get('ê±°ë˜ì¼ì‹œ', 'ë‚ ì§œ ì •ë³´ ì—†ìŒ')),
                'result': float(trade.get('ìˆ˜ìµë¥ ', 0))
            })
    
    similar_trades.sort(key=lambda x: x['similarity'], reverse=True)
    return similar_trades[:5]

def analyze_trade_with_ai(stock_name, trade_type, quantity, price, csv_data):
    """ê°œì„ ëœ ê±°ë˜ ë¶„ì„ í•¨ìˆ˜ (ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”)"""
    current_trade = {
        "ì¢…ëª©": stock_name,
        "ê±°ë˜ìœ í˜•": trade_type,
        "ìˆ˜ëŸ‰": quantity,
        "ê°€ê²©": price
    }
    
    current_situation = f"""
    ì¢…ëª©: {stock_name}
    ê±°ë˜êµ¬ë¶„: {trade_type}
    ìˆ˜ëŸ‰: {quantity}ì£¼
    ê°€ê²©: {price:,}ì›
    """
    
    # ì„ë² ë”©ì´ ì¤€ë¹„ëœ ë°ì´í„°ë¡œ ë¹ ë¥¸ ë¶„ì„
    if 'embedding' in csv_data.columns and check_gemini_api():
        similar_trades = find_similar_experiences_ai(current_situation, csv_data)
        if similar_trades:
            ai_analysis = generate_personalized_coaching(
                current_situation, 
                similar_trades, 
                st.session_state.get('current_user', 'ê¹€êµ­ë¯¼')
            )
            return {
                'similar_trades': similar_trades,
                'ai_analysis': ai_analysis,
                'method': 'optimized_gemini_ai'
            }
    
    # ê¸°ë³¸ ë°©ì‹ (í´ë°±)
    similar_trades = find_similar_trades(current_trade, csv_data)
    
    return {
        'similar_trades': similar_trades,
        'ai_analysis': "ì„ë² ë”© ë°ì´í„°ë¥¼ ì¤€ë¹„í•˜ë©´ ë” ì •í™•í•œ AI ë¶„ì„ì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        'method': 'basic'
    }

# ReMinDKoreanEngine í´ë˜ìŠ¤ (ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”)
class ReMinDKoreanEngine:
    """í•œêµ­ì–´ íˆ¬ì ì‹¬ë¦¬ ë¶„ì„ ì—”ì§„ (Gemini ê¸°ë°˜, ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”)"""
    
    def __init__(self):
        self.behavioral_patterns = {
            'ê³µí¬ë§¤ë„': ['ë¬´ì„œì›Œ', 'ê±±ì •', 'íŒ¨ë‹‰', 'í­ë½', 'ì†ì‹¤', 'ìœ„í—˜', 'ê¸‰ë½', 'í•˜ë½', 'ì†ì ˆ'],
            'ì¶”ê²©ë§¤ìˆ˜': ['ìƒí•œê°€', 'ê¸‰ë“±', 'ë†“ì¹˜ê¸°', 'ë’¤ëŠ¦ê²Œ', 'ì¶”ê²©', 'ëª¨ë‘ê°€', 'FOMO', 'fomo', 'ê¸‰íˆ', 'ìœ íŠœë²„', 'ì¶”ì²œ', 'ì»¤ë®¤ë‹ˆí‹°'],
            'ë³µìˆ˜ë§¤ë§¤': ['ë¶„í•˜ë‹¤', 'ë³´ë³µ', 'í™”ë‚˜ë‹¤', 'ì–µìš¸í•˜ë‹¤', 'íšŒë³µ', 'ë˜ì°¾ê¸°'],
            'ê³¼ì‹ ë§¤ë§¤': ['í™•ì‹ ', 'í‹€ë¦¼ì—†ë‹¤', 'ì‰¬ìš´ëˆ', 'í™•ì‹¤í•˜ë‹¤', 'ë³´ì¥', 'ë¬´ì¡°ê±´', 'ëŒ€ë°•', 'ì˜¬ì¸']
        }
        
        # ë°°ì¹˜ ì²˜ë¦¬ë¥¼ ìœ„í•œ ìºì‹œ
        self._emotion_cache = {}
    
    def analyze_emotion_text_batch(self, texts: List[str], user_type: str) -> List[Dict]:
        """ë°°ì¹˜ë¡œ ê°ì • ë¶„ì„ ì²˜ë¦¬"""
        if not texts:
            return []
        
        results = []
        
        # Gemini ë°°ì¹˜ ë¶„ì„ ì‹œë„
        if check_gemini_api() and len(texts) > 5:  # 5ê°œ ì´ìƒì¼ ë•Œë§Œ ë°°ì¹˜ ì²˜ë¦¬
            try:
                batch_prompt = f"""
                ë‹¤ìŒ {len(texts)}ê°œì˜ í…ìŠ¤íŠ¸ë“¤ì—ì„œ ê°ê°ì˜ íˆ¬ì ê°ì • íŒ¨í„´ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.
                ê° í…ìŠ¤íŠ¸ëŠ” ë²ˆí˜¸ë¡œ êµ¬ë¶„ë˜ì–´ ìˆìŠµë‹ˆë‹¤.
                
                """
                
                for i, text in enumerate(texts, 1):
                    batch_prompt += f"{i}. {text}\n"
                
                batch_prompt += """
                
                ê° í…ìŠ¤íŠ¸ì— ëŒ€í•´ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ë¥¼ ë°°ì—´ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”:
                [
                    {
                        "id": 1,
                        "pattern": "ê³µí¬ë§¤ë„/ì¶”ê²©ë§¤ìˆ˜/ë³µìˆ˜ë§¤ë§¤/ê³¼ì‹ ë§¤ë§¤/í•©ë¦¬ì íˆ¬ì ì¤‘ í•˜ë‚˜",
                        "confidence": 0.0~1.0 ì‚¬ì´ ê°’,
                        "keywords": ["ê°ì§€ëœ", "í‚¤ì›Œë“œ"],
                        "description": "íŒ¨í„´ ì„¤ëª…"
                    },
                    ...
                ]
                """
                
                model = genai.GenerativeModel('gemini-1.5-flash')
                response = model.generate_content(batch_prompt)
                
                # JSON íŒŒì‹± ì‹œë„
                try:
                    batch_results = json.loads(response.text)
                    if isinstance(batch_results, list) and len(batch_results) == len(texts):
                        return batch_results
                except:
                    pass  # íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê°œë³„ ì²˜ë¦¬ë¡œ í´ë°±
                    
            except Exception as e:
                st.warning(f"ë°°ì¹˜ ê°ì • ë¶„ì„ ì˜¤ë¥˜: {e}")
        
        # ê°œë³„ ì²˜ë¦¬ (í´ë°±)
        for text in texts:
            results.append(self.analyze_emotion_text(text, user_type))
        
        return results
    
    def analyze_emotion_text(self, text, user_type):
        """ë‹¨ì¼ ê°ì • ë¶„ì„ (ìºì‹œ ì ìš©)"""
        if not text or not isinstance(text, str):
            return {
                'pattern': 'ì¤‘ë¦½', 
                'confidence': 0.5, 
                'keywords': [],
                'description': 'ê°ì • íŒ¨í„´ì„ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
            }
        
        # ìºì‹œ í™•ì¸
        cache_key = hashlib.md5(f"{text}_{user_type}".encode()).hexdigest()
        if cache_key in self._emotion_cache:
            return self._emotion_cache[cache_key]
        
        result = self._analyze_emotion_internal(text, user_type)
        
        # ìºì‹œ ì €ì¥ (ìµœëŒ€ 1000ê°œê¹Œì§€)
        if len(self._emotion_cache) < 1000:
            self._emotion_cache[cache_key] = result
        
        return result
    
    def _analyze_emotion_internal(self, text, user_type):
        """ë‚´ë¶€ ê°ì • ë¶„ì„ ë¡œì§"""
        # Gemini ë¶„ì„ ì‹œë„
        if check_gemini_api():
            try:
                prompt = f"""
                ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ íˆ¬ì ê°ì • íŒ¨í„´ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:
                "{text}"
                
                ë¶„ì„ ê²°ê³¼ë¥¼ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”:
                {{
                    "pattern": "ê³µí¬ë§¤ë„/ì¶”ê²©ë§¤ìˆ˜/ë³µìˆ˜ë§¤ë§¤/ê³¼ì‹ ë§¤ë§¤/í•©ë¦¬ì íˆ¬ì ì¤‘ í•˜ë‚˜",
                    "confidence": 0.0~1.0 ì‚¬ì´ ê°’,
                    "keywords": ["ê°ì§€ëœ", "í‚¤ì›Œë“œ", "ëª©ë¡"],
                    "description": "íŒ¨í„´ì— ëŒ€í•œ ì„¤ëª…"
                }}
                """
                
                model = genai.GenerativeModel('gemini-1.5-flash')
                response = model.generate_content(prompt)
                
                # JSON íŒŒì‹± ì‹œë„
                try:
                    result = json.loads(response.text)
                    return result
                except:
                    pass  # JSON íŒŒì‹± ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë¶„ì„ìœ¼ë¡œ í´ë°±
            except Exception:
                pass  # Gemini ë¶„ì„ ì‹¤íŒ¨ ì‹œ ê¸°ë³¸ ë¶„ì„ìœ¼ë¡œ í´ë°±
        
        # ê¸°ë³¸ í‚¤ì›Œë“œ ë¶„ì„ (í´ë°±)
        text_lower = text.lower()
        found_keywords = []
        patterns_found = {}
        
        for pattern, keywords in self.behavioral_patterns.items():
            pattern_keywords = [kw for kw in keywords if kw in text_lower]
            if pattern_keywords:
                patterns_found[pattern] = len(pattern_keywords)
                found_keywords.extend(pattern_keywords)
        
        if patterns_found:
            dominant_pattern = max(patterns_found, key=patterns_found.get)
            confidence = min(0.9, 0.6 + (patterns_found[dominant_pattern] * 0.1))
            
            descriptions = {
                'ê³µí¬ë§¤ë„': 'ì‹œì¥ í•˜ë½ì— ëŒ€í•œ ë‘ë ¤ì›€ìœ¼ë¡œ ì¸í•œ íŒ¨ë‹‰ ë§¤ë„ íŒ¨í„´',
                'ì¶”ê²©ë§¤ìˆ˜': 'FOMO(Fear of Missing Out)ì— ì˜í•œ ê³ ì  ë§¤ìˆ˜ íŒ¨í„´',
                'ë³µìˆ˜ë§¤ë§¤': 'ì†ì‹¤ íšŒë³µì„ ìœ„í•œ ê°ì •ì  ë³µìˆ˜ ê±°ë˜ íŒ¨í„´',
                'ê³¼ì‹ ë§¤ë§¤': 'ê³¼ë„í•œ ìì‹ ê°ìœ¼ë¡œ ì¸í•œ ë¬´ë¦¬í•œ íˆ¬ì íŒ¨í„´'
            }
            
            return {
                'pattern': dominant_pattern,
                'confidence': confidence,
                'keywords': found_keywords[:3],
                'description': descriptions.get(dominant_pattern, 'ì•Œ ìˆ˜ ì—†ëŠ” íŒ¨í„´')
            }
        
        return {
            'pattern': 'í•©ë¦¬ì íˆ¬ì',
            'confidence': 0.60,
            'keywords': [],
            'description': 'ë°ì´í„° ê¸°ë°˜ì˜ í•©ë¦¬ì  íˆ¬ì íŒ¨í„´'
        }
    
    def generate_investment_charter_rules(self, user_data, user_type):
        """íˆ¬ì í—Œì¥ ê·œì¹™ ìƒì„± (ë°°ì¹˜ ì²˜ë¦¬ ìµœì í™”)"""
        if user_data.empty:
            return []
        
        rules = []
        
        # ê°ì •ë³„ ìˆ˜ìµë¥  ë¶„ì„
        if 'ê°ì •íƒœê·¸' in user_data.columns and 'ìˆ˜ìµë¥ ' in user_data.columns:
            emotion_performance = user_data.groupby('ê°ì •íƒœê·¸')['ìˆ˜ìµë¥ '].mean()
            
            # ì†ì‹¤ì´ í° ê°ì • íŒ¨í„´ì— ëŒ€í•œ ê·œì¹™ ìƒì„±
            for emotion, avg_return in emotion_performance.items():
                if avg_return < -5:  # í‰ê·  -5% ì´í•˜ì¸ ê²½ìš°
                    if emotion in ['#ê³µí¬', '#íŒ¨ë‹‰']:
                        rules.append({
                            'rule': f'{emotion} ìƒíƒœì¼ ë•ŒëŠ” 24ì‹œê°„ ê±°ë˜ ê¸ˆì§€',
                            'rationale': f'ê³¼ê±° ë°ì´í„°ìƒ {emotion} ìƒíƒœì—ì„œ í‰ê·  {avg_return:.1f}% ì†ì‹¤',
                            'evidence': f'{len(user_data[user_data["ê°ì •íƒœê·¸"] == emotion])}íšŒ ê±°ë˜ ë¶„ì„',
                            'category': 'ê°ì • ê´€ë¦¬'
                        })
                    elif emotion in ['#ì¶”ê²©ë§¤ìˆ˜', '#ìš•ì‹¬']:
                        rules.append({
                            'rule': 'ê¸‰ë“±ì£¼ ì¶”ê²©ë§¤ìˆ˜ ì‹œ íˆ¬ìê¸ˆì•¡ì„ 10ë§Œì› ì´í•˜ë¡œ ì œí•œ',
                            'rationale': f'ì¶”ê²©ë§¤ìˆ˜ì—ì„œ í‰ê·  {avg_return:.1f}% ì†ì‹¤ ë°œìƒ',
                            'evidence': f'{len(user_data[user_data["ê°ì •íƒœê·¸"] == emotion])}íšŒ ê±°ë˜ ë¶„ì„',
                            'category': 'FOMO ë°©ì§€'
                        })
        
        return rules[:5]  # ìµœëŒ€ 5ê°œ ê·œì¹™ë§Œ ë°˜í™˜
    
    def extract_principles_from_notes(self, user_data):
        """ë³µê¸°ë…¸íŠ¸ì—ì„œ íˆ¬ì ì›ì¹™ ì¶”ì¶œ (ìµœì í™”)"""
        if user_data.empty or 'ë©”ëª¨' not in user_data.columns:
            return []
        
        principles = []
        
        # ì†ì‹¤ ê±°ë˜ ë¶„ì„
        losing_trades = user_data[user_data['ìˆ˜ìµë¥ '] < 0]
        
        if len(losing_trades) > 5:
            # ê°ì •ë³„ ì†ì‹¤ íŒ¨í„´ ë¶„ì„
            emotion_losses = losing_trades.groupby('ê°ì •íƒœê·¸').agg({
                'ìˆ˜ìµë¥ ': ['mean', 'count']
            }).round(2)
            
            for emotion in emotion_losses.index:
                avg_loss = emotion_losses.loc[emotion, ('ìˆ˜ìµë¥ ', 'mean')]
                count = emotion_losses.loc[emotion, ('ìˆ˜ìµë¥ ', 'count')]
                
                if count >= 3 and avg_loss < -5:
                    principles.append({
                        'title': f'{emotion} ìƒíƒœì—ì„œì˜ ê±°ë˜ ì œí•œ',
                        'description': f'ê³¼ê±° {count}íšŒ ê±°ë˜ì—ì„œ í‰ê·  {avg_loss:.1f}% ì†ì‹¤ ë°œìƒ',
                        'rule': f'{emotion} ê°ì • ìƒíƒœì¼ ë•ŒëŠ” íˆ¬ì ê²°ì •ì„ 24ì‹œê°„ ì—°ê¸°í•œë‹¤',
                        'evidence_count': int(count),
                        'avg_impact': abs(avg_loss)
                    })
        
        # ì¢…ëª©ë³„ íŒ¨í„´ ë¶„ì„
        if 'ì¢…ëª©ëª…' in user_data.columns:
            stock_losses = losing_trades.groupby('ì¢…ëª©ëª…').agg({
                'ìˆ˜ìµë¥ ': ['mean', 'count']
            }).round(2)
            
            for stock in stock_losses.index:
                avg_loss = stock_losses.loc[stock, ('ìˆ˜ìµë¥ ', 'mean')]
                count = stock_losses.loc[stock, ('ìˆ˜ìµë¥ ', 'count')]
                
                if count >= 3 and avg_loss < -10:
                    principles.append({
                        'title': f'{stock} ì¢…ëª© ê±°ë˜ ì£¼ì˜',
                        'description': f'{stock}ì—ì„œ {count}íšŒ ê±°ë˜ë¡œ í‰ê·  {avg_loss:.1f}% ì†ì‹¤',
                        'rule': f'{stock} ê±°ë˜ ì‹œ íˆ¬ìê¸ˆì•¡ì„ í‰ì†Œì˜ 50%ë¡œ ì œí•œí•œë‹¤',
                        'evidence_count': int(count),
                        'avg_impact': abs(avg_loss)
                    })
        
        # ê¸°ë³¸ ì›ì¹™ë“¤ ì¶”ê°€ (ë°ì´í„°ê°€ ë¶€ì¡±í•œ ê²½ìš°)
        if len(principles) < 3:
            principles.extend([
                {
                    'title': 'ê±°ë˜ ì‹œê°„ëŒ€ ì œí•œ',
                    'description': 'ì¶©ë™ì  ê±°ë˜ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•œ ì‹œê°„ ê´€ë¦¬',
                    'rule': 'ì‹œì¥ ê°œì¥ ì²« 30ë¶„ê³¼ ë§ˆê° 30ë¶„ì—ëŠ” ê±°ë˜í•˜ì§€ ì•ŠëŠ”ë‹¤',
                    'evidence_count': 0,
                    'avg_impact': 0
                },
                {
                    'title': 'ë¶„í•  ë§¤ìˆ˜ ì›ì¹™',
                    'description': 'ë¦¬ìŠ¤í¬ ë¶„ì‚°ì„ ìœ„í•œ íˆ¬ì ì „ëµ',
                    'rule': 'í•œ ë²ˆì— ì „ì²´ íˆ¬ì ì˜ˆì • ê¸ˆì•¡ì˜ 30%ë¥¼ ì´ˆê³¼í•˜ì—¬ ë§¤ìˆ˜í•˜ì§€ ì•ŠëŠ”ë‹¤',
                    'evidence_count': 0,
                    'avg_impact': 0
                },
                {
                    'title': 'ì†ì ˆë§¤ ê¸°ì¤€ ì„¤ì •',
                    'description': 'ì†ì‹¤ í™•ëŒ€ ë°©ì§€ë¥¼ ìœ„í•œ ëª…í™•í•œ ê¸°ì¤€',
                    'rule': 'ë§¤ìˆ˜ê°€ ëŒ€ë¹„ -10% í•˜ë½ ì‹œ ë°˜ë“œì‹œ ì†ì ˆë§¤ë¥¼ ì‹¤í–‰í•œë‹¤',
                    'evidence_count': 0,
                    'avg_impact': 0
                }
            ])
        
        return principles[:5]  # ìµœëŒ€ 5ê°œ ì›ì¹™ë§Œ ë°˜í™˜

def generate_ai_coaching_tip(user_data, user_type):
    """ìµœì í™”ëœ AI ì½”ì¹­ íŒ ìƒì„±"""
    try:
        if user_data.empty:
            return "ğŸ“Š ê±°ë˜ ë°ì´í„°ë¥¼ ì¶•ì í•˜ì—¬ ê°œì¸í™”ëœ AI ì½”ì¹­ì„ ë°›ì•„ë³´ì„¸ìš”."
        
        # ì„ë² ë”© ê¸°ë°˜ ë¹ ë¥¸ íŒ¨í„´ ë¶„ì„
        if 'embedding' in user_data.columns and check_gemini_api():
            # ìµœê·¼ ê±°ë˜ íŒ¨í„´ ë¶„ì„
            recent_trades = user_data.tail(10)
            recent_emotions = recent_trades['ê°ì •íƒœê·¸'].value_counts().to_dict()
            recent_returns = recent_trades['ìˆ˜ìµë¥ '].tolist()
            avg_recent_return = recent_trades['ìˆ˜ìµë¥ '].mean()
            
            # ì „ì²´ ì„±ê³¼ ìš”ì•½
            total_trades = len(user_data)
            overall_return = user_data['ìˆ˜ìµë¥ '].mean()
            win_rate = len(user_data[user_data['ìˆ˜ìµë¥ '] > 0]) / len(user_data) * 100
            
            prompt = f"""
            ë‹¹ì‹ ì€ {user_type} íˆ¬ììì˜ ì „ë‹´ AI ì½”ì¹˜ì…ë‹ˆë‹¤. ì˜¤ëŠ˜ì˜ í•µì‹¬ íˆ¬ì ì¡°ì–¸ì„ ê°„ê²°í•˜ê²Œ ì œê³µí•´ì£¼ì„¸ìš”.
            
            íˆ¬ìì í˜„í™©:
            - ì´ ê±°ë˜: {total_trades}íšŒ
            - ì „ì²´ í‰ê·  ìˆ˜ìµë¥ : {overall_return:.1f}%
            - ìŠ¹ë¥ : {win_rate:.1f}%
            - ìµœê·¼ 10íšŒ ê±°ë˜ í‰ê· : {avg_recent_return:.1f}%
            
            ìµœê·¼ ê°ì • íŒ¨í„´: {recent_emotions}
            ìµœê·¼ ìˆ˜ìµë¥  ì¶”ì´: {recent_returns}
            
            ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì˜¤ëŠ˜ì˜ í•µì‹¬ ì¡°ì–¸ 1ê°œë¥¼ ì œê³µí•´ì£¼ì„¸ìš”:
            
            ğŸ¯ [ì˜¤ëŠ˜ì˜ í•µì‹¬ ë©”ì‹œì§€ - í•œ ë¬¸ì¥]
            ğŸ“Š [ë°ì´í„° ê·¼ê±° - ê°„ë‹¨íˆ]
            ğŸ’¡ [êµ¬ì²´ì  í–‰ë™ ì§€ì¹¨ - ì‹¤í–‰ ê°€ëŠ¥í•œ ë‚´ìš©]
            
            ë‹µë³€ì€ 50ì ì´ë‚´ì˜ ê°„ê²°í•˜ê³  ì„íŒ©íŠ¸ ìˆëŠ” ë©”ì‹œì§€ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
            """
            
            try:
                model = genai.GenerativeModel('gemini-1.5-flash')
                response = model.generate_content(prompt)
                return response.text
            except Exception as e:
                st.warning(f"Gemini ì½”ì¹­ ìƒì„± ì˜¤ë¥˜: {e}")
        
        # ê¸°ë³¸ ë¡œì§ (í´ë°±)
        recent_trades = user_data.tail(5)
        
        if recent_trades.empty:
            return "ğŸ“Š ê±°ë˜ ë°ì´í„°ë¥¼ ì¶•ì í•˜ì—¬ ê°œì¸í™”ëœ ì½”ì¹­ì„ ë°›ì•„ë³´ì„¸ìš”."
        
        if 'ê°ì •íƒœê·¸' not in recent_trades.columns:
            return "ğŸ“Š ê±°ë˜ ë°ì´í„°ì— ê°ì • ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. ë” ìì„¸í•œ ë°ì´í„°ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."
        
        recent_emotions = recent_trades['ê°ì •íƒœê·¸'].value_counts()
        avg_recent_return = recent_trades['ìˆ˜ìµë¥ '].mean() if 'ìˆ˜ìµë¥ ' in recent_trades.columns else 0
        
        # ì‚¬ìš©ì ìœ í˜•ë³„ ë§ì¶¤ ì¡°ì–¸
        if user_type == "ê¹€êµ­ë¯¼":
            if '#ê³µí¬' in recent_emotions.index or '#íŒ¨ë‹‰' in recent_emotions.index:
                return "âš ï¸ ìµœê·¼ ê³µí¬/íŒ¨ë‹‰ ê±°ë˜ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ì˜¤ëŠ˜ì€ ì‹œì¥ì„ ê´€ì°°í•˜ê³  24ì‹œê°„ í›„ ì¬ê²€í† í•˜ì„¸ìš”."
            elif avg_recent_return < -5:
                return "ğŸ’¡ ìµœê·¼ ìˆ˜ìµë¥ ì´ ì €ì¡°í•©ë‹ˆë‹¤. ê°ì •ì  íŒë‹¨ë³´ë‹¤ëŠ” ë°ì´í„° ê¸°ë°˜ ë¶„ì„ì— ì§‘ì¤‘í•´ë³´ì„¸ìš”."
            else:
                return "âœ… ìµœê·¼ ê±°ë˜ íŒ¨í„´ì´ ì•ˆì •ì ì…ë‹ˆë‹¤. í˜„ì¬ì˜ ì‹ ì¤‘í•œ ì ‘ê·¼ì„ ìœ ì§€í•˜ì„¸ìš”."
        else:  # ë°•íˆ¬ì
            if '#ì¶”ê²©ë§¤ìˆ˜' in recent_emotions.index or '#ìš•ì‹¬' in recent_emotions.index:
                return "âš ï¸ ìµœê·¼ FOMO ê±°ë˜ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ì˜¤ëŠ˜ì€ ì¶©ë™ì„ ì–µì œí•˜ê³  ëƒ‰ì •í•œ íŒë‹¨ì„ í•˜ì„¸ìš”."
            elif avg_recent_return < -5:
                return "ğŸ’¡ ìµœê·¼ ìˆ˜ìµë¥ ì´ ì €ì¡°í•©ë‹ˆë‹¤. ì™¸ë¶€ ì¶”ì²œë³´ë‹¤ëŠ” ë³¸ì¸ë§Œì˜ íˆ¬ì ì›ì¹™ì„ ì„¸ì›Œë³´ì„¸ìš”."
            else:
                return "âœ… ìµœê·¼ ê±°ë˜ê°€ ê°œì„ ë˜ê³  ìˆìŠµë‹ˆë‹¤. í˜„ì¬ì˜ ì‹ ì¤‘í•œ ì ‘ê·¼ì„ ê³„ì† ìœ ì§€í•˜ì„¸ìš”."
    
    except Exception as e:
        return f"ğŸ’¡ AI ì½”ì¹­ íŒ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

# ë°ì´í„° ì¤€ë¹„ ë° ê´€ë¦¬ í•¨ìˆ˜ë“¤
def prepare_user_data_with_embeddings(user_data: pd.DataFrame, user_id: str) -> pd.DataFrame:
    """ì‚¬ìš©ì ë°ì´í„°ì— ì„ë² ë”©ì„ ì¤€ë¹„í•˜ëŠ” í†µí•© í•¨ìˆ˜"""
    if user_data.empty:
        return user_data
    
    # ìºì‹œëœ ì„ë² ë”© ë°ì´í„° ì‚¬ìš©
    return preprocess_embeddings_cache(user_data, user_id)

def get_embedding_stats(user_data: pd.DataFrame) -> Dict[str, Any]:
    """ì„ë² ë”© ë°ì´í„° í†µê³„ ë°˜í™˜"""
    if user_data.empty or 'embedding' not in user_data.columns:
        return {
            'total_trades': 0,
            'embedded_trades': 0,
            'embedding_coverage': 0.0,
            'status': 'no_embeddings'
        }
    
    total_trades = len(user_data)
    embedded_trades = user_data['embedding'].notna().sum()
    
    # ìœ íš¨í•œ ì„ë² ë”© í™•ì¸
    valid_embeddings = user_data['embedding'].apply(
        lambda x: isinstance(x, list) and len(x) > 0
    ).sum()
    
    coverage = (valid_embeddings / total_trades * 100) if total_trades > 0 else 0
    
    status = 'complete' if coverage >= 95 else 'partial' if coverage >= 50 else 'minimal'
    
    return {
        'total_trades': total_trades,
        'embedded_trades': int(valid_embeddings),
        'embedding_coverage': coverage,
        'status': status
    }

# í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ë”ë¯¸ í•¨ìˆ˜ë“¤
def check_api_key():
    """í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ í•¨ìˆ˜ - Gemini ì²´í¬ë¡œ ë¦¬ë‹¤ì´ë ‰íŠ¸"""
    return check_gemini_api()

def call_openai_api(prompt, user_type="ê¹€êµ­ë¯¼"):
    """ë”ë¯¸ í•¨ìˆ˜ - ì‚¬ìš©í•˜ì§€ ì•ŠìŒ"""
    return "ì´ ê¸°ëŠ¥ì€ Gemini APIë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. check_gemini_api()ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."

# ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í•¨ìˆ˜
def get_performance_metrics() -> Dict[str, Any]:
    """ì‹œìŠ¤í…œ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë°˜í™˜"""
    metrics = {
        'gemini_available': GEMINI_AVAILABLE,
        'sklearn_available': SKLEARN_AVAILABLE,
        'api_configured': check_gemini_api(),
        'cache_size': len(getattr(ReMinDKoreanEngine(), '_emotion_cache', {})),
        'embedding_model': 'text-embedding-004'
    }
    
    return metrics