# ai_service.py
__all__ = [
    "check_api_key",
    "call_openai_api", 
    "find_similar_trades",
    "analyze_trade_with_ai",
    "ReMinDKoreanEngine",
    "generate_ai_coaching_tip"
]

import json
import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity
import re


def check_api_key():
    """API í‚¤ í™•ì¸"""
    return hasattr(st.session_state, 'openai_api_key') and bool(st.session_state.openai_api_key)
# Import ì˜¤ë¥˜ ë°©ì§€ë¥¼ ìœ„í•œ try-except êµ¬ë¬¸
try:
    from openai import OpenAI
    OPENAI_AVAILABLE = True
except ImportError:
    OPENAI_AVAILABLE = False
    # OpenAI ì—†ì–´ë„ ê²½ê³ í•˜ì§€ ì•ŠìŒ (ì„ 

def call_openai_api(messages, model="gpt-3.5-turbo", temperature=0.7):
    """OpenAI API í˜¸ì¶œ í•¨ìˆ˜ (v1.0+ í˜¸í™˜)"""
    if not check_api_key():
        return "API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ê±°ë‚˜ OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ë¥¼ ì‚¬ìš©í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
    
    if not OPENAI_AVAILABLE:
        return "OpenAI ë¼ì´ë¸ŒëŸ¬ë¦¬ê°€ ì„¤ì¹˜ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    try:
        client = OpenAI(api_key=st.session_state.openai_api_key)
        response = client.chat.completions.create(
            model=model,
            messages=messages,
            temperature=temperature,
            max_tokens=1000
        )
        return response.choices[0].message.content
    except Exception as e:
        return f"AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def find_similar_trades(current_trade, csv_data, similarity_threshold=0.3):
    """ìœ ì‚¬í•œ ê±°ë˜ë“¤ì„ ëª¨ë‘ ì°¾ì•„ì„œ ë°˜í™˜"""
    similar_trades = []
    
    if csv_data.empty:
        return similar_trades
    
    current_stock = current_trade['ì¢…ëª©']
    current_type = current_trade['ê±°ë˜ìœ í˜•']
    
    for _, trade in csv_data.iterrows():
        similarity_score = 0
        similarity_reasons = []
        
        # ì¢…ëª©ëª… ìœ ì‚¬ë„ (ê°€ì¤‘ì¹˜ 30%)
        if str(trade.get('ì¢…ëª©ëª…', '')) == current_stock:
            similarity_score += 0.3
            similarity_reasons.append(f"ë™ì¼ ì¢…ëª© ({current_stock})")
        
        # ê±°ë˜ êµ¬ë¶„ ìœ ì‚¬ë„ (ê°€ì¤‘ì¹˜ 20%)
        if str(trade.get('ê±°ë˜êµ¬ë¶„', '')) == current_type:
            similarity_score += 0.2
            similarity_reasons.append(f"ë™ì¼ ê±°ë˜ìœ í˜• ({current_type})")
        
        # ê°ì •íƒœê·¸ ìœ ì‚¬ë„ (ê°€ì¤‘ì¹˜ 25%)
        emotion_tag = trade.get('ê°ì •íƒœê·¸', '')
        if emotion_tag:
            negative_emotions = ['#ê³µí¬', '#íŒ¨ë‹‰', '#ë¶ˆì•ˆ', '#ì¶”ê²©ë§¤ìˆ˜', '#ìš•ì‹¬']
            if str(emotion_tag) in negative_emotions:
                similarity_score += 0.25
                similarity_reasons.append(f"ê°ì •íŒ¨í„´ ìœ ì‚¬ ({emotion_tag})")
        
        # ê¸°ìˆ ë¶„ì„ í‚¤ì›Œë“œ ìœ ì‚¬ë„ (ê°€ì¤‘ì¹˜ 15%)
        tech_analysis = trade.get('ê¸°ìˆ ë¶„ì„', '')
        if tech_analysis:
            tech_keywords = ['ê³¼ë§¤ë„', 'ê³¼ë§¤ìˆ˜', 'ì§€ì§€ì„ ', 'ì €í•­ì„ ', 'ëŒíŒŒ', 'ë°˜ë“±', 'í•˜ë½', 'ìƒìŠ¹']
            if any(keyword in str(tech_analysis) for keyword in tech_keywords):
                similarity_score += 0.15
                similarity_reasons.append("ê¸°ìˆ ì  íŒ¨í„´ ìœ ì‚¬")
        
        # ë‰´ìŠ¤ë¶„ì„ í‚¤ì›Œë“œ ìœ ì‚¬ë„ (ê°€ì¤‘ì¹˜ 10%)
        news_analysis = trade.get('ë‰´ìŠ¤ë¶„ì„', '')
        if news_analysis:
            news_keywords = ['ì‹¤ì ', 'ë°œí‘œ', 'ê¸°ëŒ€', 'ìš°ë ¤', 'í˜¸ì¬', 'ì•…ì¬']
            if any(keyword in str(news_analysis) for keyword in news_keywords):
                similarity_score += 0.1
                similarity_reasons.append("ë‰´ìŠ¤ ìƒí™© ìœ ì‚¬")
        
        # ì„ê³„ê°’ ì´ìƒì¸ ê²½ìš°ë§Œ ì¶”ê°€
        if similarity_score >= similarity_threshold:
            similar_trades.append({
                'trade': trade.to_dict(),
                'similarity': similarity_score,
                'reasons': similarity_reasons,
                'date': str(trade.get('ê±°ë˜ì¼ì‹œ', 'ë‚ ì§œ ì •ë³´ ì—†ìŒ')),
                'result': float(trade.get('ìˆ˜ìµë¥ ', 0))
            })
    
    # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬
    similar_trades.sort(key=lambda x: x['similarity'], reverse=True)
    return similar_trades

def analyze_trade_with_ai(stock_name, trade_type, quantity, price, csv_data):
    """ê±°ë˜ë¥¼ AIë¡œ ë¶„ì„í•˜ì—¬ ê³¼ê±° CSV ë°ì´í„°ì™€ ë¹„êµ"""
    
    # í˜„ì¬ ê±°ë˜ ì •ë³´ êµ¬ì„±
    current_trade = {
        "ì¢…ëª©": stock_name,
        "ê±°ë˜ìœ í˜•": trade_type,
        "ìˆ˜ëŸ‰": quantity,
        "ê°€ê²©": price
    }
    
    # ìœ ì‚¬í•œ ê±°ë˜ë“¤ ì°¾ê¸°
    similar_trades = find_similar_trades(current_trade, csv_data)
    
    if not similar_trades:
        return {
            'message': 'ìœ ì‚¬í•œ ê³¼ê±° ê±°ë˜ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.',
            'similar_trades': []
        }
    
    # API í‚¤ê°€ ìˆìœ¼ë©´ AI ë¶„ì„ë„ ìˆ˜í–‰
    ai_analysis = None
    if check_api_key():
        # ìƒìœ„ 5ê°œ ê±°ë˜ë¡œ AI ë¶„ì„
        top_trades = similar_trades[:5]
        trades_summary = []
        
        for similar in top_trades:
            trade = similar['trade']
            trade_summary = {
                "ê±°ë˜ì¼": str(trade.get('ê±°ë˜ì¼ì‹œ', 'ë‚ ì§œ ì •ë³´ ì—†ìŒ')),
                "ì¢…ëª©": str(trade.get('ì¢…ëª©ëª…', '')),
                "ê±°ë˜êµ¬ë¶„": str(trade.get('ê±°ë˜êµ¬ë¶„', '')),
                "ê°ì •íƒœê·¸": str(trade.get('ê°ì •íƒœê·¸', '')),
                "ìˆ˜ìµë¥ ": float(trade.get('ìˆ˜ìµë¥ ', 0)),
                "ìœ ì‚¬ë„": f"{similar['similarity']*100:.1f}%"
            }
            trades_summary.append(trade_summary)
        
        messages = [
            {
                "role": "system",
                "content": """ë‹¹ì‹ ì€ íˆ¬ì ì‹¬ë¦¬ ë¶„ì„ ì „ë¬¸ AIì…ë‹ˆë‹¤. í˜„ì¬ ê±°ë˜ì™€ ìœ ì‚¬í•œ ê³¼ê±° ê±°ë˜ë“¤ì„ ë¶„ì„í•˜ì—¬ ê°„ë‹¨í•œ ì¡°ì–¸ì„ í•´ì£¼ì„¸ìš”."""
            },
            {
                "role": "user", 
                "content": f"""
í˜„ì¬ ê±°ë˜: {json.dumps(current_trade, ensure_ascii=False)}
ìœ ì‚¬í•œ ê³¼ê±° ê±°ë˜ë“¤: {json.dumps(trades_summary, ensure_ascii=False)}

ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ê°„ë‹¨í•œ íˆ¬ì ì¡°ì–¸ì„ í•´ì£¼ì„¸ìš”.
"""
            }
        ]
        
        ai_analysis = call_openai_api(messages)
    
    return {
        'similar_trades': similar_trades,
        'ai_analysis': ai_analysis
    }

class ReMinDKoreanEngine:
    """í•œêµ­ì–´ íˆ¬ì ì‹¬ë¦¬ ë¶„ì„ ì—”ì§„"""
    
    def __init__(self):
        # í•œêµ­ íˆ¬ìì í–‰ë™ íŒ¨í„´ ì •ì˜
        self.behavioral_patterns = {
            'ê³µí¬ë§¤ë„': ['ë¬´ì„œì›Œ', 'ê±±ì •', 'íŒ¨ë‹‰', 'í­ë½', 'ì†ì‹¤', 'ìœ„í—˜', 'ê¸‰ë½', 'í•˜ë½', 'ì†ì ˆ'],
            'ì¶”ê²©ë§¤ìˆ˜': ['ìƒí•œê°€', 'ê¸‰ë“±', 'ë†“ì¹˜ê¸°', 'ë’¤ëŠ¦ê²Œ', 'ì¶”ê²©', 'ëª¨ë‘ê°€', 'FOMO', 'fomo', 'ê¸‰íˆ', 'ìœ íŠœë²„', 'ì¶”ì²œ', 'ì»¤ë®¤ë‹ˆí‹°'],
            'ë³µìˆ˜ë§¤ë§¤': ['ë¶„í•˜ë‹¤', 'ë³´ë³µ', 'í™”ë‚˜ë‹¤', 'ì–µìš¸í•˜ë‹¤', 'íšŒë³µ', 'ë˜ì°¾ê¸°'],
            'ê³¼ì‹ ë§¤ë§¤': ['í™•ì‹ ', 'í‹€ë¦¼ì—†ë‹¤', 'ì‰¬ìš´ëˆ', 'í™•ì‹¤í•˜ë‹¤', 'ë³´ì¥', 'ë¬´ì¡°ê±´', 'ëŒ€ë°•', 'ì˜¬ì¸']
        }
    
    def analyze_emotion_text(self, text, user_type):
        """í•œêµ­ì–´ ê°ì • ë¶„ì„ í•¨ìˆ˜"""
        if not text or not isinstance(text, str):
            return {
                'pattern': 'ì¤‘ë¦½', 
                'confidence': 0.5, 
                'keywords': [],
                'description': 'ê°ì • íŒ¨í„´ì„ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
            }
        
        text_lower = text.lower()
        
        # í‚¤ì›Œë“œ ë§¤ì¹­
        found_keywords = []
        patterns_found = {}
        
        for pattern, keywords in self.behavioral_patterns.items():
            pattern_keywords = [kw for kw in keywords if kw in text_lower]
            if pattern_keywords:
                patterns_found[pattern] = len(pattern_keywords)
                found_keywords.extend(pattern_keywords)
        
        # ê°€ì¥ ë§ì´ ë§¤ì¹­ëœ íŒ¨í„´ ì„ íƒ
        if patterns_found:
            dominant_pattern = max(patterns_found, key=patterns_found.get)
            confidence = min(0.9, 0.6 + (patterns_found[dominant_pattern] * 0.1))
            
            descriptions = {
                'ê³µí¬ë§¤ë„': 'ì‹œì¥ í•˜ë½ì— ëŒ€í•œ ë‘ë ¤ì›€ìœ¼ë¡œ ì¸í•œ íŒ¨ë‹‰ ë§¤ë„ íŒ¨í„´',
                'ì¶”ê²©ë§¤ìˆ˜': 'FOMO(Fear of Missing Out)ì— ì˜í•œ ê³ ì  ë§¤ìˆ˜ íŒ¨í„´',
                'ë³µìˆ˜ë§¤ë§¤': 'ì†ì‹¤ íšŒë³µì„ ìœ„í•œ ê°ì •ì  ë³µìˆ˜ ê±°ë˜ íŒ¨í„´',
                'ê³¼ì‹ ë§¤ë§¤': 'ê³¼ë„í•œ ìì‹ ê°ìœ¼ë¡œ ì¸í•œ ë¬´ë¦¬í•œ íˆ¬ì íŒ¨í„´'
            }
            
            return {
                'pattern': dominant_pattern,
                'confidence': confidence,
                'keywords': found_keywords[:3],
                'description': descriptions.get(dominant_pattern, 'ì•Œ ìˆ˜ ì—†ëŠ” íŒ¨í„´')
            }
        
        return {
            'pattern': 'í•©ë¦¬ì íˆ¬ì',
            'confidence': 0.60,
            'keywords': [],
            'description': 'ë°ì´í„° ê¸°ë°˜ì˜ í•©ë¦¬ì  íˆ¬ì íŒ¨í„´'
        }
    
    def generate_investment_charter_rules(self, user_data, user_type):
        """ê°œì¸í™”ëœ íˆ¬ì í—Œì¥ ê·œì¹™ ìƒì„±"""
        rules = []
        
        if user_data.empty:
            return rules
        
        try:
            # ê°ì •ë³„ ì„±ê³¼ ë¶„ì„
            emotion_performance = user_data.groupby('ê°ì •íƒœê·¸')['ìˆ˜ìµë¥ '].agg(['mean', 'count']).reset_index()
            emotion_performance = emotion_performance[emotion_performance['count'] >= 3]
            
            # ì‚¬ìš©ì ìœ í˜•ì— ë”°ë¼ ë‹¤ë¥¸ ê·œì¹™ ìƒì„±
            if user_type == "ê¹€êµ­ë¯¼":
                # ê¹€êµ­ë¯¼ì€ ê³µí¬ë§¤ë„ ê´€ë ¨ ê·œì¹™ ì¶”ê°€
                fear_emotions = ['#ê³µí¬', '#íŒ¨ë‹‰', '#ë¶ˆì•ˆ']
                fear_trades = emotion_performance[emotion_performance['ê°ì •íƒœê·¸'].isin(fear_emotions)]
                
                if not fear_trades.empty and fear_trades['mean'].mean() < -5:
                    rules.append({
                        'rule': "ê³µí¬ ìƒíƒœ(#ê³µí¬, #íŒ¨ë‹‰, #ë¶ˆì•ˆ)ì¼ ë•ŒëŠ” 24ì‹œê°„ ë™ì•ˆ íˆ¬ì ê²°ì • ë³´ë¥˜",
                        'rationale': f"ë°ì´í„° ë¶„ì„ ê²°ê³¼, ê³µí¬ ìƒíƒœì˜ ê±°ë˜ì—ì„œ í‰ê·  {abs(fear_trades['mean'].mean()):.1f}% ì†ì‹¤ ë°œìƒ",
                        'evidence': f"{int(fear_trades['count'].sum())}íšŒ ê±°ë˜ ë¶„ì„ ê²°ê³¼",
                        'category': 'ê°ì • ê´€ë¦¬'
                    })
            else:
                # ë°•íˆ¬ìëŠ” ì¶”ê²©ë§¤ìˆ˜ ê´€ë ¨ ê·œì¹™ ì¶”ê°€
                chase_emotions = ['#ì¶”ê²©ë§¤ìˆ˜', '#ìš•ì‹¬']
                chase_trades = emotion_performance[emotion_performance['ê°ì •íƒœê·¸'].isin(chase_emotions)]
                
                if not chase_trades.empty and chase_trades['mean'].mean() < -5:
                    rules.append({
                        'rule': "ê¸‰ë“± ì¢…ëª©ì„ ì¶”ê²© ë§¤ìˆ˜í•˜ê¸° ì „ì— 3ì¼ê°„ì˜ ëƒ‰ê°ê¸°ê°„ ê°–ê¸°",
                        'rationale': f"ë°ì´í„° ë¶„ì„ ê²°ê³¼, ì¶”ê²©ë§¤ìˆ˜ì˜ í‰ê·  ìˆ˜ìµë¥ ì€ {chase_trades['mean'].mean():.1f}%ë¡œ ì €ì¡°í•¨",
                        'evidence': f"{int(chase_trades['count'].sum())}íšŒ ê±°ë˜ ë¶„ì„ ê²°ê³¼",
                        'category': 'íˆ¬ì ì „ëµ'
                    })
            
            # ì¼ë°˜ì ì¸ ê·œì¹™ë“¤
            for _, row in emotion_performance.iterrows():
                if row['mean'] < -8 and row['count'] >= 3:
                    emotion = str(row['ê°ì •íƒœê·¸']).replace('#', '')
                    rules.append({
                        'rule': f"{emotion} ìƒíƒœì¼ ë•ŒëŠ” íˆ¬ì ê²°ì •ì„ í•˜ì§€ ì•Šê¸°",
                        'rationale': f"ë°ì´í„° ë¶„ì„ ê²°ê³¼, {emotion} ìƒíƒœì˜ ê±°ë˜ì—ì„œ í‰ê·  {abs(row['mean']):.1f}% ì†ì‹¤ ë°œìƒ",
                        'evidence': f"{int(row['count'])}íšŒ ê±°ë˜ ë¶„ì„ ê²°ê³¼",
                        'category': 'ê°ì • ê´€ë¦¬'
                    })
        
        except Exception as e:
            st.error(f"íˆ¬ì í—Œì¥ ê·œì¹™ ìƒì„± ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return []
        
        return rules

    def extract_principles_from_notes(self, user_data):
        """ì˜¤ë‹µë…¸íŠ¸ì—ì„œ íˆ¬ì ì›ì¹™ ì¶”ì¶œ"""
        principles = []
        
        if user_data.empty:
            return principles
        
        try:
            # ì†ì‹¤ ê±°ë˜ ë¶„ì„
            losing_trades = user_data[user_data['ìˆ˜ìµë¥ '] < -10]  # 10% ì´ìƒ ì†ì‹¤
            
            if len(losing_trades) > 0:
                # ê°ì •ë³„ ì†ì‹¤ íŒ¨í„´ ë¶„ì„
                emotion_losses = losing_trades.groupby('ê°ì •íƒœê·¸')['ìˆ˜ìµë¥ '].agg(['mean', 'count'])
                
                for emotion, data in emotion_losses.iterrows():
                    if data['count'] >= 2:  # 2íšŒ ì´ìƒ ë°˜ë³µëœ íŒ¨í„´
                        avg_loss = abs(data['mean'])
                        count = int(data['count'])
                        
                        principle = {
                            'title': f"{emotion} ê°ì • ìƒíƒœ ê±°ë˜ ê¸ˆì§€",
                            'description': f"{emotion} ìƒíƒœì—ì„œ {count}íšŒ ê±°ë˜í•˜ì—¬ í‰ê·  {avg_loss:.1f}% ì†ì‹¤ ë°œìƒ",
                            'rule': f"{emotion} ê°ì •ì´ ê°ì§€ë˜ë©´ 24ì‹œê°„ ê±°ë˜ ê¸ˆì§€",
                            'evidence_count': count,
                            'avg_impact': avg_loss
                        }
                        principles.append(principle)
            
            # ì‹œê°„ëŒ€ë³„ íŒ¨í„´ ë¶„ì„ (ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ëŠ” ê²½ìš°ì—ë§Œ)
            if 'ê±°ë˜ì¼ì‹œ' in user_data.columns:
                try:
                    user_data_copy = user_data.copy()
                    user_data_copy['ê±°ë˜ì‹œê°„'] = pd.to_datetime(user_data_copy['ê±°ë˜ì¼ì‹œ']).dt.hour
                    hourly_performance = user_data_copy.groupby('ê±°ë˜ì‹œê°„')['ìˆ˜ìµë¥ '].mean()
                    
                    worst_hours = hourly_performance[hourly_performance < -5].index.tolist()
                    if worst_hours:
                        principle = {
                            'title': f"íŠ¹ì • ì‹œê°„ëŒ€ ê±°ë˜ ìì œ",
                            'description': f"{worst_hours}ì‹œ ê±°ë˜ì—ì„œ ì†ì‹¤ë¥ ì´ ë†’ìŒ",
                            'rule': f"{worst_hours}ì‹œì—ëŠ” ê±°ë˜ ìì œí•˜ê³  í•œë²ˆ ë” ìƒê°í•˜ê¸°",
                            'evidence_count': len(worst_hours),
                            'avg_impact': abs(hourly_performance[hourly_performance < -5].mean())
                        }
                        principles.append(principle)
                except Exception:
                    # ì‹œê°„ëŒ€ ë¶„ì„ì—ì„œ ì˜¤ë¥˜ ë°œìƒ ì‹œ ë¬´ì‹œ
                    pass
        
        except Exception as e:
            st.error(f"íˆ¬ì ì›ì¹™ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            return []
        
        return principles

def generate_ai_coaching_tip(user_data, user_type):
    """ì˜¤ëŠ˜ì˜ AI ì½”ì¹­ íŒ ìƒì„±"""
    try:
        if user_data.empty:
            return "ğŸ“Š ê±°ë˜ ë°ì´í„°ë¥¼ ì¶•ì í•˜ì—¬ ê°œì¸í™”ëœ ì½”ì¹­ì„ ë°›ì•„ë³´ì„¸ìš”."
        
        recent_trades = user_data.tail(5)
        
        # ë¹ˆ ë°ì´í„°í”„ë ˆì„ì¸ ê²½ìš° ì²˜ë¦¬
        if recent_trades.empty:
            return "ğŸ“Š ê±°ë˜ ë°ì´í„°ë¥¼ ì¶•ì í•˜ì—¬ ê°œì¸í™”ëœ ì½”ì¹­ì„ ë°›ì•„ë³´ì„¸ìš”."
        
        # ê°ì •íƒœê·¸ê°€ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        if 'ê°ì •íƒœê·¸' not in recent_trades.columns:
            return "ğŸ“Š ê±°ë˜ ë°ì´í„°ì— ê°ì • ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤. ë” ìì„¸í•œ ë°ì´í„°ë¥¼ ì…ë ¥í•´ì£¼ì„¸ìš”."
        
        recent_emotions = recent_trades['ê°ì •íƒœê·¸'].value_counts()
        
        # ìˆ˜ìµë¥  ì»¬ëŸ¼ì´ ì¡´ì¬í•˜ëŠ”ì§€ í™•ì¸
        if 'ìˆ˜ìµë¥ ' in recent_trades.columns:
            avg_recent_return = recent_trades['ìˆ˜ìµë¥ '].mean()
        else:
            avg_recent_return = 0
        
        if user_type == "ê¹€êµ­ë¯¼":
            if '#ê³µí¬' in recent_emotions.index or '#íŒ¨ë‹‰' in recent_emotions.index:
                return "âš ï¸ ìµœê·¼ ê³µí¬/íŒ¨ë‹‰ ê±°ë˜ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ì˜¤ëŠ˜ì€ ì‹œì¥ì„ ê´€ì°°í•˜ê³  24ì‹œê°„ í›„ ì¬ê²€í† í•˜ì„¸ìš”."
            elif avg_recent_return < -5:
                return "ğŸ’¡ ìµœê·¼ ìˆ˜ìµë¥ ì´ ì €ì¡°í•©ë‹ˆë‹¤. ê°ì •ì  íŒë‹¨ë³´ë‹¤ëŠ” ë°ì´í„° ê¸°ë°˜ ë¶„ì„ì— ì§‘ì¤‘í•´ë³´ì„¸ìš”."
            else:
                return "âœ… ìµœê·¼ ê±°ë˜ íŒ¨í„´ì´ ì•ˆì •ì ì…ë‹ˆë‹¤. í˜„ì¬ì˜ ì‹ ì¤‘í•œ ì ‘ê·¼ì„ ìœ ì§€í•˜ì„¸ìš”."
        else:  # ë°•íˆ¬ì
            if '#ì¶”ê²©ë§¤ìˆ˜' in recent_emotions.index or '#ìš•ì‹¬' in recent_emotions.index:
                return "âš ï¸ ìµœê·¼ ì¶”ê²©ë§¤ìˆ˜ íŒ¨í„´ì´ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ì˜¤ëŠ˜ì€ FOMOë¥¼ ê²½ê³„í•˜ê³  ëƒ‰ì •í•œ íŒë‹¨ì„ í•˜ì„¸ìš”."
            elif avg_recent_return < -5:
                return "ğŸ’¡ ìµœê·¼ ìˆ˜ìµë¥ ì´ ì €ì¡°í•©ë‹ˆë‹¤. ì™¸ë¶€ ì¶”ì²œë³´ë‹¤ëŠ” ë³¸ì¸ë§Œì˜ íˆ¬ì ì›ì¹™ì„ ì„¸ì›Œë³´ì„¸ìš”."
            else:
                return "âœ… ìµœê·¼ ê±°ë˜ê°€ ê°œì„ ë˜ê³  ìˆìŠµë‹ˆë‹¤. í˜„ì¬ì˜ ì‹ ì¤‘í•œ ì ‘ê·¼ì„ ê³„ì† ìœ ì§€í•˜ì„¸ìš”."
    
    except Exception as e:
        return f"ğŸ’¡ AI ì½”ì¹­ íŒ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"