# ai_service.py - AI ë¶„ì„ ì—”ì§„ (ìµœì¢… ì •ë¦¬)
"""
Re:Mind 3.1 - Gemini AI ê¸°ë°˜ íˆ¬ì ì‹¬ë¦¬ ë¶„ì„ ì„œë¹„ìŠ¤
í•µì‹¬ ê¸°ëŠ¥: íˆ¬ììì˜ ê³¼ê±° ê±°ë˜ íŒ¨í„´ì„ AIê°€ ë¶„ì„í•˜ì—¬ ë§ì¶¤í˜• ì¡°ì–¸ ì œê³µ
"""

import json
import streamlit as st
import pandas as pd
import numpy as np
from datetime import datetime
import re
from typing import List, Dict, Any, Optional
import pickle
import hashlib

# === Gemini API ì—°ë™ ë° ê¸°ë³¸ ì„¤ì • ===
try:
    import google.generativeai as genai
    GEMINI_AVAILABLE = True
except ImportError:
    GEMINI_AVAILABLE = False

try:
    from sklearn.feature_extraction.text import TfidfVectorizer
    from sklearn.metrics.pairwise import cosine_similarity
    SKLEARN_AVAILABLE = True
except ImportError:
    SKLEARN_AVAILABLE = False

# === API ì—°ê²° ê´€ë¦¬ í•¨ìˆ˜ë“¤ ===
def check_gemini_api():
    """Gemini API ì—°ê²° ìƒíƒœ í™•ì¸"""
    return GEMINI_AVAILABLE and hasattr(st.session_state, 'gemini_api_key') and bool(st.session_state.gemini_api_key)

def setup_gemini_api():
    """Gemini API ì´ˆê¸°í™”"""
    if not GEMINI_AVAILABLE:
        return False
    if hasattr(st.session_state, 'gemini_api_key') and st.session_state.gemini_api_key:
        try:
            genai.configure(api_key=st.session_state.gemini_api_key)
            return True
        except Exception as e:
            st.error(f"Gemini API ì„¤ì • ì˜¤ë¥˜: {str(e)}")
            return False
    return False

def test_gemini_connection():
    """API ì—°ê²° í…ŒìŠ¤íŠ¸"""
    if not check_gemini_api() or not setup_gemini_api():
        return False
    try:
        model = genai.GenerativeModel('gemini-1.5-flash')
        response = model.generate_content("ì•ˆë…•í•˜ì„¸ìš”. ì—°ê²° í…ŒìŠ¤íŠ¸ì…ë‹ˆë‹¤.")
        return bool(response.text)
    except Exception as e:
        st.error(f"Gemini ì—°ê²° í…ŒìŠ¤íŠ¸ ì‹¤íŒ¨: {str(e)}")
        return False

# === í•µì‹¬ ê¸°ëŠ¥ 1: ì„±ê³µ ê±°ë˜ ì›ì¹™ ì¶”ì¶œ ===
def get_ai_success_principle(trade_data: dict, success_note: str, user_type: str) -> dict:
    """ì„±ê³µ ê±°ë˜ì—ì„œ ì¬ì‚¬ìš© ê°€ëŠ¥í•œ íˆ¬ì ì›ì¹™ì„ AIê°€ ì¶”ì¶œ"""
    if not check_gemini_api() or not setup_gemini_api():
        return {'success': False, 'message': 'Gemini APIê°€ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'}
    
    try:
        # ê±°ë˜ ì •ë³´ ìš”ì•½
        trade_info = f"""
        - ì¢…ëª©: {trade_data.get('ì¢…ëª©ëª…', '')}, ê±°ë˜êµ¬ë¶„: {trade_data.get('ê±°ë˜êµ¬ë¶„', '')}
        - ìˆ˜ìµë¥ : +{trade_data.get('ìˆ˜ìµë¥ ', 0):.1f}%"""
        
        # ì‚¬ìš©ì ìœ í˜•ë³„ ë§ì¶¤ ë¶„ì„ ë°©í–¥ ì„¤ì •
        focus = "ë³´ìˆ˜ì  íˆ¬ììì˜ ì„±ê³µ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ ì‹ ì¤‘í•˜ê³  ì•ˆì •ì ì¸ íˆ¬ì ì›ì¹™ì„" if user_type == "ê¹€êµ­ë¯¼" else "ì ê·¹ì  íˆ¬ììì˜ ì„±ê³µ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ ê¸°íšŒ í¬ì°©ê³¼ ë¦¬ìŠ¤í¬ ê´€ë¦¬ë¥¼ ê· í˜• ì¡ì€ íˆ¬ì ì›ì¹™ì„"
        
        # AI ë¶„ì„ ìš”ì²­ í”„ë¡¬í”„íŠ¸
        prompt = f"""
        ë‹¹ì‹ ì€ ì „ë¬¸ íˆ¬ì ë¶„ì„ê°€ì…ë‹ˆë‹¤. {user_type} íˆ¬ììì˜ ì„±ê³µí•œ ê±°ë˜ ê²½í—˜ì„ ë¶„ì„í•˜ì—¬ ì¬ì‚¬ìš© ê°€ëŠ¥í•œ íˆ¬ì ì›ì¹™ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”.
        {trade_info}
        ì‚¬ìš©ìì˜ ì„±ê³µë…¸íŠ¸: "{success_note}"
        {focus} ë‹¤ìŒ í˜•ì‹ì˜ JSONìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:
        {{
            "principle": "ë‹¤ë¥¸ íˆ¬ìì—ë„ ì ìš© ê°€ëŠ¥í•œ ì¼ë°˜í™”ëœ ì„±ê³µ ì›ì¹™ í•œ ë¬¸ì¥",
            "analysis": {{
                "success_factor": "ì´ ê±°ë˜ê°€ ì„±ê³µí•œ í•µì‹¬ ìš”ì¸",
                "reproducibility": "ì´ ì„±ê³µ íŒ¨í„´ì˜ ì¬í˜„ ê°€ëŠ¥ì„± (ë†’ìŒ/ë³´í†µ/ë‚®ìŒ)",
                "insights": {{"strengths": ["ì˜í•œ ì ë“¤"], "lessons": ["ë‹¤ë¥¸ íˆ¬ìì— ì ìš©í•  ìˆ˜ ìˆëŠ” êµí›ˆë“¤"]}},
                "coaching_advice": "í–¥í›„ íˆ¬ì ì¡°ì–¸ (3-4ë¬¸ì¥)"
            }}
        }}"""
        
        # Gemini AI í˜¸ì¶œ
        model = genai.GenerativeModel('gemini-1.5-flash')
        response = model.generate_content(prompt)
        response_text = response.text.strip()
        
        # JSON íŒŒì‹±
        if response_text.startswith('```json'):
            response_text = response_text[7:-3]
        analysis_result = json.loads(response_text)
        
        return {
            'success': True, 
            'principle': analysis_result.get('principle', ''), 
            'analysis': analysis_result.get('analysis', {}), 
            'raw_response': response.text
        }
    except Exception as e:
        return {'success': False, 'message': f'ì„±ê³µ ì›ì¹™ ì¶”ì¶œ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'}

# === í•µì‹¬ ê¸°ëŠ¥ 2: ìœ ì‚¬ ê±°ë˜ ì„ ë³„ ë° AI ë¶„ì„ ===
# ai_service.py íŒŒì¼ì˜ gemini_select_and_analyze_trades í•¨ìˆ˜ë¥¼ ì´ ì½”ë“œë¡œ ì™„ì „íˆ êµì²´í•˜ì„¸ìš”.

def gemini_select_and_analyze_trades(current_trade: dict, user_data: pd.DataFrame, user_type: str) -> dict:
    """ [ìµœì¢… ìˆ˜ì •] ë°ì´í„° ì¤€ë¹„ ê³¼ì •ì„ í¬í•¨í•˜ê³ , ì½”ì‚¬ì¸ ìœ ì‚¬ë„ë¡œ 'ì„ íƒ' í›„ AIë¡œ 'ë¶„ì„'í•˜ì—¬ ì˜¤ë¥˜ë¥¼ í•´ê²°í•œ í•¨ìˆ˜ """
    if not check_gemini_api() or not setup_gemini_api():
        return {'method': 'error', 'analysis': 'Gemini APIê°€ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'}
    if user_data.empty:
        return {'method': 'error', 'analysis': 'ë¶„ì„í•  ê³¼ê±° ê±°ë˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.'}

    try:
        # --- [í•´ê²°ì±… 1] AI ë¶„ì„ ì „, ê³¼ê±° ê±°ë˜ ë°ì´í„°ì— ì„ë² ë”©ì„ ì¤€ë¹„í•˜ëŠ” ê³¼ì • ì¶”ê°€ ---
        # ì´ í•¨ìˆ˜ëŠ” ì„ë² ë”©ì´ ì—†ìœ¼ë©´ ìƒì„±í•˜ê³ , ì´ë¯¸ ìˆìœ¼ë©´ ê·¸ëŒ€ë¡œ ì‚¬ìš©í•˜ë¯€ë¡œ ì•ˆì „í•©ë‹ˆë‹¤.
        st.info("AI ë¶„ì„ì„ ìœ„í•´ ê³¼ê±° ê±°ë˜ ë°ì´í„°ë¥¼ ì¤€ë¹„í•©ë‹ˆë‹¤...")
        processed_user_data = preprocess_embeddings_cache(user_data, user_type)
        st.info("ë°ì´í„° ì¤€ë¹„ ì™„ë£Œ. ìœ ì‚¬ ê±°ë˜ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤.")


        # --- 1. ì„ íƒ (Selection using Cosine Similarity) ---
        current_trade_text = generate_text_for_embedding(pd.Series(current_trade))
        # ì¤€ë¹„ëœ ë°ì´í„°ë¥¼ ì‚¬ìš©í•˜ì—¬ ìœ ì‚¬ ê±°ë˜ë¥¼ ì°¾ìŠµë‹ˆë‹¤.
        similar_trades_info = find_similar_experiences_ai(current_trade_text, processed_user_data, top_k=3)

        if not similar_trades_info:
            return {'method': 'error', 'analysis': 'ìœ ì‚¬í•œ ê³¼ê±° ê±°ë˜ë¥¼ ì°¾ì§€ ëª»í–ˆìŠµë‹ˆë‹¤.'}

        # original_indexëŠ” preprocess_embeddings_cacheë¥¼ ê±°ì³ë„ ìœ ì§€ë©ë‹ˆë‹¤.
        selected_indices = [trade['trade_data']['original_index'] for trade in similar_trades_info]
        selected_trades_df = processed_user_data.loc[selected_indices]

        # --- 2. ë¶„ì„ (Analysis using Gemini AI) ---

        # [í•´ê²°ì±… 2] AIì—ê²Œ ë¶„ì„ì„ ìš”ì²­í•˜ê¸° ì „, ë¶ˆí•„ìš”í•œ 'embedding' ì»¬ëŸ¼ì„ í™•ì‹¤í•˜ê²Œ ì œê±°í•©ë‹ˆë‹¤.
        selected_trades_for_analysis = selected_trades_df.copy()
        if 'embedding' in selected_trades_for_analysis.columns:
            selected_trades_for_analysis = selected_trades_for_analysis.drop(columns=['embedding'])
        
        selected_trades_json = selected_trades_for_analysis.to_json(orient='records', indent=2, force_ascii=False)

        prompt = f"""
        ë‹¹ì‹ ì€ ì „ë¬¸ íˆ¬ì ë¶„ì„ê°€ì…ë‹ˆë‹¤. {user_type} íˆ¬ììì˜ 'í˜„ì¬ ê±°ë˜ ê³„íš'ê³¼ ì•„ë˜ ì œì‹œëœ 'ê°€ì¥ ìœ ì‚¬í•œ ê³¼ê±° ê±°ë˜ 3ê°œ'ì˜ ì™„ì „í•œ ë°ì´í„°ë¥¼ ë¹„êµ ë¶„ì„í•´ì£¼ì„¸ìš”.

        [í˜„ì¬ ê±°ë˜ ê³„íš]
        {current_trade_text}

        [ê°€ì¥ ìœ ì‚¬í•œ ê³¼ê±° ê±°ë˜ 3ê°œ (JSON í˜•ì‹)]
        {selected_trades_json}

        [ë¶„ì„ ì§€ì‹œ]
        ì œì‹œëœ 3ê°œì˜ ìœ ì‚¬ ê±°ë˜ ë°ì´í„°ë§Œì„ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ í•­ëª©ë“¤ì„ ë¶„ì„í•˜ì—¬ JSON í˜•ì‹ìœ¼ë¡œ ì‘ë‹µí•´ì£¼ì„¸ìš”.
        {{
            "pattern_analysis": "ì„ íƒëœ 3ê°œ ê±°ë˜ì˜ ê³µí†µì ì¸ ì„±ê³µ/ì‹¤íŒ¨ íŒ¨í„´ ìš”ì•½",
            "risk_assessment": "ê³¼ê±° íŒ¨í„´ì„ ë°”íƒ•ìœ¼ë¡œ í•œ í˜„ì¬ ê±°ë˜ì˜ ìœ„í—˜ë„ í‰ê°€ (ë†’ìŒ/ë³´í†µ/ë‚®ìŒ) ë° ê·¼ê±°",
            "recommendation": "ìœ„í—˜ë„ì™€ íŒ¨í„´ì„ ì¢…í•©í•˜ì—¬ ë‚´ë¦¬ëŠ” ìµœì¢… ê¶Œê³ ì‚¬í•­",
            "alternative_strategy": "í˜„ì¬ ê±°ë˜ì— ëŒ€í•œ ëŒ€ì•ˆ ì „ëµ ì œì•ˆ"
        }}
        """
        model = genai.GenerativeModel('gemini-1.5-flash')
        response = model.generate_content(prompt)
        response_text = response.text.strip()
        if response_text.startswith('```json'):
            response_text = response_text[7:-3]
        
        ai_analysis_json = json.loads(response_text)

        return {
            'method': 'cosine_selection_and_gemini_analysis',
            'selected_trades': selected_trades_df.to_dict(orient='records'),
            'ai_analysis': ai_analysis_json
        }
    except Exception as e:
        return {'method': 'error', 'analysis': f'AI ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'}
# === í•µì‹¬ ê¸°ëŠ¥ 3: ê±°ë˜ ë³µê¸° ë¶„ì„ ===
def analyze_trade_reflection(trade_data: dict, reflection_text: str, user_type: str) -> dict:
    """ë§¤ìˆ˜/ë§¤ë„ ëª¨ë“  ê±°ë˜ì˜ ë³µê¸° ë¶„ì„ (ì„±ê³µ/ì‹¤íŒ¨ ë¬´ê´€)"""
    if not check_gemini_api() or not setup_gemini_api():
        return {'success': False, 'message': 'Gemini APIê°€ ì—°ê²°ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.'}
    
    try:
        # ê±°ë˜ ì •ë³´ ìš”ì•½
        trade_type = trade_data.get('ê±°ë˜êµ¬ë¶„', '')
        trade_info = f"""
        ê±°ë˜ ì •ë³´:
        - ì¢…ëª©: {trade_data.get('ì¢…ëª©ëª…', '')}, ê±°ë˜êµ¬ë¶„: {trade_type}
        - ìˆ˜ìµë¥ : {trade_data.get('ìˆ˜ìµë¥ ', 0):.1f}%"""
        
        # ì‚¬ìš©ì ìœ í˜•ë³„ ë¶„ì„ ê´€ì  ì„¤ì •
        focus = "ë³´ìˆ˜ì  íˆ¬ì ê´€ì ì—ì„œ" if user_type == "ê¹€êµ­ë¯¼" else "FOMO ë§¤ìˆ˜ íŒ¨í„´ê³¼ ì ê·¹ì  íˆ¬ì ê´€ì ì—ì„œ"
        
        # AI ë³µê¸° ë¶„ì„ ìš”ì²­
        prompt = f"""
        ë‹¹ì‹ ì€ ì „ë¬¸ íˆ¬ì ì‹¬ë¦¬ ë¶„ì„ê°€ì…ë‹ˆë‹¤. {user_type} íˆ¬ììì˜ ê±°ë˜ ë³µê¸°ë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.
        {trade_info}
        ì‚¬ìš©ìì˜ ë³µê¸° ë‚´ìš©: "{reflection_text}"
        {focus} ë‹¤ìŒ í˜•ì‹ì˜ JSONìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:
        {{
            "emotion_analysis": {{ "primary_emotion": "ì£¼ìš” ê°ì •", "emotion_intensity": 5, "emotion_keywords": [] }},
            "pattern_recognition": {{ "trading_pattern": "ê±°ë˜ íŒ¨í„´ ë¶„ë¥˜", "confidence": 0.8, "pattern_description": "íŒ¨í„´ ì„¤ëª…" }},
            "insights": {{ "strengths": ["ì˜í•œ ì "], "weaknesses": ["ê°œì„ ì "], "lessons": ["í•µì‹¬ êµí›ˆ"] }},
            "ai_hashtags": ["#í•´ì‹œíƒœê·¸"],
            "coaching_advice": "ê°œì¸í™”ëœ ì¡°ì–¸"
        }}"""
        
        model = genai.GenerativeModel('gemini-1.5-flash')
        response = model.generate_content(prompt)
        response_text = response.text.strip()
        if response_text.startswith('```json'):
            response_text = response_text[7:-3]
        analysis_result = json.loads(response_text)
        
        return {'success': True, 'analysis': analysis_result, 'raw_response': response.text}
    except Exception as e:
        return {'success': False, 'message': f'ë¶„ì„ ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}'}

# === ì„ë² ë”© ë° ìœ ì‚¬ë„ ê³„ì‚° í•¨ìˆ˜ë“¤ ===
def create_embedding(text: str) -> Optional[List[float]]:
    """í…ìŠ¤íŠ¸ë¥¼ Gemini ì„ë² ë”©ìœ¼ë¡œ ë²¡í„°í™”"""
    if not check_gemini_api() or not setup_gemini_api():
        return None
    
    try:
        result = genai.embed_content(
            model="models/text-embedding-004",
            content=[text],
            task_type="semantic_similarity"
        )
        return result['embedding'][0] if result['embedding'] else None
    except Exception as e:
        st.error(f"ì„ë² ë”© ìƒì„± ì˜¤ë¥˜: {str(e)}")
        return None

def create_embeddings_batch(texts: List[str], batch_size: int = 100) -> Optional[List[List[float]]]:
    """í…ìŠ¤íŠ¸ ëª©ë¡ì„ ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì„ë² ë”© ìƒì„±"""
    if not texts or not check_gemini_api() or not setup_gemini_api():
        return None
    
    all_embeddings = []
    for i in range(0, len(texts), batch_size):
        batch_texts = texts[i:i + batch_size]
        try:
            result = genai.embed_content(
                model="models/text-embedding-004",
                content=batch_texts,
                task_type="semantic_similarity"
            )
            if result and 'embedding' in result:
                all_embeddings.extend(result['embedding'])
        except Exception as e:
            st.error(f"ë°°ì¹˜ ì„ë² ë”© ìƒì„± ì˜¤ë¥˜: {str(e)}")
            all_embeddings.extend([None] * len(batch_texts))
    
    return all_embeddings if all_embeddings else None

def generate_text_for_embedding(trade_row: pd.Series) -> str:
    """ê±°ë˜ ë°ì´í„°ë¥¼ ì„ë² ë”©ìš© í…ìŠ¤íŠ¸ë¡œ ë³€í™˜"""
    parts = []
    
    # í•„ìˆ˜ ì •ë³´ ì¶”ì¶œ
    if 'ì¢…ëª©ëª…' in trade_row and pd.notna(trade_row['ì¢…ëª©ëª…']):
        parts.append(f"ì¢…ëª©: {trade_row['ì¢…ëª©ëª…']}")
    if 'ê±°ë˜êµ¬ë¶„' in trade_row and pd.notna(trade_row['ê±°ë˜êµ¬ë¶„']):
        parts.append(f"ê±°ë˜: {trade_row['ê±°ë˜êµ¬ë¶„']}")
    if 'ê°ì •íƒœê·¸' in trade_row and pd.notna(trade_row['ê°ì •íƒœê·¸']):
        parts.append(f"ê°ì •: {trade_row['ê°ì •íƒœê·¸']}")
    if 'ë©”ëª¨' in trade_row and pd.notna(trade_row['ë©”ëª¨']):
        memo = str(trade_row['ë©”ëª¨']).strip()
        if memo:
            parts.append(f"ë©”ëª¨: {memo}")
    
    # ë¶„ì„ ì •ë³´ ì¶”ê°€
    for col in ['ê¸°ìˆ ë¶„ì„', 'ë‰´ìŠ¤ë¶„ì„', 'ê°ì •ë¶„ì„']:
        if col in trade_row and pd.notna(trade_row[col]):
            content = str(trade_row[col]).strip()
            if content:
                parts.append(f"{col}: {content}")
    
    # ìˆ˜ìµë¥  ì •ë³´
    if 'ìˆ˜ìµë¥ ' in trade_row and pd.notna(trade_row['ìˆ˜ìµë¥ ']):
        profit = float(trade_row['ìˆ˜ìµë¥ '])
        if profit > 0:
            parts.append(f"ìˆ˜ìµ: +{profit:.1f}%")
        elif profit < 0:
            parts.append(f"ì†ì‹¤: {profit:.1f}%")
    
    return " | ".join(parts) if parts else "ê±°ë˜ ì •ë³´ ì—†ìŒ"

# ai_service.py íŒŒì¼ì˜ ê¸°ì¡´ preprocess_embeddings_cache í•¨ìˆ˜ë¥¼ ì´ ì½”ë“œë¡œ êµì²´í•˜ì„¸ìš”.

@st.cache_data(ttl=3600, show_spinner=False)  # 1ì‹œê°„ ìºì‹œ
def preprocess_embeddings_cache(user_data: pd.DataFrame, user_id: str) -> pd.DataFrame:
    """
    [Robust Version] ê±°ë˜ ë°ì´í„°ì— ëŒ€í•œ ì„ë² ë”©ì„ ë¯¸ë¦¬ ìƒì„±í•˜ê³  ìºì‹œí•˜ë©°, ì¸ë±ìŠ¤ ì •ë ¬ì„ ë³´ì¥í•©ë‹ˆë‹¤.
    """
    if user_data.empty:
        return user_data

    # ì›ë³¸ ë°ì´í„°í”„ë ˆì„ ìˆ˜ì •ì„ í”¼í•˜ê¸° ìœ„í•´ ë³µì‚¬ë³¸ìœ¼ë¡œ ì‘ì—…í•©ë‹ˆë‹¤.
    df = user_data.copy()
    # ë‚˜ì¤‘ì— ì›ë˜ ì¸ë±ìŠ¤ë¥¼ ì°¸ì¡°í•  ìˆ˜ ìˆë„ë¡ ë³´ì¡´í•©ë‹ˆë‹¤.
    if 'original_index' not in df.columns:
        df['original_index'] = df.index

    if 'embedding' not in df.columns:
        df['embedding'] = None

    # ì„ë² ë”©ì´ í•„ìš”í•œ í–‰ì„ ì°¾ìŠµë‹ˆë‹¤ (nullì´ê±°ë‚˜, ë¦¬ìŠ¤íŠ¸ê°€ ì•„ë‹ˆê±°ë‚˜, ë¹ˆ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš°).
    needs_embedding_mask = df['embedding'].apply(lambda x: not isinstance(x, list) or len(x) == 0)
    needs_embedding = df[needs_embedding_mask]

    if needs_embedding.empty:
        return df

    if check_gemini_api():
        progress_container = st.container()
        with progress_container:
            st.info(f"ğŸ’¾ AI ë¶„ì„ ì¤€ë¹„ ì¤‘: {len(needs_embedding)}ê°œ ê±°ë˜ ë°ì´í„°ì˜ ì„ë² ë”©ì„ ìƒì„±í•©ë‹ˆë‹¤...")
            progress_bar = st.progress(0)
            st.session_state.embedding_progress = progress_bar

        texts_to_embed = [generate_text_for_embedding(row) for _, row in needs_embedding.iterrows()]

        embeddings = create_embeddings_batch(texts_to_embed)

        # [í•µì‹¬ ìˆ˜ì •] ìƒì„±ëœ ì„ë² ë”©ì˜ ê¸¸ì´ì™€ í•„ìš”í•œ ì„ë² ë”©ì˜ ê¸¸ì´ê°€ ê°™ì€ì§€ í™•ì¸í•©ë‹ˆë‹¤.
        if embeddings and len(embeddings) == len(needs_embedding):
            # [ì˜¤ë¥˜ í•´ê²°] ì„ë² ë”© ë¦¬ìŠ¤íŠ¸ë¡œ pandas Seriesë¥¼ ìƒì„±í•©ë‹ˆë‹¤.
            # ì´ë ‡ê²Œ í•˜ë©´ ìƒˆë¡œìš´ ë°ì´í„°ì˜ ì¸ë±ìŠ¤ê°€ ì—…ë°ì´íŠ¸í•˜ë ¤ëŠ” ë°ì´í„°í”„ë ˆì„ì˜ ì¸ë±ìŠ¤ì™€ ì™„ë²½í•˜ê²Œ ì •ë ¬ë©ë‹ˆë‹¤.
            embedding_series = pd.Series(embeddings, index=needs_embedding.index)

            # Seriesë¥¼ 'embedding' ì—´ì— í• ë‹¹í•©ë‹ˆë‹¤. ì´ ë°©ì‹ì´ ë¦¬ìŠ¤íŠ¸ë¥¼ ì§ì ‘ í• ë‹¹í•˜ëŠ” ê²ƒë³´ë‹¤ ì•ˆì „í•©ë‹ˆë‹¤.
            df.loc[needs_embedding.index, 'embedding'] = embedding_series
            progress_container.success(f"âœ… {len(needs_embedding)}ê°œ ì„ë² ë”© ìƒì„± ì™„ë£Œ!")
        else:
            # create_embeddings_batchê°€ Noneì„ ë°˜í™˜í•˜ê±°ë‚˜ ê¸¸ì´ê°€ ë‹¤ë¥¸ ë¦¬ìŠ¤íŠ¸ë¥¼ ë°˜í™˜í•˜ëŠ” ê²½ìš°ë¥¼ ì²˜ë¦¬í•©ë‹ˆë‹¤.
            error_message = (f"âŒ ì„ë² ë”© ìƒì„±ì— ì‹¤íŒ¨í–ˆìŠµë‹ˆë‹¤. API ì—°ê²°ì„ í™•ì¸í•˜ê±°ë‚˜ ì¼ë¶€ ë°ì´í„°ì— ë¬¸ì œê°€ ìˆì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤. "
                           f"(ìƒì„±ëœ ì„ë² ë”© ìˆ˜: {len(embeddings if embeddings else [])}, í•„ìš”í•œ ìˆ˜: {len(needs_embedding)})")
            progress_container.error(error_message)


        if 'embedding_progress' in st.session_state:
            del st.session_state.embedding_progress

    return df

def calculate_cosine_similarity(embedding1: List[float], embedding2: List[float]) -> float:
    """ë‘ ì„ë² ë”© ê°„ì˜ ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°"""
    try:
        vec1 = np.array(embedding1).reshape(1, -1)
        vec2 = np.array(embedding2).reshape(1, -1)
        
        dot_product = np.dot(vec1, vec2.T)[0, 0]
        norm1 = np.linalg.norm(vec1)
        norm2 = np.linalg.norm(vec2)
        
        if norm1 == 0 or norm2 == 0:
            return 0.0
        
        similarity = dot_product / (norm1 * norm2)
        return float(similarity)
    except Exception:
        return 0.0

def find_similar_experiences_ai(current_situation: str, user_data: pd.DataFrame, top_k: int = 5) -> List[Dict]:
    """í˜„ì¬ ìƒí™©ê³¼ ìœ ì‚¬í•œ ê³¼ê±° ê±°ë˜ ê²½í—˜ì„ AI ì„ë² ë”©ìœ¼ë¡œ ì°¾ê¸°"""
    if user_data.empty or not check_gemini_api():
        return []
    
    # í˜„ì¬ ìƒí™© ì„ë² ë”© ìƒì„±
    current_embedding = create_embedding(current_situation)
    if not current_embedding:
        return []
    
    # ìœ íš¨í•œ ì„ë² ë”©ì´ ìˆëŠ” ê³¼ê±° ê±°ë˜ë§Œ í•„í„°ë§
    valid_trades = user_data[
        user_data['embedding'].notna() & 
        user_data['embedding'].apply(lambda x: isinstance(x, list) and len(x) > 0)
    ]
    
    if valid_trades.empty:
        return []
    
    # ìœ ì‚¬ë„ ê³„ì‚° ë° ì •ë ¬
    similar_experiences = []
    for idx, trade in valid_trades.iterrows():
        trade_embedding = trade['embedding']
        similarity = calculate_cosine_similarity(current_embedding, trade_embedding)
        
        if similarity > 0.2:  # ìœ ì‚¬ë„ ì„ê³„ê°’
            trade_dict = trade.to_dict()
            trade_dict['original_index'] = idx  # ì›ë³¸ ì¸ë±ìŠ¤ ë³´ì¡´
            
            similar_experiences.append({
                'trade_data': trade_dict,
                'similarity': similarity,
                'date': str(trade.get('ê±°ë˜ì¼ì‹œ', 'ë‚ ì§œ ì •ë³´ ì—†ìŒ')),
                'result': float(trade.get('ìˆ˜ìµë¥ ', 0))
            })
    
    # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ì—¬ ìƒìœ„ kê°œ ë°˜í™˜
    similar_experiences.sort(key=lambda x: x['similarity'], reverse=True)
    return similar_experiences[:top_k]

# === ê°œì¸í™”ëœ ì½”ì¹­ ë° ë¶„ì„ í•¨ìˆ˜ë“¤ ===
def generate_personalized_coaching(current_situation: str, similar_experiences: List[Dict], user_type: str) -> str:
    """ìœ ì‚¬ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ ê°œì¸í™”ëœ AI ì½”ì¹­ ë©”ì‹œì§€ ìƒì„±"""
    if not check_gemini_api() or not setup_gemini_api():
        return "âš ï¸ Gemini API í‚¤ê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤."
    
    try:
        # ìœ ì‚¬ ê²½í—˜ì„ í…ìŠ¤íŠ¸ë¡œ ë³€í™˜
        experiences_text = ""
        for i, exp in enumerate(similar_experiences[:3], 1):
            trade = exp['trade_data']
            experiences_text += f"""
            ê²½í—˜ {i} (ìœ ì‚¬ë„: {exp['similarity']*100:.1f}%):
            - ì¢…ëª©: {trade.get('ì¢…ëª©ëª…', '')}
            - ê±°ë˜: {trade.get('ê±°ë˜êµ¬ë¶„', '')}
            - ìˆ˜ìµë¥ : {trade.get('ìˆ˜ìµë¥ ', 0)}%
            - ê°ì •ìƒíƒœ: {trade.get('ê°ì •íƒœê·¸', '')}
            - ë‹¹ì‹œ ë©”ëª¨: "{trade.get('ë©”ëª¨', '')}"
            """
        
        # ì‚¬ìš©ì ìœ í˜•ë³„ ì½”ì¹­ ë°©í–¥ ì„¤ì •
        if user_type == "ê¹€êµ­ë¯¼":
            persona_context = "ê³µí¬ë§¤ë„ ì„±í–¥ì´ ê°•í•œ ë³´ìˆ˜ì  íˆ¬ìì"
            coaching_focus = "ê°ì •ì  íŒë‹¨ì„ í”¼í•˜ê³  ë°ì´í„° ê¸°ë°˜ì˜ ëƒ‰ì •í•œ ë¶„ì„ì„ í†µí•œ íˆ¬ì ê²°ì •"
        else:  # ë°•íˆ¬ì
            persona_context = "FOMO(Fear of Missing Out) ì„±í–¥ì´ ê°•í•œ ì ê·¹ì  íˆ¬ìì"
            coaching_focus = "ì¶©ë™ì  ë§¤ìˆ˜ë¥¼ í”¼í•˜ê³  ì‹ ì¤‘í•œ ë¶„ì„ì„ í†µí•œ íˆ¬ì ê²°ì •"
        
        # AI ì½”ì¹­ ìš”ì²­
        prompt = f"""
        ë‹¹ì‹ ì€ í•œêµ­ì˜ ì „ë¬¸ íˆ¬ì ì‹¬ë¦¬ ì½”ì¹˜ì…ë‹ˆë‹¤. {persona_context}ì¸ íˆ¬ììì—ê²Œ ì¡°ì–¸ì„ ì œê³µí•´ì•¼ í•©ë‹ˆë‹¤.
        
        í˜„ì¬ íˆ¬ì ìƒí™©:
        {current_situation}
        
        ì´ íˆ¬ììì˜ ê³¼ê±° ìœ ì‚¬ ê²½í—˜ë“¤:
        {experiences_text}
        
        ìœ„ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì¡°ì–¸í•´ì£¼ì„¸ìš”:
        
        ## ğŸ” íŒ¨í„´ ë¶„ì„
        ê³¼ê±° ìœ ì‚¬ ê±°ë˜ë“¤ì˜ ê³µí†µì ê³¼ ê²°ê³¼ë¥¼ 2-3ë¬¸ì¥ìœ¼ë¡œ ë¶„ì„
        
        ## â“ ìê¸° ì„±ì°° ì§ˆë¬¸
        í˜„ì¬ ê²°ì •ì„ ë‚´ë¦¬ê¸° ì „ ìŠ¤ìŠ¤ë¡œì—ê²Œ ë¬¼ì–´ë´ì•¼ í•  3ê°€ì§€ í•µì‹¬ ì§ˆë¬¸
        
        ## ğŸ’¡ êµ¬ì²´ì  ì¡°ì–¸
        {coaching_focus}ë¥¼ ìœ„í•œ 3-4ê°€ì§€ ì‹¤í–‰ ê°€ëŠ¥í•œ ì¡°ì–¸
        
        ## ğŸ¯ 24ì‹œê°„ ì•¡ì…˜ í”Œëœ
        ì˜¤ëŠ˜ ë‹¹ì¥ ì‹¤í–‰í•  ìˆ˜ ìˆëŠ” 1-2ê°€ì§€ êµ¬ì²´ì  í–‰ë™
        """
        
        model = genai.GenerativeModel('gemini-1.5-flash')
        response = model.generate_content(prompt)
        
        return response.text
        
    except Exception as e:
        return f"AI ì½”ì¹­ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

def analyze_trading_pattern_with_ai(user_data: pd.DataFrame, user_type: str) -> Dict[str, Any]:
    """ì „ì²´ ê±°ë˜ íŒ¨í„´ì„ AIë¡œ ì¢…í•© ë¶„ì„"""
    if user_data.empty or not check_gemini_api():
        return {}
    
    try:
        # ê±°ë˜ ë°ì´í„° í†µê³„ ê³„ì‚°
        total_trades = len(user_data)
        avg_return = user_data['ìˆ˜ìµë¥ '].mean()
        losing_trades = user_data[user_data['ìˆ˜ìµë¥ '] < 0]
        winning_trades = user_data[user_data['ìˆ˜ìµë¥ '] > 0]
        emotion_distribution = user_data['ê°ì •íƒœê·¸'].value_counts().to_dict()
        emotion_performance = user_data.groupby('ê°ì •íƒœê·¸')['ìˆ˜ìµë¥ '].agg(['mean', 'count']).round(2)
        
        # ìµœê·¼ ê±°ë˜ íŒ¨í„´ ë¶„ì„
        recent_trades = user_data.tail(10)
        recent_context = ""
        for _, trade in recent_trades.iterrows():
            recent_context += f"""
            - {trade.get('ê±°ë˜ì¼ì‹œ', '')}: {trade.get('ì¢…ëª©ëª…', '')} ({trade.get('ê±°ë˜êµ¬ë¶„', '')})
              ê°ì •: {trade.get('ê°ì •íƒœê·¸', '')}, ìˆ˜ìµë¥ : {trade.get('ìˆ˜ìµë¥ ', 0)}%
              ë©”ëª¨: "{trade.get('ë©”ëª¨', '')}"
            """
        
        # AI íŒ¨í„´ ë¶„ì„ ìš”ì²­
        prompt = f"""
        ë‹¹ì‹ ì€ í•œêµ­ì˜ ì „ë¬¸ íˆ¬ì ë¶„ì„ê°€ì…ë‹ˆë‹¤. {user_type} íˆ¬ììì˜ ê±°ë˜ íŒ¨í„´ì„ ì¢…í•© ë¶„ì„í•´ì£¼ì„¸ìš”.
        
        ## ê±°ë˜ ë°ì´í„° ìš”ì•½
        - ì´ ê±°ë˜ íšŸìˆ˜: {total_trades}íšŒ
        - í‰ê·  ìˆ˜ìµë¥ : {avg_return:.1f}%
        - ìˆ˜ìµ ê±°ë˜: {len(winning_trades)}íšŒ ({len(winning_trades)/total_trades*100:.1f}%)
        - ì†ì‹¤ ê±°ë˜: {len(losing_trades)}íšŒ ({len(losing_trades)/total_trades*100:.1f}%)
        - ê°ì •ë³„ ê±°ë˜ ë¶„í¬: {emotion_distribution}
        
        ## ê°ì •ë³„ ì„±ê³¼ ë¶„ì„
        {emotion_performance.to_string()}
        
        ## ìµœê·¼ 10ê°œ ê±°ë˜ íŒ¨í„´
        {recent_context}
        
        ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ìƒì„¸ ë¶„ì„í•´ì£¼ì„¸ìš”:
        
        ### ğŸ¯ í•µì‹¬ íˆ¬ì íŒ¨í„´
        - ì£¼ìš” ê°•ì  2ê°€ì§€
        - ì£¼ìš” ì•½ì  2ê°€ì§€
        - íŠ¹ì´í•œ íŒ¨í„´ì´ë‚˜ ìŠµê´€
        
        ### ğŸ“Š ê°ì •ë³„ ì„±ê³¼ ë¶„ì„
        - ê°€ì¥ ìˆ˜ìµì„±ì´ ë†’ì€ ê°ì • ìƒíƒœ
        - ê°€ì¥ ìœ„í—˜í•œ ê°ì • ìƒíƒœ
        - ê°ì • ê´€ë¦¬ ê°œì„ ì 
        
        ### âš ï¸ ìœ„í—˜ ì‹ í˜¸ ê°ì§€
        - ê±°ë˜ ì¤‘ë‹¨ì„ ê³ ë ¤í•´ì•¼ í•˜ëŠ” 3ê°€ì§€ ì‹ í˜¸
        - ê° ì‹ í˜¸ì— ëŒ€í•œ êµ¬ì²´ì  ê¸°ì¤€
        
        ### ğŸ’ ê°œì„  ì „ëµ
        - ì¦‰ì‹œ ì ìš© ê°€ëŠ¥í•œ 3ê°€ì§€ ê°œì„ ì±…
        - ì¤‘ì¥ê¸° ëª©í‘œ 2ê°€ì§€
        
        ### ğŸ“‹ ë§ì¶¤í˜• íˆ¬ì ì›ì¹™
        - ì´ íˆ¬ììì—ê²Œ íŠ¹íˆ ì¤‘ìš”í•œ 3ê°€ì§€ ê·œì¹™
        - ê° ê·œì¹™ì˜ ê·¼ê±°
        """
        
        model = genai.GenerativeModel('gemini-1.5-flash')
        response = model.generate_content(prompt)
        
        return {
            'analysis': response.text,
            'total_trades': total_trades,
            'avg_return': avg_return,
            'win_rate': len(winning_trades)/total_trades*100,
            'loss_rate': len(losing_trades)/total_trades*100,
            'emotion_distribution': emotion_distribution,
            'emotion_performance': emotion_performance.to_dict()
        }
        
    except Exception as e:
        return {'error': f"íŒ¨í„´ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}"}

def generate_investment_charter(user_data: pd.DataFrame, user_type: str) -> str:
    """ê°œì¸í™”ëœ íˆ¬ì í—Œì¥ ìƒì„±"""
    if user_data.empty or not check_gemini_api():
        return "íˆ¬ì í—Œì¥ì„ ìƒì„±í•˜ê¸° ìœ„í•´ì„œëŠ” ì¶©ë¶„í•œ ê±°ë˜ ë°ì´í„°ì™€ Gemini APIê°€ í•„ìš”í•©ë‹ˆë‹¤."
    
    try:
        pattern_analysis = analyze_trading_pattern_with_ai(user_data, user_type)
        if 'error' in pattern_analysis:
            return f"í—Œì¥ ìƒì„± ì¤‘ ì˜¤ë¥˜: {pattern_analysis['error']}"
        
        # ì†ì‹¤ì´ í° ê°ì • íŒ¨í„´ ì‹ë³„
        losing_emotions = user_data[user_data['ìˆ˜ìµë¥ '] < -5].groupby('ê°ì •íƒœê·¸')['ìˆ˜ìµë¥ '].agg(['mean', 'count'])
        
        prompt = f"""
        ë‹¹ì‹ ì€ íˆ¬ì í—Œì¥ ì‘ì„± ì „ë¬¸ê°€ì…ë‹ˆë‹¤. {user_type} íˆ¬ììë¥¼ ìœ„í•œ ê°œì¸í™”ëœ íˆ¬ì í—Œì¥ì„ ì‘ì„±í•´ì£¼ì„¸ìš”.
        
        íˆ¬ìì í”„ë¡œí•„:
        - ì´ ê±°ë˜: {pattern_analysis.get('total_trades', 0)}íšŒ
        - í‰ê·  ìˆ˜ìµë¥ : {pattern_analysis.get('avg_return', 0):.1f}%
        - ìŠ¹ë¥ : {pattern_analysis.get('win_rate', 0):.1f}%
        
        ì£¼ìš” ìœ„í—˜ ê°ì •:
        {losing_emotions.to_string() if not losing_emotions.empty else "íŠ¹ë³„í•œ ìœ„í—˜ íŒ¨í„´ ì—†ìŒ"}
        
        ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ íˆ¬ì í—Œì¥ì„ ì‘ì„±í•´ì£¼ì„¸ìš”:
        
        # ğŸ“œ {user_type}ë‹˜ì˜ ê°œì¸ íˆ¬ì í—Œì¥
        
        ## ğŸ¯ íˆ¬ì ì² í•™
        ë‚˜ì˜ íˆ¬ì ìŠ¤íƒ€ì¼ê³¼ ëª©í‘œë¥¼ ëª…í™•íˆ ì„ ì–¸
        
        ## âš–ï¸ í•µì‹¬ ì›ì¹™ (5ê°€ì§€)
        1. ê°ì • ê´€ë¦¬ ì›ì¹™
        2. ë¦¬ìŠ¤í¬ ê´€ë¦¬ ì›ì¹™  
        3. ê±°ë˜ ì‹¤í–‰ ì›ì¹™
        4. ì •ë³´ ìˆ˜ì§‘ ì›ì¹™
        5. ì„±ê³¼ í‰ê°€ ì›ì¹™
        
        ## ğŸš« ì ˆëŒ€ ê¸ˆì§€ ì‚¬í•­ (3ê°€ì§€)
        ì´ íˆ¬ììê°€ ì ˆëŒ€ í•˜ì§€ ë§ì•„ì•¼ í•  í–‰ë™ë“¤
        
        ## â° ê±°ë˜ ì¤‘ë‹¨ ê¸°ì¤€
        ì–¸ì œ íˆ¬ìë¥¼ ë©ˆì¶”ê³  ëƒ‰ì •í•´ì•¼ í•˜ëŠ”ì§€
        
        ## ğŸ“Š ì •ê¸° ì ê²€ ê³„íš
        ì–¸ì œ, ì–´ë–»ê²Œ ì´ í—Œì¥ì„ ê²€í† í•  ê²ƒì¸ì§€
        
        ## âœï¸ ì„œëª…
        ì‘ì„±ì¼: {datetime.now().strftime('%Yë…„ %mì›” %dì¼')}
        íˆ¬ìì: {user_type}
        """
        
        model = genai.GenerativeModel('gemini-1.5-flash')
        response = model.generate_content(prompt)
        
        return response.text
        
    except Exception as e:
        return f"íˆ¬ì í—Œì¥ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}"

def analyze_trading_psychology(user_input: str, user_data: pd.DataFrame, user_type: str) -> str:
    """í˜„ì¬ ê±°ë˜ ì‹¬ë¦¬ ìƒíƒœ ë¶„ì„"""
    if not check_gemini_api():
        return "ì‹¬ë¦¬ ë¶„ì„ì„ ìœ„í•´ Gemini APIê°€ í•„ìš”í•©ë‹ˆë‹¤."
    
    try:
        # ìµœê·¼ ê±°ë˜ íŒ¨í„´ ë¶„ì„
        recent_emotions = user_data.tail(10)['ê°ì •íƒœê·¸'].value_counts().to_dict() if not user_data.empty else {}
        recent_returns = user_data.tail(5)['ìˆ˜ìµë¥ '].tolist() if not user_data.empty else []
        
        prompt = f"""
        ë‹¹ì‹ ì€ íˆ¬ì ì‹¬ë¦¬ ì „ë¬¸ê°€ì…ë‹ˆë‹¤. {user_type} íˆ¬ììì˜ í˜„ì¬ ì‹¬ë¦¬ ìƒíƒœë¥¼ ë¶„ì„í•´ì£¼ì„¸ìš”.
        
        íˆ¬ììì˜ í˜„ì¬ ìƒê°/ê³ ë¯¼:
        "{user_input}"
        
        ìµœê·¼ ê±°ë˜ì—ì„œì˜ ê°ì • íŒ¨í„´:
        {recent_emotions}
        
        ìµœê·¼ 5íšŒ ê±°ë˜ ìˆ˜ìµë¥ :
        {recent_returns}
        
        ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ë¶„ì„í•´ì£¼ì„¸ìš”:
        
        ## ğŸ§  í˜„ì¬ ì‹¬ë¦¬ ìƒíƒœ ì§„ë‹¨
        - ì£¼ìš” ê°ì •: (ë¶ˆì•ˆ/ìš•ì‹¬/ê³µí¬/ìì‹ ê° ë“±)
        - ìœ„í—˜ë„: (ë‚®ìŒ/ë³´í†µ/ë†’ìŒ/ë§¤ìš°ë†’ìŒ)
        - íŒë‹¨ë ¥ ìƒíƒœ: ë¶„ì„
        
        ## ğŸ” ì‹¬ë¦¬ì  í¸í–¥ ì²´í¬
        - ì¸ì§€í¸í–¥ ì—¬ë¶€ (í™•ì¦í¸í–¥, ì†ì‹¤íšŒí”¼í¸í–¥ ë“±)
        - ê°ì •ì  ì˜ì‚¬ê²°ì • ìœ„í—˜ë„
        
        ## ğŸ’Š ì²˜ë°©ì „
        - ì¦‰ì‹œ ì‹¤í–‰í•  ë©˜íƒˆ ê´€ë¦¬ë²• 2ê°€ì§€
        - 24ì‹œê°„ ë‚´ í”¼í•´ì•¼ í•  í–‰ë™ 3ê°€ì§€
        - ì¥ê¸°ì  ì‹¬ë¦¬ í›ˆë ¨ ë°©ë²• 1ê°€ì§€
        
        ## ğŸ¯ ë‹¤ìŒ ê±°ë˜ ê¶Œì¥ì‚¬í•­
        í˜„ì¬ ì‹¬ë¦¬ ìƒíƒœë¥¼ ê³ ë ¤í•œ êµ¬ì²´ì  í–‰ë™ ì§€ì¹¨
        """
        
        model = genai.GenerativeModel('gemini-1.5-flash')
        response = model.generate_content(prompt)
        
        return response.text
        
    except Exception as e:
        return f"ì‹¬ë¦¬ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}"

# === ê¸°ì¡´ ê±°ë˜ ë¶„ì„ í•¨ìˆ˜ë“¤ (í•˜ìœ„ í˜¸í™˜ì„± ìœ ì§€) ===
def find_similar_trades(current_trade, csv_data, similarity_threshold=0.3):
    """ê¸°ì¡´ ìœ ì‚¬ ê±°ë˜ ì°¾ê¸° í•¨ìˆ˜ (ì„ë² ë”© ìš°ì„ , í‚¤ì›Œë“œ ë§¤ì¹­ í´ë°±)"""
    if csv_data.empty:
        return []
    
    # ì„ë² ë”© ê¸°ë°˜ ë¶„ì„ ì‹œë„
    if 'embedding' in csv_data.columns and check_gemini_api():
        current_situation = f"""
        ì¢…ëª©: {current_trade.get('ì¢…ëª©', '')}
        ê±°ë˜êµ¬ë¶„: {current_trade.get('ê±°ë˜ìœ í˜•', '')}
        ìˆ˜ëŸ‰: {current_trade.get('ìˆ˜ëŸ‰', '')}ì£¼
        ê°€ê²©: {current_trade.get('ê°€ê²©', '')}ì›
        """
        
        similar_experiences = find_similar_experiences_ai(current_situation, csv_data, top_k=5)
        if similar_experiences:
            return similar_experiences
    
    # ê¸°ë³¸ í‚¤ì›Œë“œ ë§¤ì¹­ ë°©ì‹ (í´ë°±)
    similar_trades = []
    current_stock = current_trade.get('ì¢…ëª©', '')
    current_type = current_trade.get('ê±°ë˜ìœ í˜•', '')
    
    for _, trade in csv_data.iterrows():
        similarity_score = 0
        similarity_reasons = []
        
        # ì¢…ëª©ëª… ìœ ì‚¬ë„
        if str(trade.get('ì¢…ëª©ëª…', '')) == current_stock:
            similarity_score += 0.4
            similarity_reasons.append(f"ë™ì¼ ì¢…ëª© ({current_stock})")
        
        # ê±°ë˜ êµ¬ë¶„ ìœ ì‚¬ë„
        if str(trade.get('ê±°ë˜êµ¬ë¶„', '')) == current_type:
            similarity_score += 0.3
            similarity_reasons.append(f"ë™ì¼ ê±°ë˜ìœ í˜• ({current_type})")
        
        # ê°ì • íŒ¨í„´ ìœ ì‚¬ë„
        emotion_tag = trade.get('ê°ì •íƒœê·¸', '')
        if emotion_tag and any(keyword in emotion_tag for keyword in ['#ê³µí¬', '#íŒ¨ë‹‰', '#ì¶”ê²©ë§¤ìˆ˜', '#ìš•ì‹¬']):
            similarity_score += 0.3
            similarity_reasons.append(f"ìœ„í—˜ ê°ì •íŒ¨í„´ ({emotion_tag})")
        
        if similarity_score >= similarity_threshold:
            similar_trades.append({
                'trade_data': trade.to_dict(),
                'similarity': similarity_score,
                'reasons': similarity_reasons,
                'date': str(trade.get('ê±°ë˜ì¼ì‹œ', 'ë‚ ì§œ ì •ë³´ ì—†ìŒ')),
                'result': float(trade.get('ìˆ˜ìµë¥ ', 0))
            })
    
    similar_trades.sort(key=lambda x: x['similarity'], reverse=True)
    return similar_trades[:5]

def analyze_trade_with_ai(stock_name, trade_type, quantity, price, csv_data):
    """í†µí•© ê±°ë˜ ë¶„ì„ í•¨ìˆ˜ (ì„ë² ë”© ìš°ì„ , ê¸°ë³¸ ë¶„ì„ í´ë°±)"""
    current_trade = {
        "ì¢…ëª©": stock_name,
        "ê±°ë˜ìœ í˜•": trade_type,
        "ìˆ˜ëŸ‰": quantity,
        "ê°€ê²©": price
    }
    
    current_situation = f"""
    ì¢…ëª©: {stock_name}
    ê±°ë˜êµ¬ë¶„: {trade_type}
    ìˆ˜ëŸ‰: {quantity}ì£¼
    ê°€ê²©: {price:,}ì›
    """
    
    # ì„ë² ë”© ê¸°ë°˜ ë¹ ë¥¸ ë¶„ì„
    if 'embedding' in csv_data.columns and check_gemini_api():
        similar_trades = find_similar_experiences_ai(current_situation, csv_data)
        if similar_trades:
            ai_analysis = generate_personalized_coaching(
                current_situation, 
                similar_trades, 
                st.session_state.get('current_user', 'ê¹€êµ­ë¯¼')
            )
            return {
                'similar_trades': similar_trades,
                'ai_analysis': ai_analysis,
                'method': 'optimized_gemini_ai'
            }
    
    # ê¸°ë³¸ ë°©ì‹ (í´ë°±)
    similar_trades = find_similar_trades(current_trade, csv_data)
    
    return {
        'similar_trades': similar_trades,
        'ai_analysis': "ì„ë² ë”© ë°ì´í„°ë¥¼ ì¤€ë¹„í•˜ë©´ ë” ì •í™•í•œ AI ë¶„ì„ì„ ë°›ì„ ìˆ˜ ìˆìŠµë‹ˆë‹¤.",
        'method': 'basic'
    }

# === íˆ¬ì ì‹¬ë¦¬ ë¶„ì„ ì—”ì§„ í´ë˜ìŠ¤ ===
class ReMinDKoreanEngine:
    """í•œêµ­ì–´ íˆ¬ì ì‹¬ë¦¬ ë¶„ì„ ì—”ì§„ (Gemini ê¸°ë°˜)"""
    
    def __init__(self):
        # í–‰ë™ íŒ¨í„´ í‚¤ì›Œë“œ ì •ì˜
        self.behavioral_patterns = {
            'ê³µí¬ë§¤ë„': ['ë¬´ì„œì›Œ', 'ê±±ì •', 'íŒ¨ë‹‰', 'í­ë½', 'ì†ì‹¤', 'ìœ„í—˜', 'ê¸‰ë½', 'í•˜ë½', 'ì†ì ˆ'],
            'ì¶”ê²©ë§¤ìˆ˜': ['ìƒí•œê°€', 'ê¸‰ë“±', 'ë†“ì¹˜ê¸°', 'ë’¤ëŠ¦ê²Œ', 'ì¶”ê²©', 'ëª¨ë‘ê°€', 'FOMO', 'fomo', 'ê¸‰íˆ', 'ìœ íŠœë²„', 'ì¶”ì²œ', 'ì»¤ë®¤ë‹ˆí‹°'],
            'ë³µìˆ˜ë§¤ë§¤': ['ë¶„í•˜ë‹¤', 'ë³´ë³µ', 'í™”ë‚˜ë‹¤', 'ì–µìš¸í•˜ë‹¤', 'íšŒë³µ', 'ë˜ì°¾ê¸°'],
            'ê³¼ì‹ ë§¤ë§¤': ['í™•ì‹ ', 'í‹€ë¦¼ì—†ë‹¤', 'ì‰¬ìš´ëˆ', 'í™•ì‹¤í•˜ë‹¤', 'ë³´ì¥', 'ë¬´ì¡°ê±´', 'ëŒ€ë°•', 'ì˜¬ì¸']
        }
        self._emotion_cache = {}  # ê°ì • ë¶„ì„ ìºì‹œ
    
    def analyze_emotion_text_batch(self, texts: List[str], user_type: str) -> List[Dict]:
        """ë°°ì¹˜ ë‹¨ìœ„ ê°ì • ë¶„ì„"""
        if not texts:
            return []
        
        results = []
        
        # Gemini ë°°ì¹˜ ë¶„ì„ ì‹œë„ (5ê°œ ì´ìƒì¼ ë•Œ)
        if check_gemini_api() and len(texts) > 5:
            try:
                batch_prompt = f"""
                ë‹¤ìŒ {len(texts)}ê°œì˜ í…ìŠ¤íŠ¸ë“¤ì—ì„œ ê°ê°ì˜ íˆ¬ì ê°ì • íŒ¨í„´ì„ ë¶„ì„í•´ì£¼ì„¸ìš”.
                """
                
                for i, text in enumerate(texts, 1):
                    batch_prompt += f"{i}. {text}\n"
                
                batch_prompt += """
                ê° í…ìŠ¤íŠ¸ì— ëŒ€í•´ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ê²°ê³¼ë¥¼ ë°°ì—´ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”:
                [
                    {
                        "id": 1,
                        "pattern": "ê³µí¬ë§¤ë„/ì¶”ê²©ë§¤ìˆ˜/ë³µìˆ˜ë§¤ë§¤/ê³¼ì‹ ë§¤ë§¤/í•©ë¦¬ì íˆ¬ì ì¤‘ í•˜ë‚˜",
                        "confidence": 0.0~1.0 ì‚¬ì´ ê°’,
                        "keywords": ["ê°ì§€ëœ", "í‚¤ì›Œë“œ"],
                        "description": "íŒ¨í„´ ì„¤ëª…"
                    }
                ]
                """
                
                model = genai.GenerativeModel('gemini-1.5-flash')
                response = model.generate_content(batch_prompt)
                
                try:
                    batch_results = json.loads(response.text)
                    if isinstance(batch_results, list) and len(batch_results) == len(texts):
                        return batch_results
                except:
                    pass
                    
            except Exception as e:
                st.warning(f"ë°°ì¹˜ ê°ì • ë¶„ì„ ì˜¤ë¥˜: {e}")
        
        # ê°œë³„ ì²˜ë¦¬ (í´ë°±)
        for text in texts:
            results.append(self.analyze_emotion_text(text, user_type))
        
        return results
    
    def analyze_emotion_text(self, text, user_type):
        """ë‹¨ì¼ í…ìŠ¤íŠ¸ ê°ì • ë¶„ì„ (ìºì‹œ ì ìš©)"""
        if not text or not isinstance(text, str):
            return {
                'pattern': 'ì¤‘ë¦½', 
                'confidence': 0.5, 
                'keywords': [],
                'description': 'ê°ì • íŒ¨í„´ì„ ë¶„ì„í•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.'
            }
        
        # ìºì‹œ í™•ì¸
        cache_key = hashlib.md5(f"{text}_{user_type}".encode()).hexdigest()
        if cache_key in self._emotion_cache:
            return self._emotion_cache[cache_key]
        
        result = self._analyze_emotion_internal(text, user_type)
        
        # ìºì‹œ ì €ì¥ (ìµœëŒ€ 1000ê°œ)
        if len(self._emotion_cache) < 1000:
            self._emotion_cache[cache_key] = result
        
        return result
    
    def _analyze_emotion_internal(self, text, user_type):
        """ë‚´ë¶€ ê°ì • ë¶„ì„ ë¡œì§ (Gemini ìš°ì„ , í‚¤ì›Œë“œ ë¶„ì„ í´ë°±)"""
        # Gemini ë¶„ì„ ì‹œë„
        if check_gemini_api():
            try:
                prompt = f"""
                ë‹¤ìŒ í…ìŠ¤íŠ¸ì—ì„œ íˆ¬ì ê°ì • íŒ¨í„´ì„ ë¶„ì„í•´ì£¼ì„¸ìš”:
                "{text}"
                
                ë¶„ì„ ê²°ê³¼ë¥¼ ë‹¤ìŒ JSON í˜•ì‹ìœ¼ë¡œ ë°˜í™˜í•´ì£¼ì„¸ìš”:
                {{
                    "pattern": "ê³µí¬ë§¤ë„/ì¶”ê²©ë§¤ìˆ˜/ë³µìˆ˜ë§¤ë§¤/ê³¼ì‹ ë§¤ë§¤/í•©ë¦¬ì íˆ¬ì ì¤‘ í•˜ë‚˜",
                    "confidence": 0.0~1.0 ì‚¬ì´ ê°’,
                    "keywords": ["ê°ì§€ëœ", "í‚¤ì›Œë“œ", "ëª©ë¡"],
                    "description": "íŒ¨í„´ì— ëŒ€í•œ ì„¤ëª…"
                }}
                """
                
                model = genai.GenerativeModel('gemini-1.5-flash')
                response = model.generate_content(prompt)
                
                try:
                    result = json.loads(response.text)
                    return result
                except:
                    pass
            except Exception:
                pass
        
        # ê¸°ë³¸ í‚¤ì›Œë“œ ë¶„ì„ (í´ë°±)
        text_lower = text.lower()
        found_keywords = []
        patterns_found = {}
        
        for pattern, keywords in self.behavioral_patterns.items():
            pattern_keywords = [kw for kw in keywords if kw in text_lower]
            if pattern_keywords:
                patterns_found[pattern] = len(pattern_keywords)
                found_keywords.extend(pattern_keywords)
        
        if patterns_found:
            dominant_pattern = max(patterns_found, key=patterns_found.get)
            confidence = min(0.9, 0.6 + (patterns_found[dominant_pattern] * 0.1))
            
            descriptions = {
                'ê³µí¬ë§¤ë„': 'ì‹œì¥ í•˜ë½ì— ëŒ€í•œ ë‘ë ¤ì›€ìœ¼ë¡œ ì¸í•œ íŒ¨ë‹‰ ë§¤ë„ íŒ¨í„´',
                'ì¶”ê²©ë§¤ìˆ˜': 'FOMO(Fear of Missing Out)ì— ì˜í•œ ê³ ì  ë§¤ìˆ˜ íŒ¨í„´',
                'ë³µìˆ˜ë§¤ë§¤': 'ì†ì‹¤ íšŒë³µì„ ìœ„í•œ ê°ì •ì  ë³µìˆ˜ ê±°ë˜ íŒ¨í„´',
                'ê³¼ì‹ ë§¤ë§¤': 'ê³¼ë„í•œ ìì‹ ê°ìœ¼ë¡œ ì¸í•œ ë¬´ë¦¬í•œ íˆ¬ì íŒ¨í„´'
            }
            
            return {
                'pattern': dominant_pattern,
                'confidence': confidence,
                'keywords': found_keywords[:3],
                'description': descriptions.get(dominant_pattern, 'ì•Œ ìˆ˜ ì—†ëŠ” íŒ¨í„´')
            }
        
        return {
            'pattern': 'í•©ë¦¬ì íˆ¬ì',
            'confidence': 0.60,
            'keywords': [],
            'description': 'ë°ì´í„° ê¸°ë°˜ì˜ í•©ë¦¬ì  íˆ¬ì íŒ¨í„´'
        }
    
    def generate_investment_charter_rules(self, user_data, user_type):
        """ê°œì¸í™”ëœ íˆ¬ì í—Œì¥ ê·œì¹™ ìƒì„±"""
        if user_data.empty:
            return []
        
        rules = []
        
        # ê°ì •ë³„ ìˆ˜ìµë¥  ë¶„ì„ìœ¼ë¡œ ê·œì¹™ ìƒì„±
        if 'ê°ì •íƒœê·¸' in user_data.columns and 'ìˆ˜ìµë¥ ' in user_data.columns:
            emotion_performance = user_data.groupby('ê°ì •íƒœê·¸')['ìˆ˜ìµë¥ '].mean()
            
            # ì†ì‹¤ì´ í° ê°ì • íŒ¨í„´ì— ëŒ€í•œ ê·œì¹™ ìƒì„±
            for emotion, avg_return in emotion_performance.items():
                if avg_return < -5:  # í‰ê·  -5% ì´í•˜ì¸ ê²½ìš°
                    if emotion in ['#ê³µí¬', '#íŒ¨ë‹‰']:
                        rules.append({
                            'rule': f'{emotion} ìƒíƒœì¼ ë•ŒëŠ” 24ì‹œê°„ ê±°ë˜ ê¸ˆì§€',
                            'rationale': f'ê³¼ê±° ë°ì´í„°ìƒ {emotion} ìƒíƒœì—ì„œ í‰ê·  {avg_return:.1f}% ì†ì‹¤',
                            'evidence': f'{len(user_data[user_data["ê°ì •íƒœê·¸"] == emotion])}íšŒ ê±°ë˜ ë¶„ì„',
                            'category': 'ê°ì • ê´€ë¦¬'
                        })
                    elif emotion in ['#ì¶”ê²©ë§¤ìˆ˜', '#ìš•ì‹¬']:
                        rules.append({
                            'rule': 'ê¸‰ë“±ì£¼ ì¶”ê²©ë§¤ìˆ˜ ì‹œ íˆ¬ìê¸ˆì•¡ì„ 10ë§Œì› ì´í•˜ë¡œ ì œí•œ',
                            'rationale': f'ì¶”ê²©ë§¤ìˆ˜ì—ì„œ í‰ê·  {avg_return:.1f}% ì†ì‹¤ ë°œìƒ',
                            'evidence': f'{len(user_data[user_data["ê°ì •íƒœê·¸"] == emotion])}íšŒ ê±°ë˜ ë¶„ì„',
                            'category': 'FOMO ë°©ì§€'
                        })
        
        return rules[:5]  # ìµœëŒ€ 5ê°œ ê·œì¹™
    
    def extract_principles_from_notes(self, user_data):
        """ë³µê¸°ë…¸íŠ¸ì—ì„œ íˆ¬ì ì›ì¹™ ì¶”ì¶œ"""
        if user_data.empty or 'ë©”ëª¨' not in user_data.columns:
            return []
        
        principles = []
        
        # ì†ì‹¤ ê±°ë˜ ë¶„ì„
        losing_trades = user_data[user_data['ìˆ˜ìµë¥ '] < 0]
        
        if len(losing_trades) > 5:
            # ê°ì •ë³„ ì†ì‹¤ íŒ¨í„´ ë¶„ì„
            emotion_losses = losing_trades.groupby('ê°ì •íƒœê·¸').agg({
                'ìˆ˜ìµë¥ ': ['mean', 'count']
            }).round(2)
            
            for emotion in emotion_losses.index:
                avg_loss = emotion_losses.loc[emotion, ('ìˆ˜ìµë¥ ', 'mean')]
                count = emotion_losses.loc[emotion, ('ìˆ˜ìµë¥ ', 'count')]
                
                if count >= 3 and avg_loss < -5:
                    principles.append({
                        'title': f'{emotion} ìƒíƒœì—ì„œì˜ ê±°ë˜ ì œí•œ',
                        'description': f'ê³¼ê±° {count}íšŒ ê±°ë˜ì—ì„œ í‰ê·  {avg_loss:.1f}% ì†ì‹¤ ë°œìƒ',
                        'rule': f'{emotion} ê°ì • ìƒíƒœì¼ ë•ŒëŠ” íˆ¬ì ê²°ì •ì„ 24ì‹œê°„ ì—°ê¸°í•œë‹¤',
                        'evidence_count': int(count),
                        'avg_impact': abs(avg_loss)
                    })
        
        # ì¢…ëª©ë³„ íŒ¨í„´ ë¶„ì„
        if 'ì¢…ëª©ëª…' in user_data.columns:
            stock_losses = losing_trades.groupby('ì¢…ëª©ëª…').agg({
                'ìˆ˜ìµë¥ ': ['mean', 'count']
            }).round(2)
            
            for stock in stock_losses.index:
                avg_loss = stock_losses.loc[stock, ('ìˆ˜ìµë¥ ', 'mean')]
                count = stock_losses.loc[stock, ('ìˆ˜ìµë¥ ', 'count')]
                
                if count >= 3 and avg_loss < -10:
                    principles.append({
                        'title': f'{stock} ì¢…ëª© ê±°ë˜ ì£¼ì˜',
                        'description': f'{stock}ì—ì„œ {count}íšŒ ê±°ë˜ë¡œ í‰ê·  {avg_loss:.1f}% ì†ì‹¤',
                        'rule': f'{stock} ê±°ë˜ ì‹œ íˆ¬ìê¸ˆì•¡ì„ í‰ì†Œì˜ 50%ë¡œ ì œí•œí•œë‹¤',
                        'evidence_count': int(count),
                        'avg_impact': abs(avg_loss)
                    })
        
        # ê¸°ë³¸ ì›ì¹™ë“¤ ì¶”ê°€ (ë°ì´í„° ë¶€ì¡± ì‹œ)
        if len(principles) < 3:
            principles.extend([
                {
                    'title': 'ê±°ë˜ ì‹œê°„ëŒ€ ì œí•œ',
                    'description': 'ì¶©ë™ì  ê±°ë˜ë¥¼ ë°©ì§€í•˜ê¸° ìœ„í•œ ì‹œê°„ ê´€ë¦¬',
                    'rule': 'ì‹œì¥ ê°œì¥ ì²« 30ë¶„ê³¼ ë§ˆê° 30ë¶„ì—ëŠ” ê±°ë˜í•˜ì§€ ì•ŠëŠ”ë‹¤',
                    'evidence_count': 0,
                    'avg_impact': 0
                },
                {
                    'title': 'ë¶„í•  ë§¤ìˆ˜ ì›ì¹™',
                    'description': 'ë¦¬ìŠ¤í¬ ë¶„ì‚°ì„ ìœ„í•œ íˆ¬ì ì „ëµ',
                    'rule': 'í•œ ë²ˆì— ì „ì²´ íˆ¬ì ì˜ˆì • ê¸ˆì•¡ì˜ 30%ë¥¼ ì´ˆê³¼í•˜ì—¬ ë§¤ìˆ˜í•˜ì§€ ì•ŠëŠ”ë‹¤',
                    'evidence_count': 0,
                    'avg_impact': 0
                }
            ])
        
        return principles[:5]

# === ìœ í‹¸ë¦¬í‹° í•¨ìˆ˜ë“¤ ===
def generate_ai_coaching_tip(user_data, user_type):
    """ì¼ì¼ AI ì½”ì¹­ íŒ ìƒì„±"""
    try:
        if user_data.empty:
            return "ğŸ“Š ê±°ë˜ ë°ì´í„°ë¥¼ ì¶•ì í•˜ì—¬ ê°œì¸í™”ëœ AI ì½”ì¹­ì„ ë°›ì•„ë³´ì„¸ìš”."
        
        # ì„ë² ë”© ê¸°ë°˜ ë¹ ë¥¸ íŒ¨í„´ ë¶„ì„
        if 'embedding' in user_data.columns and check_gemini_api():
            recent_trades = user_data.tail(10)
            recent_emotions = recent_trades['ê°ì •íƒœê·¸'].value_counts().to_dict()
            recent_returns = recent_trades['ìˆ˜ìµë¥ '].tolist()
            avg_recent_return = recent_trades['ìˆ˜ìµë¥ '].mean()
            
            total_trades = len(user_data)
            overall_return = user_data['ìˆ˜ìµë¥ '].mean()
            win_rate = len(user_data[user_data['ìˆ˜ìµë¥ '] > 0]) / len(user_data) * 100
            
            prompt = f"""
            ë‹¹ì‹ ì€ {user_type} íˆ¬ììì˜ ì „ë‹´ AI ì½”ì¹˜ì…ë‹ˆë‹¤. ì˜¤ëŠ˜ì˜ í•µì‹¬ íˆ¬ì ì¡°ì–¸ì„ ê°„ê²°í•˜ê²Œ ì œê³µí•´ì£¼ì„¸ìš”.
            
            íˆ¬ìì í˜„í™©:
            - ì´ ê±°ë˜: {total_trades}íšŒ
            - ì „ì²´ í‰ê·  ìˆ˜ìµë¥ : {overall_return:.1f}%
            - ìŠ¹ë¥ : {win_rate:.1f}%
            - ìµœê·¼ 10íšŒ ê±°ë˜ í‰ê· : {avg_recent_return:.1f}%
            
            ìµœê·¼ ê°ì • íŒ¨í„´: {recent_emotions}
            ìµœê·¼ ìˆ˜ìµë¥  ì¶”ì´: {recent_returns}
            
            ë‹¤ìŒ í˜•ì‹ìœ¼ë¡œ ì˜¤ëŠ˜ì˜ í•µì‹¬ ì¡°ì–¸ 1ê°œë¥¼ ì œê³µí•´ì£¼ì„¸ìš”:
            ğŸ¯ [ì˜¤ëŠ˜ì˜ í•µì‹¬ ë©”ì‹œì§€ - í•œ ë¬¸ì¥]
            ğŸ“Š [ë°ì´í„° ê·¼ê±° - ê°„ë‹¨íˆ]
            ğŸ’¡ [êµ¬ì²´ì  í–‰ë™ ì§€ì¹¨ - ì‹¤í–‰ ê°€ëŠ¥í•œ ë‚´ìš©]
            
            ë‹µë³€ì€ 50ì ì´ë‚´ì˜ ê°„ê²°í•˜ê³  ì„íŒ©íŠ¸ ìˆëŠ” ë©”ì‹œì§€ë¡œ ì‘ì„±í•´ì£¼ì„¸ìš”.
            """
            
            try:
                model = genai.GenerativeModel('gemini-1.5-flash')
                response = model.generate_content(prompt)
                return response.text
            except Exception as e:
                st.warning(f"Gemini ì½”ì¹­ ìƒì„± ì˜¤ë¥˜: {e}")
        
        # ê¸°ë³¸ ë¡œì§ (í´ë°±)
        recent_trades = user_data.tail(5)
        if recent_trades.empty:
            return "ğŸ“Š ê±°ë˜ ë°ì´í„°ë¥¼ ì¶•ì í•˜ì—¬ ê°œì¸í™”ëœ ì½”ì¹­ì„ ë°›ì•„ë³´ì„¸ìš”."
        
        if 'ê°ì •íƒœê·¸' not in recent_trades.columns:
            return "ğŸ“Š ê±°ë˜ ë°ì´í„°ì— ê°ì • ì •ë³´ê°€ ì—†ìŠµë‹ˆë‹¤."
        
        recent_emotions = recent_trades['ê°ì •íƒœê·¸'].value_counts()
        avg_recent_return = recent_trades['ìˆ˜ìµë¥ '].mean() if 'ìˆ˜ìµë¥ ' in recent_trades.columns else 0
        
        # ì‚¬ìš©ì ìœ í˜•ë³„ ë§ì¶¤ ì¡°ì–¸
        if user_type == "ê¹€êµ­ë¯¼":
            if '#ê³µí¬' in recent_emotions.index or '#íŒ¨ë‹‰' in recent_emotions.index:
                return "âš ï¸ ìµœê·¼ ê³µí¬/íŒ¨ë‹‰ ê±°ë˜ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ì˜¤ëŠ˜ì€ ì‹œì¥ì„ ê´€ì°°í•˜ê³  24ì‹œê°„ í›„ ì¬ê²€í† í•˜ì„¸ìš”."
            elif avg_recent_return < -5:
                return "ğŸ’¡ ìµœê·¼ ìˆ˜ìµë¥ ì´ ì €ì¡°í•©ë‹ˆë‹¤. ê°ì •ì  íŒë‹¨ë³´ë‹¤ëŠ” ë°ì´í„° ê¸°ë°˜ ë¶„ì„ì— ì§‘ì¤‘í•´ë³´ì„¸ìš”."
            else:
                return "âœ… ìµœê·¼ ê±°ë˜ íŒ¨í„´ì´ ì•ˆì •ì ì…ë‹ˆë‹¤. í˜„ì¬ì˜ ì‹ ì¤‘í•œ ì ‘ê·¼ì„ ìœ ì§€í•˜ì„¸ìš”."
        else:  # ë°•íˆ¬ì
            if '#ì¶”ê²©ë§¤ìˆ˜' in recent_emotions.index or '#ìš•ì‹¬' in recent_emotions.index:
                return "âš ï¸ ìµœê·¼ FOMO ê±°ë˜ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤. ì˜¤ëŠ˜ì€ ì¶©ë™ì„ ì–µì œí•˜ê³  ëƒ‰ì •í•œ íŒë‹¨ì„ í•˜ì„¸ìš”."
            elif avg_recent_return < -5:
                return "ğŸ’¡ ìµœê·¼ ìˆ˜ìµë¥ ì´ ì €ì¡°í•©ë‹ˆë‹¤. ì™¸ë¶€ ì¶”ì²œë³´ë‹¤ëŠ” ë³¸ì¸ë§Œì˜ íˆ¬ì ì›ì¹™ì„ ì„¸ì›Œë³´ì„¸ìš”."
            else:
                return "âœ… ìµœê·¼ ê±°ë˜ê°€ ê°œì„ ë˜ê³  ìˆìŠµë‹ˆë‹¤. í˜„ì¬ì˜ ì‹ ì¤‘í•œ ì ‘ê·¼ì„ ê³„ì† ìœ ì§€í•˜ì„¸ìš”."
    
    except Exception as e:
        return f"ğŸ’¡ AI ì½”ì¹­ íŒ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤: {str(e)}"

# === í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ ë”ë¯¸ í•¨ìˆ˜ë“¤ ===
def check_api_key():
    """í•˜ìœ„ í˜¸í™˜ì„±ì„ ìœ„í•œ í•¨ìˆ˜"""
    return check_gemini_api()

def call_openai_api(prompt, user_type="ê¹€êµ­ë¯¼"):
    """ë”ë¯¸ í•¨ìˆ˜ - ì‚¬ìš©í•˜ì§€ ì•ŠìŒ"""
    return "ì´ ê¸°ëŠ¥ì€ Gemini APIë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤. check_gemini_api()ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”."

def get_performance_metrics() -> Dict[str, Any]:
    """ì‹œìŠ¤í…œ ì„±ëŠ¥ ë©”íŠ¸ë¦­ ë°˜í™˜"""
    metrics = {
        'gemini_available': GEMINI_AVAILABLE,
        'sklearn_available': SKLEARN_AVAILABLE,
        'api_configured': check_gemini_api(),
        'cache_size': len(getattr(ReMinDKoreanEngine(), '_emotion_cache', {})),
        'embedding_model': 'text-embedding-004'
    }
    return metrics