#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
KB Reflex - ê±°ìš¸ ì½”ì¹­ ì‹œìŠ¤í…œ (AI Challenge í•µì‹¬ ê¸°ëŠ¥) - ê°œì„  ë²„ì „
ê³¼ê±° ê²½í—˜ì„ í˜„ì¬ ìƒí™©ê³¼ ë§¤ì¹­í•˜ì—¬ "ê±°ìš¸"ì²˜ëŸ¼ ë°˜ì„±í•  ìˆ˜ ìˆê²Œ ë„ì™€ì£¼ëŠ” AI ì‹œìŠ¤í…œ

ê°œì„ ì‚¬í•­:
- SentenceTransformer ëª¨ë¸ ìºì‹± ìµœì í™”
- ë©”ëª¨ë¦¬ ì‚¬ìš©ëŸ‰ ìµœì í™”
- ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”
- ì„¤ì • ë¶„ë¦¬ ë° í™•ì¥ì„± ê°œì„ 
- ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ì¶”ê°€
"""
import streamlit as st  
import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Tuple, Union
from datetime import datetime, timedelta
import re
from pathlib import Path
import sys
import logging
import time
from functools import lru_cache
import warnings

# ê²½ê³  ë©”ì‹œì§€ ì–µì œ
warnings.filterwarnings('ignore', category=FutureWarning)

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

# í†µí•©ëœ ë°ì´í„° ì†ŒìŠ¤ import
from db.central_data_manager import get_user_trading_history

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ================================
# [CONFIG] ì„¤ì • ê´€ë¦¬
# ================================

class MirrorCoachingConfig:
    """ê±°ìš¸ ì½”ì¹­ ì‹œìŠ¤í…œ ì„¤ì • í´ë˜ìŠ¤"""
    
    # ëª¨ë¸ ì„¤ì •
    MODEL_NAME = 'jhgan/ko-sroberta-multitask'
    MODEL_CACHE_TTL = 3600  # 1ì‹œê°„
    
    # ìœ ì‚¬ë„ ì„¤ì •
    MIN_SIMILARITY_THRESHOLD = 0.3
    DEFAULT_TOP_K = 3
    MAX_TOP_K = 10
    
    # í…ìŠ¤íŠ¸ ì²˜ë¦¬ ì„¤ì •
    MAX_TEXT_LENGTH = 500
    MIN_TEXT_LENGTH = 5
    
    # í•œêµ­ì–´ ë¶ˆìš©ì–´
    KOREAN_STOPWORDS = {
        'ê·¸ë¦¬ê³ ', 'í•˜ì§€ë§Œ', 'ê·¸ëŸ°ë°', 'ê·¸ë˜ì„œ', 'ê·¸ê²ƒ', 'ì´ê²ƒ', 'ì €ê²ƒ',
        'ìˆë‹¤', 'ì—†ë‹¤', 'ë˜ë‹¤', 'í•˜ë‹¤', 'ìˆëŠ”', 'ì—†ëŠ”', 'ëœë‹¤', 'ê·¸ëŸ°',
        'ì´ëŸ°', 'ì €ëŸ°', 'ê·¸ë¦¬ê³ ëŠ”', 'í•˜ì§€ë§Œì€', 'ê·¸ëŸ°ë°ë„'
    }
    
    # ê°ì • í‚¤ì›Œë“œ ë§¤í•‘
    EMOTION_KEYWORDS = {
        'ê³µí¬': ['ë¬´ì„œì›Œ', 'ë‘ë ¤ì›Œ', 'ë¶ˆì•ˆ', 'ê±±ì •', 'íŒ¨ë‹‰', 'í­ë½', 'ê¸‰ë½'],
        'ìš•ì‹¬': ['ìš•ì‹¬', 'ë”', 'ì¶”ê°€', 'í’€ë§¤ìˆ˜', 'ì˜¬ì¸', 'ëŒ€ë°•', 'ì­íŒŸ'],
        'í›„íšŒ': ['í›„íšŒ', 'ì•„ì‰¬ì›Œ', 'ì˜ëª»', 'ì‹¤ìˆ˜', 'ë†“ì³¤', 'ì•„ê¹Œì›Œ'],
        'í™•ì‹ ': ['í™•ì‹ ', 'í™•ì‹¤', 'í‹€ë¦¼ì—†', 'ë¶„ëª…', '100%', 'ë‹¹ì—°'],
        'ëƒ‰ì •': ['ë¶„ì„', 'íŒë‹¨', 'ê·¼ê±°', 'ë°ì´í„°', 'ê°ê´€ì ', 'ì´ì„±ì ']
    }
    
    # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
    ENABLE_PERFORMANCE_MONITORING = True
    SLOW_OPERATION_THRESHOLD = 2.0  # 2ì´ˆ ì´ìƒ ê±¸ë¦¬ëŠ” ì‘ì—… ë¡œê¹…

# ================================
# [OPTIMIZED MODEL LOADING] ëª¨ë¸ ë¡œë”© ìµœì í™”
# ================================

class ModelManager:
    """SentenceTransformer ëª¨ë¸ ê´€ë¦¬ í´ë˜ìŠ¤"""
    
    _instance = None
    _model = None
    _last_loaded = None
    
    def __new__(cls):
        if cls._instance is None:
            cls._instance = super().__new__(cls)
        return cls._instance
    
    @property
    def model(self):
        """ëª¨ë¸ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜ (ì§€ì—° ë¡œë”©)"""
        current_time = time.time()
        
        # ëª¨ë¸ì´ ì—†ê±°ë‚˜ ìºì‹œê°€ ë§Œë£Œëœ ê²½ìš° ë¡œë“œ
        if (self._model is None or 
            self._last_loaded is None or 
            current_time - self._last_loaded > MirrorCoachingConfig.MODEL_CACHE_TTL):
            
            self._load_model()
        
        return self._model
    
    def _load_model(self):
        """ëª¨ë¸ ë¡œë“œ"""
        try:
            start_time = time.time()
            logger.info(f"SentenceTransformer ëª¨ë¸ ë¡œë”© ì‹œì‘: {MirrorCoachingConfig.MODEL_NAME}")
            
            # SentenceTransformer ì§€ì—° import (ëª¨ë“ˆ ë¡œë“œ ì†ë„ ê°œì„ )
            from sentence_transformers import SentenceTransformer
            
            self._model = SentenceTransformer(MirrorCoachingConfig.MODEL_NAME)
            self._last_loaded = time.time()
            
            load_time = time.time() - start_time
            logger.info(f"ëª¨ë¸ ë¡œë”© ì™„ë£Œ ({load_time:.2f}ì´ˆ)")
            
            if MirrorCoachingConfig.ENABLE_PERFORMANCE_MONITORING and load_time > MirrorCoachingConfig.SLOW_OPERATION_THRESHOLD:
                logger.warning(f"ëª¨ë¸ ë¡œë”©ì´ ì˜ˆìƒë³´ë‹¤ ì˜¤ë˜ ê±¸ë ¸ìŠµë‹ˆë‹¤: {load_time:.2f}ì´ˆ")
                
        except Exception as e:
            logger.error(f"ëª¨ë¸ ë¡œë”© ì‹¤íŒ¨: {str(e)}")
            raise RuntimeError(f"SentenceTransformer ëª¨ë¸ì„ ë¡œë“œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {str(e)}")
    
    def clear_cache(self):
        """ëª¨ë¸ ìºì‹œ í´ë¦¬ì–´"""
        self._model = None
        self._last_loaded = None
        logger.info("ëª¨ë¸ ìºì‹œê°€ í´ë¦¬ì–´ë˜ì—ˆìŠµë‹ˆë‹¤")

# ê¸€ë¡œë²Œ ëª¨ë¸ ë§¤ë‹ˆì € ì¸ìŠ¤í„´ìŠ¤
model_manager = ModelManager()

@st.cache_resource
def get_sentence_transformer_model():
    """SentenceTransformer ëª¨ë¸ì„ ë¡œë“œí•˜ê³  ìºì‹œí•©ë‹ˆë‹¤."""
    logger.info("ğŸš€ [Cache Miss] SentenceTransformer ëª¨ë¸ì„ ìƒˆë¡œ ë¡œë“œí•©ë‹ˆë‹¤.")
    return model_manager.model

# ================================
# [PERFORMANCE MONITOR] ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
# ================================

class PerformanceMonitor:
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í´ë˜ìŠ¤"""
    
    def __init__(self, operation_name: str):
        self.operation_name = operation_name
        self.start_time = None
    
    def __enter__(self):
        self.start_time = time.time()
        return self
    
    def __exit__(self, exc_type, exc_val, exc_tb):
        if self.start_time is not None:
            elapsed = time.time() - self.start_time
            
            if MirrorCoachingConfig.ENABLE_PERFORMANCE_MONITORING:
                if elapsed > MirrorCoachingConfig.SLOW_OPERATION_THRESHOLD:
                    logger.warning(f"ëŠë¦° ì‘ì—… ê°ì§€: {self.operation_name} ({elapsed:.2f}ì´ˆ)")
                else:
                    logger.debug(f"ì‘ì—… ì™„ë£Œ: {self.operation_name} ({elapsed:.2f}ì´ˆ)")

# ================================
# [ENHANCED TEXT PROCESSING] í…ìŠ¤íŠ¸ ì²˜ë¦¬ ê°œì„ 
# ================================

class TextProcessor:
    """í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ í´ë˜ìŠ¤"""
    
    @staticmethod
    @lru_cache(maxsize=1000)  # ìì£¼ ì‚¬ìš©ë˜ëŠ” í…ìŠ¤íŠ¸ ìºì‹±
    def clean_text(text: str) -> str:
        """í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ (ìºì‹± ì ìš©)"""
        if not isinstance(text, str) or not text.strip():
            return ""
        
        # ê¸¸ì´ ì œí•œ
        if len(text) > MirrorCoachingConfig.MAX_TEXT_LENGTH:
            text = text[:MirrorCoachingConfig.MAX_TEXT_LENGTH]
        
        # ê¸°ë³¸ ì •ì œ
        text = text.lower().strip()
        
        # íŠ¹ìˆ˜ë¬¸ì ì œê±° (í•œê¸€, ì˜ë¬¸, ìˆ«ì, ê³µë°±ë§Œ ìœ ì§€)
        text = re.sub(r'[^\w\sê°€-í£]', ' ', text)
        
        # ì¤‘ë³µ ê³µë°± ì œê±°
        text = re.sub(r'\s+', ' ', text)
        
        # ë¶ˆìš©ì–´ ì œê±°
        words = text.split()
        words = [word for word in words if word not in MirrorCoachingConfig.KOREAN_STOPWORDS]
        
        result = ' '.join(words)
        
        # ìµœì†Œ ê¸¸ì´ í™•ì¸
        if len(result.strip()) < MirrorCoachingConfig.MIN_TEXT_LENGTH:
            return ""
        
        return result
    
    @staticmethod
    def extract_keywords(text: str, max_keywords: int = 5) -> List[str]:
        """í‚¤ì›Œë“œ ì¶”ì¶œ"""
        cleaned = TextProcessor.clean_text(text)
        if not cleaned:
            return []
        
        words = cleaned.split()
        # ê¸¸ì´ê°€ 2 ì´ìƒì¸ ë‹¨ì–´ë“¤ì„ í‚¤ì›Œë“œë¡œ ì¶”ì¶œ
        keywords = [word for word in words if len(word) >= 2]
        
        # ë¹ˆë„ìˆ˜ ê¸°ë°˜ ì •ë ¬ (ì‹¤ì œë¡œëŠ” TF-IDF ë“±ì„ ì‚¬ìš©í•  ìˆ˜ ìˆìŒ)
        from collections import Counter
        word_counts = Counter(keywords)
        
        return [word for word, count in word_counts.most_common(max_keywords)]

# ================================
# [MAIN COACHING CLASS] ë©”ì¸ ì½”ì¹­ í´ë˜ìŠ¤
# ================================

class MirrorCoaching:
    """
    ê±°ìš¸ ì½”ì¹­ ì‹œìŠ¤í…œ - ê°œì„  ë²„ì „
    
    ê°œì„ ì‚¬í•­:
    1. ì„±ëŠ¥ ìµœì í™” ë° ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ê°œì„ 
    2. ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”
    3. ìºì‹± ì „ëµ ê°œì„ 
    4. ì„¤ì • ê´€ë¦¬ ë¶„ë¦¬
    """
    
    def __init__(self):
        """ì´ˆê¸°í™”"""
        self.text_processor = TextProcessor()
        self._cache = {}  # ë‚´ë¶€ ìºì‹œ
        logger.info("MirrorCoaching ì‹œìŠ¤í…œ ì´ˆê¸°í™” ì™„ë£Œ")
    
    def _convert_to_dataframe(self, trades_list: List[Dict]) -> pd.DataFrame:
        """ê±°ë˜ ë°ì´í„° ë¦¬ìŠ¤íŠ¸ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜ (ì—ëŸ¬ ì²˜ë¦¬ ê°•í™”)"""
        if not trades_list:
            return pd.DataFrame()
        
        try:
            df = pd.DataFrame(trades_list)
            
            # ë‚ ì§œ ì»¬ëŸ¼ ì²˜ë¦¬
            if 'ê±°ë˜ì¼ì‹œ' in df.columns:
                df['ê±°ë˜ì¼ì‹œ'] = pd.to_datetime(df['ê±°ë˜ì¼ì‹œ'], errors='coerce')
                # ìœ íš¨í•˜ì§€ ì•Šì€ ë‚ ì§œ ì œê±°
                df = df.dropna(subset=['ê±°ë˜ì¼ì‹œ'])
            
            # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸ ë° ê¸°ë³¸ê°’ ì„¤ì •
            required_columns = {
                'ë©”ëª¨': '',
                'ìˆ˜ìµë¥ ': 0.0,
                'ê°ì •íƒœê·¸': '',
                'ì¢…ëª©ëª…': 'ì•Œìˆ˜ì—†ìŒ'
            }
            
            for col, default_val in required_columns.items():
                if col not in df.columns:
                    df[col] = default_val
                else:
                    df[col] = df[col].fillna(default_val)
            
            return df
            
        except Exception as e:
            logger.error(f"DataFrame ë³€í™˜ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return pd.DataFrame()
    
    def initialize_for_user(self, username: str) -> Dict:
        """ì‚¬ìš©ì ì´ˆê¸°í™” ë° ê¸°ë³¸ ì¸ì‚¬ì´íŠ¸ ìƒì„± (ì„±ëŠ¥ ê°œì„ )"""
        try:
            with PerformanceMonitor(f"ì‚¬ìš©ì ì´ˆê¸°í™”: {username}"):
                # ìºì‹œ í™•ì¸
                cache_key = f"user_init_{username}"
                if cache_key in self._cache:
                    cached_result = self._cache[cache_key]
                    if (datetime.now() - cached_result['timestamp']).seconds < 300:  # 5ë¶„ ìºì‹œ
                        logger.debug(f"ìºì‹œì—ì„œ ì‚¬ìš©ì ë°ì´í„° ë°˜í™˜: {username}")
                        return cached_result['data']
                
                # í†µí•©ëœ ë°ì´í„° ì†ŒìŠ¤ì—ì„œ ê±°ë˜ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                trades_list = get_user_trading_history(username)
                trades_data = self._convert_to_dataframe(trades_list)
                
                if trades_data.empty:
                    result = {
                        'status': 'no_data',
                        'message': f'{username}ë‹˜ì˜ ê±°ë˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.',
                        'insights': {},
                        'performance_info': {
                            'total_trades': 0,
                            'processing_time': 0
                        }
                    }
                else:
                    # ê¸°ë³¸ íŒ¨í„´ ë¶„ì„
                    base_insights = self._analyze_base_patterns(trades_data)
                    
                    result = {
                        'status': 'initialized',
                        'message': f'{username}ë‹˜ì˜ ê±°ë˜ íŒ¨í„´ ë¶„ì„ ì™„ë£Œ',
                        'insights': base_insights,
                        'total_trades': len(trades_data),
                        'performance_info': {
                            'total_trades': len(trades_data),
                            'processing_time': time.time()
                        }
                    }
                
                # ê²°ê³¼ ìºì‹±
                self._cache[cache_key] = {
                    'data': result,
                    'timestamp': datetime.now()
                }
                
                return result
                
        except Exception as e:
            logger.error(f"ì‚¬ìš©ì ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return {
                'status': 'error',
                'message': f'ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜: {str(e)}',
                'insights': {}
            }
    
    def find_similar_experiences(
        self, 
        current_situation: str, 
        username: str, 
        top_k: int = None
    ) -> List[Dict]:
        """
        í˜„ì¬ ìƒí™©ê³¼ ìœ ì‚¬í•œ ê³¼ê±° ê²½í—˜ ì°¾ê¸° (ì„±ëŠ¥ ìµœì í™”)
        
        Args:
            current_situation: í˜„ì¬ íˆ¬ì ìƒí™©/ìƒê°
            username: ì‚¬ìš©ìëª…
            top_k: ë°˜í™˜í•  ìœ ì‚¬ ê²½í—˜ ê°œìˆ˜ (ê¸°ë³¸ê°’: configì—ì„œ ì„¤ì •)
        
        Returns:
            ìœ ì‚¬í•œ ê³¼ê±° ê²½í—˜ ë¦¬ìŠ¤íŠ¸
        """
        if top_k is None:
            top_k = MirrorCoachingConfig.DEFAULT_TOP_K
        
        top_k = min(top_k, MirrorCoachingConfig.MAX_TOP_K)  # ìµœëŒ€ê°’ ì œí•œ
        
        try:
            with PerformanceMonitor(f"ìœ ì‚¬ ê²½í—˜ íƒìƒ‰: {username}"):
                # ì…ë ¥ ê²€ì¦
                cleaned_current = self.text_processor.clean_text(current_situation)
                if not cleaned_current:
                    logger.warning("í˜„ì¬ ìƒí™© í…ìŠ¤íŠ¸ê°€ ìœ íš¨í•˜ì§€ ì•ŠìŠµë‹ˆë‹¤")
                    return []
                
                # í†µí•©ëœ ë°ì´í„° ì†ŒìŠ¤ì—ì„œ ê±°ë˜ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
                trades_list = get_user_trading_history(username)
                trades_data = self._convert_to_dataframe(trades_list)
                
                if trades_data.empty:
                    return []
                
                # ë©”ëª¨ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬ (ë²¡í„°í™”)
                past_memos = trades_data['ë©”ëª¨'].astype(str).tolist()
                cleaned_memos = [self.text_processor.clean_text(memo) for memo in past_memos]
                
                # ë¹ˆ ë©”ëª¨ í•„í„°ë§
                valid_indices = [i for i, memo in enumerate(cleaned_memos) if memo.strip()]
                valid_memos = [cleaned_memos[i] for i in valid_indices]
                
                if not valid_memos:
                    logger.info(f"ìœ íš¨í•œ ë©”ëª¨ê°€ ì—†ìŠµë‹ˆë‹¤: {username}")
                    return []
                
                # ëª¨ë¸ ë¡œë“œ ë° ì„ë² ë”© ìƒì„±
                model = get_sentence_transformer_model()
                
                # ë°°ì¹˜ ì²˜ë¦¬ë¡œ ì„±ëŠ¥ ê°œì„ 
                try:
                    current_embedding = model.encode([cleaned_current], show_progress_bar=False)
                    past_embeddings = model.encode(valid_memos, show_progress_bar=False)
                except Exception as e:
                    logger.error(f"ì„ë² ë”© ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
                    return []
                
                # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
                import sentence_transformers.util
                similarities = sentence_transformers.util.pytorch_cos_sim(
                    current_embedding, past_embeddings
                )[0]
                
                # NumPy ë°°ì—´ë¡œ ë³€í™˜í•˜ì—¬ ì •ë ¬
                similarities_np = similarities.cpu().numpy()
                
                # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ê³  ìƒìœ„ kê°œ ì„ íƒ
                top_indices = np.argsort(similarities_np)[::-1][:top_k]
                
                similar_experiences = []
                for idx in top_indices:
                    similarity_score = float(similarities_np[idx])
                    if similarity_score > MirrorCoachingConfig.MIN_SIMILARITY_THRESHOLD:
                        original_idx = valid_indices[idx]
                        trade_info = trades_data.iloc[original_idx]
                        
                        similar_experiences.append({
                            'trade_data': trade_info.to_dict(),
                            'similarity_score': similarity_score,
                            'insight_type': self._determine_insight_type(trade_info),
                            'key_lesson': self._extract_key_lesson(trade_info),
                            'keywords': self.text_processor.extract_keywords(trade_info.get('ë©”ëª¨', ''))
                        })
                
                logger.info(f"ìœ ì‚¬ ê²½í—˜ {len(similar_experiences)}ê°œ ë°œê²¬: {username}")
                return similar_experiences
                
        except Exception as e:
            logger.error(f"ìœ ì‚¬ ê²½í—˜ íƒìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return []
    
    def generate_hybrid_coaching(self, current_trade: dict, similar_experiences: list) -> dict:
        """
        í•˜ì´ë¸Œë¦¬ë“œ ë°ì´í„° ì£¼ì…í˜• ì½”ì¹­ ë©”ì‹œì§€ ìƒì„± (ê°œì„  ë²„ì „)
        """
        try:
            with PerformanceMonitor("ì½”ì¹­ ë©”ì‹œì§€ ìƒì„±"):
                # 1. ìœ ì‚¬ ê²½í—˜ì´ ì—†ëŠ” ê²½ìš° - ê°œì„ ëœ ê¸°ë³¸ ë©”ì‹œì§€
                if not similar_experiences:
                    return {
                        "analysis": "ìƒˆë¡œìš´ íŒ¨í„´ì˜ ê±°ë˜ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.",
                        "message": "ì´ë²ˆ ê±°ë˜ëŠ” ë‹¹ì‹ ë§Œì˜ íˆ¬ì ì›ì¹™ì„ ë§Œë“¤ì–´ê°ˆ ì¢‹ì€ ê¸°íšŒì…ë‹ˆë‹¤. ì‹ ì¤‘í•˜ê²Œ ì ‘ê·¼í•´ë³´ì„¸ìš”.",
                        "question": "ì´ë²ˆ ê²°ì •ì— ê°€ì¥ í° ì˜í–¥ì„ ë¯¸ì¹œ ë‹¨ í•˜ë‚˜ì˜ ìš”ì¸ì€ ë¬´ì—‡ì¸ê°€ìš”?",
                        "confidence": "low",
                        "suggestion": "ê±°ë˜ í›„ ë³µê¸°ë¥¼ í†µí•´ íŒ¨í„´ì„ ì¶•ì í•´ë³´ì„¸ìš”."
                    }
                
                # 2. ê°€ì¥ ìœ ì‚¬í•œ ê³¼ê±° ê±°ë˜ ë°ì´í„° ì¶”ì¶œ
                best_match = similar_experiences[0]
                past_trade = best_match['trade_data']
                similarity_score = best_match['similarity_score']
                
                # 3. ì‹ ë¢°ë„ ê¸°ë°˜ ë©”ì‹œì§€ ì¡°ì •
                confidence_level = "high" if similarity_score > 0.7 else "medium" if similarity_score > 0.5 else "low"
                
                # 4. ì„±ê³¼ ê¸°ë°˜ í…œí”Œë¦¿ ì„ íƒ
                if past_trade.get('ìˆ˜ìµë¥ ', 0) >= 0:
                    # ì„±ê³µ ê²½í—˜ ê¸°ë°˜ í…œí”Œë¦¿
                    analysis = (
                        f"í˜„ì¬ '{current_trade.get('ì¢…ëª©ëª…', 'í•´ë‹¹ ì¢…ëª©')}'ì— ëŒ€í•œ ê³ ë¯¼ì€ "
                        f"ê³¼ê±° '{past_trade.get('ì¢…ëª©ëª…', 'N/A')}'ì—ì„œ ì„±ê³µí–ˆë˜ ê²½í—˜ê³¼ "
                        f"{similarity_score:.0%} ìœ ì‚¬í•©ë‹ˆë‹¤."
                    )
                    
                    message = (
                        f"ê³¼ê±° í•´ë‹¹ ê±°ë˜ì—ì„œ '{past_trade.get('ë©”ëª¨', 'íŠ¹ë³„í•œ íŒë‹¨')}' ë¼ëŠ” íŒë‹¨ìœ¼ë¡œ "
                        f"{past_trade.get('ìˆ˜ìµë¥ ', 0):.1f}%ì˜ ìˆ˜ìµì„ ì–»ìœ¼ì…¨ìŠµë‹ˆë‹¤. "
                        f"ì„±ê³µ ìš”ì¸ì„ í˜„ì¬ ìƒí™©ì— ì ìš©í•  ìˆ˜ ìˆì„ì§€ ê²€í† í•´ë³´ì„¸ìš”."
                    )
                    
                    question = "ê³¼ê±°ì˜ ì„±ê³µ ê²½í—˜ê³¼ ë¹„êµí–ˆì„ ë•Œ, í˜„ì¬ ìƒí™©ì—ì„œ ë†“ì¹˜ê³  ìˆëŠ” ìš”ì†ŒëŠ” ë¬´ì—‡ì¸ê°€ìš”?"
                    
                else:
                    # ì‹¤íŒ¨ ê²½í—˜ ê¸°ë°˜ í…œí”Œë¦¿
                    analysis = (
                        f"í˜„ì¬ ìƒí™©ì€ ê³¼ê±° '{past_trade.get('ì¢…ëª©ëª…', 'N/A')}' ê±°ë˜ì—ì„œ "
                        f"ì†ì‹¤ì„ ê²½í—˜í–ˆë˜ ìƒí™©ê³¼ {similarity_score:.0%} ìœ ì‚¬í•©ë‹ˆë‹¤."
                    )
                    
                    message = (
                        f"ê³¼ê±° '{past_trade.get('ë©”ëª¨', 'ë‹¹ì‹œì˜ íŒë‹¨')}' ë¼ê³  íŒë‹¨í–ˆë˜ ê±°ë˜ëŠ” "
                        f"{abs(past_trade.get('ìˆ˜ìµë¥ ', 0)):.1f}%ì˜ ì†ì‹¤ë¡œ ì´ì–´ì¡ŒìŠµë‹ˆë‹¤. "
                        f"ê°™ì€ ì‹¤ìˆ˜ë¥¼ ë°˜ë³µí•˜ì§€ ì•Šê¸° ìœ„í•´ ì‹ ì¤‘í•œ ê²€í† ê°€ í•„ìš”í•©ë‹ˆë‹¤."
                    )
                    
                    question = "ê³¼ê±°ì˜ ì‹¤ìˆ˜ë¥¼ ë°˜ë³µí•˜ì§€ ì•Šê¸° ìœ„í•´ ì§€ê¸ˆ ë‹¹ì¥ ë‹¤ë¥´ê²Œ í–‰ë™í•´ì•¼ í•  ê²ƒì€ ë¬´ì—‡ì¼ê¹Œìš”?"
                
                # 5. ì¶”ê°€ ì¸ì‚¬ì´íŠ¸ ì œê³µ
                suggestion = self._generate_coaching_suggestion(similar_experiences, confidence_level)
                
                return {
                    "analysis": analysis,
                    "message": message,
                    "question": question,
                    "confidence": confidence_level,
                    "similarity_score": similarity_score,
                    "suggestion": suggestion,
                    "related_emotions": [exp['trade_data'].get('ê°ì •íƒœê·¸', '') for exp in similar_experiences[:3]]
                }
                
        except Exception as e:
            logger.error(f"ì½”ì¹­ ë©”ì‹œì§€ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return {
                "analysis": "ì‹œìŠ¤í…œ ì˜¤ë¥˜ë¡œ ë¶„ì„ì„ ì™„ë£Œí•  ìˆ˜ ì—†ìŠµë‹ˆë‹¤.",
                "message": "ì ì‹œ í›„ ë‹¤ì‹œ ì‹œë„í•´ë³´ì„¸ìš”.",
                "question": "í˜„ì¬ ìƒí™©ì„ ê°ê´€ì ìœ¼ë¡œ íŒë‹¨í•´ë³´ì„¸ìš”.",
                "confidence": "error"
            }
    
    def _generate_coaching_suggestion(self, similar_experiences: List[Dict], confidence_level: str) -> str:
        """ì½”ì¹­ ì œì•ˆ ìƒì„±"""
        if confidence_level == "high":
            return "ê³¼ê±° ê²½í—˜ê³¼ ë§¤ìš° ìœ ì‚¬í•œ íŒ¨í„´ì…ë‹ˆë‹¤. ê³¼ê±°ì˜ êµí›ˆì„ ì ê·¹ í™œìš©í•˜ì„¸ìš”."
        elif confidence_level == "medium":
            return "ê³¼ê±° ê²½í—˜ì„ ì°¸ê³ í•˜ë˜, í˜„ì¬ ìƒí™©ì˜ ì°¨ì´ì ë„ í•¨ê»˜ ê³ ë ¤í•˜ì„¸ìš”."
        else:
            return "ê³¼ê±° ê²½í—˜ì´ ì œí•œì ì…ë‹ˆë‹¤. ë³´ìˆ˜ì ì¸ ì ‘ê·¼ì„ ê¶Œì¥í•©ë‹ˆë‹¤."
    
    def generate_mirror_questions(
        self, 
        similar_experiences: List[Dict],
        current_situation: str,
        max_questions: int = 5
    ) -> List[str]:
        """
        ê±°ìš¸ ì§ˆë¬¸ ìƒì„± - ê°œì„ ëœ ë²„ì „
        """
        try:
            questions = []
            
            if not similar_experiences:
                # ê¸°ë³¸ ì§ˆë¬¸ ì„¸íŠ¸ (ì‹ ê·œ ì‚¬ìš©ììš©)
                questions.extend([
                    "ğŸ¤” ì´ë²ˆ íˆ¬ì ê²°ì •ì˜ ê°€ì¥ ëª…í™•í•œ ê·¼ê±°ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
                    "âš–ï¸ ì´ íˆ¬ìì˜ ìœ„í—˜ê³¼ ê¸°íšŒë¥¼ ì–´ë–»ê²Œ í‰ê°€í•˜ì‹œë‚˜ìš”?",
                    "ğŸ¯ 6ê°œì›” í›„ì˜ ë‹¹ì‹ ì—ê²Œ ì´ ê²°ì •ì„ ì–´ë–»ê²Œ ì„¤ëª…í•˜ì‹œê² ë‚˜ìš”?",
                    "ğŸ’° ìµœì•…ì˜ ê²½ìš° ì†ì‹¤ì„ ê°ë‹¹í•  ìˆ˜ ìˆëŠ” ê¸ˆì•¡ì¸ê°€ìš”?",
                    "ğŸ§­ ì´ ê±°ë˜ê°€ ë‹¹ì‹ ì˜ íˆ¬ì ì›ì¹™ì— ë¶€í•©í•˜ë‚˜ìš”?"
                ])
                return questions[:max_questions]
            
            # ê³¼ê±° ê²½í—˜ ê¸°ë°˜ ë§ì¶¤í˜• ì§ˆë¬¸
            success_count = sum(1 for exp in similar_experiences if exp['trade_data'].get('ìˆ˜ìµë¥ ', 0) > 0)
            failure_count = len(similar_experiences) - success_count
            
            # ì„±ê³µ/ì‹¤íŒ¨ ë¹„ìœ¨ì— ë”°ë¥¸ ì§ˆë¬¸ ì¡°ì •
            for i, exp in enumerate(similar_experiences[:2]):  # ìƒìœ„ 2ê°œ ê²½í—˜ë§Œ ì‚¬ìš©
                trade = exp['trade_data']
                similarity = exp['similarity_score']
                
                if trade.get('ìˆ˜ìµë¥ ', 0) < 0:  # ì†ì‹¤ ê²½í—˜
                    questions.append(
                        f"ğŸ“‰ ê³¼ê±° {trade.get('ì¢…ëª©ëª…', 'N/A')} ê±°ë˜ì—ì„œ "
                        f"{abs(trade.get('ìˆ˜ìµë¥ ', 0)):.1f}% ì†ì‹¤ì„ ê²½í—˜í•˜ì…¨ìŠµë‹ˆë‹¤. "
                        f"ê·¸ë•Œì™€ ì§€ê¸ˆì˜ ê°€ì¥ í° ì°¨ì´ì ì€ ë¬´ì—‡ì¸ê°€ìš”? (ìœ ì‚¬ë„: {similarity:.0%})"
                    )
                    
                    emotion = trade.get('ê°ì •íƒœê·¸', '')
                    if emotion in ['#ê³µí¬', '#íŒ¨ë‹‰', '#ë¶ˆì•ˆ']:
                        questions.append(f"ğŸ˜° ê³¼ê±° {emotion} ìƒíƒœì—ì„œì˜ ê²°ì •ì„ ì–´ë–»ê²Œ ê°œì„ í•  ìˆ˜ ìˆì„ê¹Œìš”?")
                        
                else:  # ìˆ˜ìµ ê²½í—˜
                    questions.append(
                        f"ğŸ“ˆ ê³¼ê±° {trade.get('ì¢…ëª©ëª…', 'N/A')} ê±°ë˜ì—ì„œ "
                        f"{trade.get('ìˆ˜ìµë¥ ', 0):.1f}% ìˆ˜ìµì„ ë‚´ì‹  ì„±ê³µ ìš”ì¸ì„ "
                        f"ì´ë²ˆì—ë„ ì ìš©í•  ìˆ˜ ìˆì„ê¹Œìš”? (ìœ ì‚¬ë„: {similarity:.0%})"
                    )
            
            # ê°ì • íŒ¨í„´ ê¸°ë°˜ ì§ˆë¬¸
            emotion_pattern = self._detect_dominant_emotion(similar_experiences)
            if emotion_pattern:
                questions.append(
                    f"ğŸ§  ìµœê·¼ '{emotion_pattern}' íŒ¨í„´ì´ ë°˜ë³µë˜ê³  ìˆìŠµë‹ˆë‹¤. "
                    f"ì´ë²ˆì—” ì–´ë–»ê²Œ ë‹¤ë¥´ê²Œ ì ‘ê·¼í•˜ì‹œê² ë‚˜ìš”?"
                )
            
            # ê¸°ë³¸ ì„±ì°° ì§ˆë¬¸ ì¶”ê°€
            base_questions = [
                "â° ì´ íˆ¬ì ê²°ì •ì„ 24ì‹œê°„ í›„ì—ë„ ê°™ì€ ë§ˆìŒìœ¼ë¡œ í•  ìˆ˜ ìˆë‚˜ìš”?",
                "ğŸ“Š ê°ê´€ì  ë°ì´í„°ì™€ ì£¼ê´€ì  ëŠë‚Œ ì¤‘ ì–´ëŠ ìª½ì— ë” ì˜ì¡´í•˜ê³  ìˆë‚˜ìš”?",
                "ğŸª ë§Œì•½ ì´ íˆ¬ìê°€ ì‹¤íŒ¨í•œë‹¤ë©´, ê°€ì¥ í° ì›ì¸ì€ ë¬´ì—‡ì¼ ê²ƒ ê°™ë‚˜ìš”?",
                "ğŸª ì§€ê¸ˆì˜ ê²°ì •ì„ ê°€ì¥ ì¹œí•œ ì¹œêµ¬ì—ê²Œë„ ê¶Œí•  ìˆ˜ ìˆë‚˜ìš”?"
            ]
            
            # ì„±ê³µ/ì‹¤íŒ¨ ë¹„ìœ¨ì— ë”°ë¼ ì¶”ê°€ ì§ˆë¬¸ ì„ íƒ
            if failure_count > success_count:
                base_questions.insert(0, "ğŸš¨ ê³¼ê±° ì‹¤íŒ¨ íŒ¨í„´ì´ ë§ì´ ê°ì§€ë©ë‹ˆë‹¤. ì •ë§ ì§€ê¸ˆì´ ì ì ˆí•œ íƒ€ì´ë°ì¸ê°€ìš”?")
            
            questions.extend(base_questions)
            
            return questions[:max_questions]
            
        except Exception as e:
            logger.error(f"ê±°ìš¸ ì§ˆë¬¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return [
                "ğŸ¤” í˜„ì¬ ìƒí™©ì„ ê°ê´€ì ìœ¼ë¡œ íŒë‹¨í•´ë³´ì„¸ìš”.",
                "âš–ï¸ ìœ„í—˜ê³¼ ê¸°íšŒë¥¼ ê· í˜•ìˆê²Œ ê³ ë ¤í•˜ê³  ìˆë‚˜ìš”?",
                "ğŸ¯ ì´ ê²°ì •ì˜ ëª…í™•í•œ ê·¼ê±°ê°€ ìˆë‚˜ìš”?"
            ]
    
    def _detect_dominant_emotion(self, similar_experiences: List[Dict]) -> str:
        """ì§€ë°°ì  ê°ì • íŒ¨í„´ ê°ì§€ (ê°œì„ ëœ ë²„ì „)"""
        if not similar_experiences:
            return ""
        
        emotions = []
        for exp in similar_experiences:
            emotion = exp['trade_data'].get('ê°ì •íƒœê·¸', '')
            if emotion:
                emotions.append(emotion)
        
        if not emotions:
            return ""
        
        # ë¹ˆë„ìˆ˜ ê³„ì‚°
        from collections import Counter
        emotion_counts = Counter(emotions)
        
        # ê°€ì¥ ë¹ˆë²ˆí•œ ê°ì • ë°˜í™˜ (ë™ì ì¼ ê²½ìš° ì²« ë²ˆì§¸)
        if emotion_counts:
            most_common = emotion_counts.most_common(1)[0]
            if most_common[1] >= 2:  # ìµœì†Œ 2ë²ˆ ì´ìƒ ë‚˜íƒ€ë‚œ ê°ì •ë§Œ
                return most_common[0]
        
        return ""
    
    def create_mirror_report(
        self, 
        username: str, 
        current_situation: str,
        similar_experiences: List[Dict] = None
    ) -> Dict:
        """ì¢…í•© ê±°ìš¸ ë¦¬í¬íŠ¸ ìƒì„± (ê°œì„ ëœ ë²„ì „)"""
        try:
            with PerformanceMonitor(f"ê±°ìš¸ ë¦¬í¬íŠ¸ ìƒì„±: {username}"):
                report = {
                    'timestamp': datetime.now(),
                    'username': username,
                    'current_situation': current_situation,
                    'mirror_analysis': {},
                    'performance_info': {}
                }
                
                # ìœ ì‚¬ ê²½í—˜ì´ ì œê³µë˜ì§€ ì•Šì•˜ë‹¤ë©´ ì°¾ê¸°
                if similar_experiences is None:
                    similar_experiences = self.find_similar_experiences(current_situation, username)
                
                if similar_experiences:
                    report['mirror_analysis']['similar_count'] = len(similar_experiences)
                    report['mirror_analysis']['experiences'] = similar_experiences
                    
                    # íŒ¨í„´ ìš”ì•½
                    success_count = sum(1 for exp in similar_experiences if exp['trade_data'].get('ìˆ˜ìµë¥ ', 0) > 0)
                    failure_count = len(similar_experiences) - success_count
                    
                    report['mirror_analysis']['pattern_summary'] = {
                        'success_cases': success_count,
                        'failure_cases': failure_count,
                        'dominant_emotion': self._detect_dominant_emotion(similar_experiences),
                        'avg_similarity': np.mean([exp['similarity_score'] for exp in similar_experiences])
                    }
                    
                    # ê±°ìš¸ ì§ˆë¬¸ ìƒì„±
                    report['mirror_questions'] = self.generate_mirror_questions(
                        similar_experiences, current_situation
                    )
                    
                    # í•µì‹¬ ì¸ì‚¬ì´íŠ¸
                    report['key_insights'] = self._generate_key_insights(similar_experiences)
                    
                    # ìœ„í—˜ë„ í‰ê°€
                    report['risk_assessment'] = self._assess_risk_level(similar_experiences)
                    
                else:
                    report['mirror_analysis']['message'] = "ìœ ì‚¬í•œ ê³¼ê±° ê²½í—˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                    report['mirror_questions'] = self.generate_mirror_questions([], current_situation)
                    report['key_insights'] = ["ìƒˆë¡œìš´ íŒ¨í„´ì˜ ê±°ë˜ì…ë‹ˆë‹¤. ì‹ ì¤‘í•œ ì ‘ê·¼ì„ ê¶Œì¥í•©ë‹ˆë‹¤."]
                    report['risk_assessment'] = {'level': 'unknown', 'score': 50}
                
                # ì„±ëŠ¥ ì •ë³´ ì¶”ê°€
                report['performance_info'] = {
                    'similar_experiences_count': len(similar_experiences),
                    'processing_timestamp': datetime.now(),
                    'cache_status': 'processed'
                }
                
                return report
                
        except Exception as e:
            logger.error(f"ê±°ìš¸ ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return {
                'timestamp': datetime.now(),
                'username': username,
                'error': f"ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}",
                'mirror_questions': ["í˜„ì¬ ìƒí™©ì„ ê°ê´€ì ìœ¼ë¡œ íŒë‹¨í•´ë³´ì„¸ìš”."]
            }
    
    def _assess_risk_level(self, similar_experiences: List[Dict]) -> Dict:
        """ìœ„í—˜ë„ í‰ê°€"""
        if not similar_experiences:
            return {'level': 'unknown', 'score': 50, 'reason': 'ê³¼ê±° ë°ì´í„° ë¶€ì¡±'}
        
        # ì†ì‹¤ ê±°ë˜ ë¹„ìœ¨ ê³„ì‚°
        loss_count = sum(1 for exp in similar_experiences if exp['trade_data'].get('ìˆ˜ìµë¥ ', 0) < 0)
        loss_ratio = loss_count / len(similar_experiences)
        
        # í‰ê·  ì†ì‹¤ë¥  ê³„ì‚°
        losses = [exp['trade_data'].get('ìˆ˜ìµë¥ ', 0) for exp in similar_experiences if exp['trade_data'].get('ìˆ˜ìµë¥ ', 0) < 0]
        avg_loss = np.mean(losses) if losses else 0
        
        # ìœ„í—˜ ì ìˆ˜ ê³„ì‚° (0-100)
        risk_score = 50  # ê¸°ë³¸ê°’
        risk_score += loss_ratio * 30  # ì†ì‹¤ ë¹„ìœ¨ ê°€ì¤‘ì¹˜
        if avg_loss < -10:
            risk_score += 20  # í° ì†ì‹¤ ê²½í—˜ ì‹œ ì¶”ê°€ ìœ„í—˜
        
        # ê°ì • íŒ¨í„´ ìœ„í—˜ë„
        risky_emotions = ['#ê³µí¬', '#íŒ¨ë‹‰', '#ìš•ì‹¬', '#ì¶”ê²©ë§¤ìˆ˜']
        emotion_risk = sum(1 for exp in similar_experiences if exp['trade_data'].get('ê°ì •íƒœê·¸', '') in risky_emotions)
        risk_score += (emotion_risk / len(similar_experiences)) * 20
        
        risk_score = min(100, max(0, risk_score))
        
        # ìœ„í—˜ ë“±ê¸‰ ê²°ì •
        if risk_score >= 80:
            level = 'very_high'
        elif risk_score >= 65:
            level = 'high'
        elif risk_score >= 35:
            level = 'medium'
        else:
            level = 'low'
        
        return {
            'level': level,
            'score': round(risk_score, 1),
            'loss_ratio': round(loss_ratio * 100, 1),
            'avg_loss': round(avg_loss, 2) if avg_loss != 0 else 0,
            'reason': f"ê³¼ê±° ìœ ì‚¬ ìƒí™©ì—ì„œ {loss_ratio:.0%}ì˜ ì†ì‹¤ í™•ë¥ "
        }
    
    # ================================
    # [HELPER METHODS] ê¸°ì¡´ ë©”ì†Œë“œë“¤ (ìµœì í™”)
    # ================================
    
    def _analyze_base_patterns(self, trades_data: pd.DataFrame) -> Dict:
        """ê¸°ë³¸ ê±°ë˜ íŒ¨í„´ ë¶„ì„ (ë©”ëª¨ë¦¬ ìµœì í™”)"""
        try:
            patterns = {}
            
            # ë°ì´í„°ê°€ ë„ˆë¬´ ì ìœ¼ë©´ ê°„ë‹¨í•œ ë¶„ì„ë§Œ
            if len(trades_data) < 5:
                return {
                    'message': 'ë¶„ì„í•˜ê¸°ì— ê±°ë˜ ë°ì´í„°ê°€ ë¶€ì¡±í•©ë‹ˆë‹¤.',
                    'trade_count': len(trades_data)
                }
            
            # 1. ê°ì •ë³„ ì„±ê³¼ ë¶„ì„ (ìƒìœ„ 5ê°œë§Œ)
            if 'ê°ì •íƒœê·¸' in trades_data.columns and 'ìˆ˜ìµë¥ ' in trades_data.columns:
                emotion_performance = trades_data.groupby('ê°ì •íƒœê·¸')['ìˆ˜ìµë¥ '].agg(['mean', 'count']).round(2)
                emotion_performance = emotion_performance.nlargest(5, 'count')  # ìƒìœ„ 5ê°œë§Œ
                patterns['emotion_performance'] = emotion_performance.to_dict('index')
            
            # 2. ì›”ë³„ ê±°ë˜ íŒ¨í„´ (ìµœê·¼ 12ê°œì›”ë§Œ)
            if 'ê±°ë˜ì¼ì‹œ' in trades_data.columns:
                trades_data['month'] = pd.to_datetime(trades_data['ê±°ë˜ì¼ì‹œ']).dt.month
                monthly_pattern = trades_data.groupby('month')['ìˆ˜ìµë¥ '].agg(['mean', 'count']).round(2)
                patterns['monthly_pattern'] = monthly_pattern.to_dict('index')
            
            # 3. ì¢…ëª©ë³„ ì„±ê³¼ (ìƒìœ„ 10ê°œë§Œ)
            if 'ì¢…ëª©ëª…' in trades_data.columns:
                stock_performance = trades_data.groupby('ì¢…ëª©ëª…')['ìˆ˜ìµë¥ '].agg(['mean', 'count']).round(2)
                stock_performance = stock_performance.nlargest(10, 'count')  # ìƒìœ„ 10ê°œë§Œ
                patterns['stock_performance'] = stock_performance.to_dict('index')
            
            # 4. ì „ì²´ í†µê³„
            patterns['overall_stats'] = {
                'total_trades': len(trades_data),
                'win_rate': round((trades_data['ìˆ˜ìµë¥ '] > 0).mean() * 100, 1),
                'avg_return': round(trades_data['ìˆ˜ìµë¥ '].mean(), 2),
                'best_return': round(trades_data['ìˆ˜ìµë¥ '].max(), 2),
                'worst_return': round(trades_data['ìˆ˜ìµë¥ '].min(), 2)
            }
            
            return patterns
            
        except Exception as e:
            logger.error(f"ê¸°ë³¸ íŒ¨í„´ ë¶„ì„ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return {'error': f'íŒ¨í„´ ë¶„ì„ ì‹¤íŒ¨: {str(e)}'}
    
    def _determine_insight_type(self, trade_info: pd.Series) -> str:
        """ì¸ì‚¬ì´íŠ¸ ìœ í˜• ê²°ì •"""
        try:
            return_pct = trade_info.get('ìˆ˜ìµë¥ ', 0)
            emotion = trade_info.get('ê°ì •íƒœê·¸', '')
            
            if return_pct > 10:
                return "success_pattern"
            elif return_pct < -10:
                return "failure_pattern" 
            elif emotion in ['#ê³µí¬', '#íŒ¨ë‹‰']:
                return "emotional_pattern"
            else:
                return "neutral_pattern"
        except Exception:
            return "unknown_pattern"
    
    def _extract_key_lesson(self, trade_info: pd.Series) -> str:
        """í•µì‹¬ êµí›ˆ ì¶”ì¶œ"""
        try:
            emotion = trade_info.get('ê°ì •íƒœê·¸', '')
            return_pct = trade_info.get('ìˆ˜ìµë¥ ', 0)
            
            if return_pct > 15:
                return f"ì„±ê³µ ìš”ì¸: {emotion} ìƒíƒœì—ì„œë„ ì¢‹ì€ ê²°ê³¼"
            elif return_pct < -15:
                return f"ì£¼ì˜ ì‚¬í•­: {emotion} ê°ì •ì´ ì†ì‹¤ë¡œ ì´ì–´ì§"
            else:
                return f"í‰ë²”í•œ ê²°ê³¼: {emotion} ê°ì •ì˜ ì˜í–¥ ë¶„ì„ í•„ìš”"
        except Exception:
            return "êµí›ˆ ì¶”ì¶œ ì‹¤íŒ¨"
    
    def _generate_key_insights(self, similar_experiences: List[Dict]) -> List[str]:
        """í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ìƒì„± (ê°œì„ ëœ ë²„ì „)"""
        try:
            insights = []
            
            if not similar_experiences:
                return ["ê³¼ê±° ìœ ì‚¬ ê²½í—˜ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. ì‹ ì¤‘í•œ ì ‘ê·¼ì„ ê¶Œì¥í•©ë‹ˆë‹¤."]
            
            # ìˆ˜ìµë¥  ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸
            returns = [exp['trade_data'].get('ìˆ˜ìµë¥ ', 0) for exp in similar_experiences]
            avg_return = np.mean(returns)
            
            if avg_return > 5:
                insights.append(f"ğŸ¯ ìœ ì‚¬í•œ ìƒí™©ì—ì„œ í‰ê·  {avg_return:.1f}%ì˜ ìˆ˜ìµì„ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤.")
            elif avg_return < -5:
                insights.append(f"âš ï¸ ìœ ì‚¬í•œ ìƒí™©ì—ì„œ í‰ê·  {abs(avg_return):.1f}%ì˜ ì†ì‹¤ì´ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
            else:
                insights.append("ğŸ“Š ìœ ì‚¬í•œ ìƒí™©ì—ì„œ ë³´í†µì˜ ê²°ê³¼ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤.")
            
            # ê°ì • íŒ¨í„´ ì¸ì‚¬ì´íŠ¸
            dominant_emotion = self._detect_dominant_emotion(similar_experiences)
            if dominant_emotion:
                insights.append(f"ğŸ§  ê³¼ê±° ìœ ì‚¬ ìƒí™©ì—ì„œ ì£¼ë¡œ '{dominant_emotion}' ê°ì •ì´ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.")
            
            # ìœ ì‚¬ë„ ê¸°ë°˜ ì‹ ë¢°ë„
            avg_similarity = np.mean([exp['similarity_score'] for exp in similar_experiences])
            if avg_similarity > 0.7:
                insights.append(f"ğŸ” ë§¤ìš° ìœ ì‚¬í•œ íŒ¨í„´ì…ë‹ˆë‹¤ (í‰ê·  ìœ ì‚¬ë„: {avg_similarity:.0%})")
            elif avg_similarity < 0.4:
                insights.append("âš ï¸ ê³¼ê±° ê²½í—˜ê³¼ì˜ ìœ ì‚¬ë„ê°€ ë‚®ìŠµë‹ˆë‹¤. ì‹ ì¤‘í•œ ì ‘ê·¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
            
            return insights[:3]  # ìµœëŒ€ 3ê°œê¹Œì§€
            
        except Exception as e:
            logger.error(f"ì¸ì‚¬ì´íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return ["ì¸ì‚¬ì´íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜ê°€ ë°œìƒí–ˆìŠµë‹ˆë‹¤."]
    
    def clear_cache(self):
        """ìºì‹œ í´ë¦¬ì–´"""
        self._cache.clear()
        model_manager.clear_cache()
        # LRU ìºì‹œë„ í´ë¦¬ì–´
        self.text_processor.clean_text.cache_clear()
        logger.info("ëª¨ë“  ìºì‹œê°€ í´ë¦¬ì–´ë˜ì—ˆìŠµë‹ˆë‹¤")
    
    def get_cache_info(self) -> Dict:
        """ìºì‹œ ì •ë³´ ì¡°íšŒ"""
        return {
            'internal_cache_size': len(self._cache),
            'text_processor_cache': self.text_processor.clean_text.cache_info()._asdict(),
            'model_cache_status': 'loaded' if model_manager._model else 'not_loaded'
        }