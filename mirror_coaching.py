#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
KB Reflex - ê±°ìš¸ ì½”ì¹­ ì‹œìŠ¤í…œ (AI Challenge í•µì‹¬ ê¸°ëŠ¥)
ê³¼ê±° ê²½í—˜ì„ í˜„ì¬ ìƒí™©ê³¼ ë§¤ì¹­í•˜ì—¬ "ê±°ìš¸"ì²˜ëŸ¼ ë°˜ì„±í•  ìˆ˜ ìˆê²Œ ë„ì™€ì£¼ëŠ” AI ì‹œìŠ¤í…œ
"""

import pandas as pd
import numpy as np
from typing import Dict, List, Optional, Tuple
from datetime import datetime, timedelta
from sentence_transformers import SentenceTransformer
import sentence_transformers.util
import re
from pathlib import Path
import sys

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ê²½ë¡œ ì¶”ê°€
project_root = Path(__file__).parent.parent
sys.path.append(str(project_root))

# í†µí•©ëœ ë°ì´í„° ì†ŒìŠ¤ import
from db.central_data_manager import get_user_trading_history

class MirrorCoaching:
    """
    ê±°ìš¸ ì½”ì¹­ ì‹œìŠ¤í…œ
    
    ì‚¬ìš©ìì˜ ê³¼ê±° ê±°ë˜ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ:
    1. í˜„ì¬ ìƒí™©ê³¼ ìœ ì‚¬í•œ ê³¼ê±° ê²½í—˜ ì°¾ê¸° (Semantic Similarity)
    2. ì„±ê³µ/ì‹¤íŒ¨ íŒ¨í„´ ë¶„ì„
    3. ê°ê´€ì ì¸ ì¸ì‚¬ì´íŠ¸ ì œê³µ (ì ˆëŒ€ ë§¤ë§¤ ì¶”ì²œ ì•ˆ í•¨!)
    4. ìŠ¤ìŠ¤ë¡œ ë‹µì„ ì°¾ë„ë¡ ìœ ë„í•˜ëŠ” ì§ˆë¬¸ ìƒì„±
    """
    
    def __init__(self):
        # ìµœì‹  í•œêµ­ì–´ Sentence Transformer ëª¨ë¸ ì´ˆê¸°í™”
        self.model = SentenceTransformer('jhgan/ko-sroberta-multitask')
        
        # í•œêµ­ì–´ ë¶ˆìš©ì–´ ì„¤ì •
        self.korean_stopwords = {
            'ê·¸ë¦¬ê³ ', 'í•˜ì§€ë§Œ', 'ê·¸ëŸ°ë°', 'ê·¸ë˜ì„œ', 'ê·¸ê²ƒ', 'ì´ê²ƒ', 'ì €ê²ƒ',
            'ìˆë‹¤', 'ì—†ë‹¤', 'ë˜ë‹¤', 'í•˜ë‹¤', 'ìˆëŠ”', 'ì—†ëŠ”', 'ëœë‹¤'
        }
        
        # ê°ì • í‚¤ì›Œë“œ ë§¤í•‘
        self.emotion_keywords = {
            'ê³µí¬': ['ë¬´ì„œì›Œ', 'ë‘ë ¤ì›Œ', 'ë¶ˆì•ˆ', 'ê±±ì •', 'íŒ¨ë‹‰', 'í­ë½'],
            'ìš•ì‹¬': ['ìš•ì‹¬', 'ë”', 'ì¶”ê°€', 'í’€ë§¤ìˆ˜', 'ì˜¬ì¸', 'ëŒ€ë°•'],
            'í›„íšŒ': ['í›„íšŒ', 'ì•„ì‰¬ì›Œ', 'ì˜ëª»', 'ì‹¤ìˆ˜', 'ë†“ì³¤'],
            'í™•ì‹ ': ['í™•ì‹ ', 'í™•ì‹¤', 'í‹€ë¦¼ì—†', 'ë¶„ëª…', '100%'],
            'ëƒ‰ì •': ['ë¶„ì„', 'íŒë‹¨', 'ê·¼ê±°', 'ë°ì´í„°', 'ê°ê´€ì ']
        }
    
    def _convert_to_dataframe(self, trades_list: List[Dict]) -> pd.DataFrame:
        """ê±°ë˜ ë°ì´í„° ë¦¬ìŠ¤íŠ¸ë¥¼ DataFrameìœ¼ë¡œ ë³€í™˜"""
        if not trades_list:
            return pd.DataFrame()
        
        df = pd.DataFrame(trades_list)
        
        # ë‚ ì§œ ì»¬ëŸ¼ì´ ìˆìœ¼ë©´ datetimeìœ¼ë¡œ ë³€í™˜
        if 'ê±°ë˜ì¼ì‹œ' in df.columns:
            df['ê±°ë˜ì¼ì‹œ'] = pd.to_datetime(df['ê±°ë˜ì¼ì‹œ'])
        
        return df
    
    def initialize_for_user(self, username: str) -> Dict:
        """ì‚¬ìš©ì ì´ˆê¸°í™” ë° ê¸°ë³¸ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        try:
            # í†µí•©ëœ ë°ì´í„° ì†ŒìŠ¤ì—ì„œ ê±°ë˜ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            trades_list = get_user_trading_history(username)
            trades_data = self._convert_to_dataframe(trades_list)
            
            if trades_data.empty:
                return {
                    'status': 'no_data',
                    'message': f'{username}ë‹˜ì˜ ê±°ë˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.',
                    'insights': {}
                }
            
            # ê¸°ë³¸ íŒ¨í„´ ë¶„ì„
            base_insights = self._analyze_base_patterns(trades_data)
            
            return {
                'status': 'initialized',
                'message': f'{username}ë‹˜ì˜ ê±°ë˜ íŒ¨í„´ ë¶„ì„ ì™„ë£Œ',
                'insights': base_insights,
                'total_trades': len(trades_data)
            }
            
        except Exception as e:
            return {
                'status': 'error',
                'message': f'ì´ˆê¸°í™” ì¤‘ ì˜¤ë¥˜: {str(e)}',
                'insights': {}
            }
    
    def find_similar_experiences(
        self, 
        current_situation: str, 
        username: str, 
        top_k: int = 3
    ) -> List[Dict]:
        """
        í˜„ì¬ ìƒí™©ê³¼ ìœ ì‚¬í•œ ê³¼ê±° ê²½í—˜ ì°¾ê¸° (Semantic Similarity ì‚¬ìš©)
        
        Args:
            current_situation: í˜„ì¬ íˆ¬ì ìƒí™©/ìƒê°
            username: ì‚¬ìš©ìëª…
            top_k: ë°˜í™˜í•  ìœ ì‚¬ ê²½í—˜ ê°œìˆ˜
        
        Returns:
            ìœ ì‚¬í•œ ê³¼ê±° ê²½í—˜ ë¦¬ìŠ¤íŠ¸
        """
        try:
            # í†µí•©ëœ ë°ì´í„° ì†ŒìŠ¤ì—ì„œ ê±°ë˜ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            trades_list = get_user_trading_history(username)
            trades_data = self._convert_to_dataframe(trades_list)
            
            if trades_data.empty:
                return []
            
            # ë©”ëª¨ í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬
            past_memos = trades_data['ë©”ëª¨'].fillna('').tolist()
            cleaned_memos = [self._clean_text(memo) for memo in past_memos]
            cleaned_current = self._clean_text(current_situation)
            
            # ë¹ˆ ë©”ëª¨ í•„í„°ë§
            valid_indices = [i for i, memo in enumerate(cleaned_memos) if memo.strip()]
            valid_memos = [cleaned_memos[i] for i in valid_indices]
            
            if not valid_memos:
                return []
            
            # Sentence Embeddings ìƒì„±
            current_embedding = self.model.encode([cleaned_current])
            past_embeddings = self.model.encode(valid_memos)
            
            # ì½”ì‚¬ì¸ ìœ ì‚¬ë„ ê³„ì‚°
            similarities = sentence_transformers.util.pytorch_cos_sim(
                current_embedding, past_embeddings
            )[0]
            
            # NumPy ë°°ì—´ë¡œ ë³€í™˜í•˜ì—¬ ì •ë ¬
            similarities_np = similarities.cpu().numpy()
            
            # ìœ ì‚¬ë„ ìˆœìœ¼ë¡œ ì •ë ¬í•˜ê³  ìƒìœ„ kê°œ ì„ íƒ
            top_indices = np.argsort(similarities_np)[::-1][:top_k]
            
            similar_experiences = []
            for idx in top_indices:
                similarity_score = float(similarities_np[idx])
                if similarity_score > 0.3:  # ìµœì†Œ ìœ ì‚¬ë„ ì„ê³„ê°’ (Semantic ê¸°ë°˜ìœ¼ë¡œ ë†’ê²Œ ì„¤ì •)
                    original_idx = valid_indices[idx]
                    trade_info = trades_data.iloc[original_idx]
                    similar_experiences.append({
                        'trade_data': trade_info.to_dict(),
                        'similarity_score': similarity_score,
                        'insight_type': self._determine_insight_type(trade_info),
                        'key_lesson': self._extract_key_lesson(trade_info)
                    })
            
            return similar_experiences
            
        except Exception as e:
            print(f"ìœ ì‚¬ ê²½í—˜ íƒìƒ‰ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return []
    
    def generate_hybrid_coaching(self, current_trade: dict, similar_experiences: list) -> dict:
        """
        í•˜ì´ë¸Œë¦¬ë“œ ë°ì´í„° ì£¼ì…í˜• ì½”ì¹­ ë©”ì‹œì§€ ìƒì„±
        
        ì‚¬ìš©ìì˜ ì‹¤ì œ ê³¼ê±° ê±°ë˜ ë°ì´í„°ë¥¼ ê·œì¹™ ê¸°ë°˜ í…œí”Œë¦¿ì— ë™ì ìœ¼ë¡œ ì‚½ì…í•˜ì—¬
        ê°œì¸í™”ëœ ì½”ì¹­ ë©”ì‹œì§€ë¥¼ ìƒì„±í•©ë‹ˆë‹¤. ì™¸ë¶€ LLMì´ë‚˜ APIë¥¼ ì‚¬ìš©í•˜ì§€ ì•Šê³ ,
        ìˆœìˆ˜í•˜ê²Œ ë°ì´í„° ê¸°ë°˜ì˜ ì§€ëŠ¥í˜• í…œí”Œë¦¿ ì‹œìŠ¤í…œì„ í™œìš©í•©ë‹ˆë‹¤.
        
        Args:
            current_trade: í˜„ì¬ ê±°ë˜/ìƒí™© ì •ë³´ ë”•ì…”ë„ˆë¦¬
            similar_experiences: ìœ ì‚¬í•œ ê³¼ê±° ê²½í—˜ ë¦¬ìŠ¤íŠ¸
        
        Returns:
            ë¶„ì„, ë©”ì‹œì§€, ì§ˆë¬¸ì´ í¬í•¨ëœ ì½”ì¹­ ë”•ì…”ë„ˆë¦¬
            {
                "analysis": "ìƒí™© ë¶„ì„ ë©”ì‹œì§€",
                "message": "ê°œì¸í™”ëœ ì½”ì¹­ ë©”ì‹œì§€", 
                "question": "ì„±ì°°ì„ ìœ ë„í•˜ëŠ” ì§ˆë¬¸"
            }
        """
        # 1. ìœ ì‚¬ ê²½í—˜ì´ ì—†ëŠ” ê²½ìš° - ê¸°ë³¸ ì½”ì¹­ ë©”ì‹œì§€ ì œê³µ
        if not similar_experiences:
            return {
                "analysis": "ìƒˆë¡œìš´ íŒ¨í„´ì˜ ê±°ë˜ê°€ ê°ì§€ë˜ì—ˆìŠµë‹ˆë‹¤.",
                "message": "ì´ë²ˆ ê±°ë˜ëŠ” ë‹¹ì‹ ë§Œì˜ íˆ¬ì ì›ì¹™ì„ ë§Œë“¤ì–´ê°ˆ ì¢‹ì€ ê¸°íšŒì…ë‹ˆë‹¤.",
                "question": "ì´ë²ˆ ê²°ì •ì— ê°€ì¥ í° ì˜í–¥ì„ ë¯¸ì¹œ ë‹¨ í•˜ë‚˜ì˜ ìš”ì¸ì€ ë¬´ì—‡ì¸ê°€ìš”?"
            }
        
        # 2. ê°€ì¥ ìœ ì‚¬í•œ ê³¼ê±° ê±°ë˜ ë°ì´í„° ì¶”ì¶œ (ì²« ë²ˆì§¸ ìš”ì†Œê°€ ê°€ì¥ ìœ ì‚¬í•¨)
        past_trade = similar_experiences[0]['trade_data']
        
        # 3. ê·œì¹™ ê¸°ë°˜ í…œí”Œë¦¿ ì„ íƒ ë° ë™ì  ë©”ì‹œì§€ êµ¬ì„±
        if past_trade['ìˆ˜ìµë¥ '] >= 0:
            # ê³¼ê±° ì„±ê³µ ê²½í—˜ì„ ë°”íƒ•ìœ¼ë¡œ í•œ ì„±ì°° í…œí”Œë¦¿
            analysis = (
                f"ì§€ê¸ˆ '{current_trade.get('ì¢…ëª©ëª…', 'í•´ë‹¹ ì¢…ëª©')}'ì— ëŒ€í•œ ê³ ë¯¼ì€, "
                f"ê³¼ê±° '{past_trade['ì¢…ëª©ëª…']}'ì—ì„œ '{past_trade.get('ê°ì •íƒœê·¸', 'íŠ¹ì • ê°ì •')}' "
                f"ê°ì •ìœ¼ë¡œ ì„±ê³µí–ˆë˜ ê²½í—˜ê³¼ ìœ ì‚¬í•©ë‹ˆë‹¤."
            )
            
            message = (
                f"ê³¼ê±° í•´ë‹¹ ê±°ë˜ì—ì„œ '{past_trade.get('ë©”ëª¨', 'íŠ¹ë³„í•œ íŒë‹¨')}' ë¼ëŠ” íŒë‹¨ìœ¼ë¡œ "
                f"{past_trade['ìˆ˜ìµë¥ ']:.1f}%ì˜ ì¢‹ì€ ê²°ê³¼ë¥¼ ì–»ìœ¼ì…¨ìŠµë‹ˆë‹¤. "
                f"ì´ë²ˆì—ë„ ê·¸ë•Œì˜ ì„±ê³µ ìš”ì¸ì„ ì ìš©í•  ìˆ˜ ìˆì„ê¹Œìš”?"
            )
            
            question = (
                f"ê³¼ê±°ì˜ ì„±ê³µ ê²½í—˜ê³¼ ë¹„êµí–ˆì„ ë•Œ, í˜„ì¬ ìƒí™©ì˜ ê°€ì¥ í° ì°¨ì´ì ì€ "
                f"ë¬´ì—‡ì´ë¼ê³  ìƒê°í•˜ì‹œë‚˜ìš”?"
            )
            
        else:
            # ê³¼ê±° ì‹¤íŒ¨ ê²½í—˜ìœ¼ë¡œë¶€í„°ì˜ í•™ìŠµ í…œí”Œë¦¿
            analysis = (
                f"í˜„ì¬ '{current_trade.get('ì¢…ëª©ëª…', 'í•´ë‹¹ ì¢…ëª©')}'ì„ ë³´ë©° ëŠë¼ëŠ” "
                f"'{current_trade.get('ê°ì •íƒœê·¸', 'í˜„ì¬ ê°ì •')}' ê°ì •ì€, "
                f"ê³¼ê±° '{past_trade['ì¢…ëª©ëª…']}' ê±°ë˜ì—ì„œ ì†ì‹¤ì„ ë³´ì…¨ì„ ë•Œì™€ ë§¤ìš° í¡ì‚¬í•©ë‹ˆë‹¤."
            )
            
            message = (
                f"ë°ì´í„°ì— ë”°ë¥´ë©´, ê³¼ê±° '{past_trade.get('ë©”ëª¨', 'ë‹¹ì‹œì˜ íŒë‹¨')}' ë¼ê³  "
                f"íŒë‹¨í–ˆë˜ ê±°ë˜ëŠ” {abs(past_trade['ìˆ˜ìµë¥ ']):.1f}%ì˜ ì†ì‹¤ë¡œ ì´ì–´ì¡ŒìŠµë‹ˆë‹¤. "
                f"ê³¼ê±°ì˜ ê²½í—˜ì´ í˜„ì¬ì˜ ê²°ì •ì— ì–´ë–¤ ê²½ê³ ë¥¼ ë³´ë‚´ê³  ìˆë‚˜ìš”?"
            )
            
            question = (
                f"ê³¼ê±°ì˜ ì‹¤ìˆ˜ë¥¼ ë°˜ë³µí•˜ì§€ ì•Šê¸° ìœ„í•´ ì§€ê¸ˆ ë‹¹ì¥ ë‹¤ë¥´ê²Œ í–‰ë™í•´ì•¼ í•  "
                f"í•œ ê°€ì§€ëŠ” ë¬´ì—‡ì¼ê¹Œìš”?"
            )
        
        # 4. ìµœì¢… ì½”ì¹­ ë”•ì…”ë„ˆë¦¬ ë°˜í™˜
        return {
            "analysis": analysis,
            "message": message,
            "question": question
        }
    
    def generate_mirror_questions(
        self, 
        similar_experiences: List[Dict],
        current_situation: str
    ) -> List[str]:
        """
        ê±°ìš¸ ì§ˆë¬¸ ìƒì„± - ì‚¬ìš©ìê°€ ìŠ¤ìŠ¤ë¡œ ë‹µí•˜ë„ë¡ ìœ ë„í•˜ëŠ” ì§ˆë¬¸ë“¤
        
        Args:
            similar_experiences: ìœ ì‚¬í•œ ê³¼ê±° ê²½í—˜ë“¤
            current_situation: í˜„ì¬ ìƒí™©
        
        Returns:
            ê±°ìš¸ ì§ˆë¬¸ ë¦¬ìŠ¤íŠ¸
        """
        questions = []
        
        if not similar_experiences:
            questions.extend([
                "ğŸ¤” ì´ë²ˆ íˆ¬ì ê²°ì •ì˜ ê°€ì¥ í° ê·¼ê±°ëŠ” ë¬´ì—‡ì¸ê°€ìš”?",
                "âš–ï¸ ì´ íˆ¬ìì˜ ìœ„í—˜ê³¼ ê¸°íšŒë¥¼ ì–´ë–»ê²Œ í‰ê°€í•˜ì‹œë‚˜ìš”?",
                "ğŸ¯ ë§Œì•½ 6ê°œì›” í›„ì˜ ë‚˜ì—ê²Œ ì´ ê²°ì •ì„ ì„¤ëª…í•œë‹¤ë©´?"
            ])
            return questions
        
        # ê³¼ê±° ê²½í—˜ ê¸°ë°˜ ë§ì¶¤í˜• ì§ˆë¬¸
        for exp in similar_experiences[:2]:  # ìƒìœ„ 2ê°œ ê²½í—˜ë§Œ ì‚¬ìš©
            trade = exp['trade_data']
            
            if trade['ìˆ˜ìµë¥ '] < 0:  # ì†ì‹¤ ê²½í—˜
                questions.append(
                    f"ğŸ“‰ ê³¼ê±° {trade['ì¢…ëª©ëª…']} ê±°ë˜ì—ì„œ {abs(trade['ìˆ˜ìµë¥ ']):.1f}% ì†ì‹¤ì„ ë³¸ ê²½í—˜ì´ ìˆìŠµë‹ˆë‹¤. "
                    f"ê·¸ë•Œì™€ ì§€ê¸ˆ ìƒí™©ì—ì„œ ë‹¤ë¥¸ ì ì€ ë¬´ì—‡ì¸ê°€ìš”?"
                )
                
                if 'ê³µí¬' in trade.get('ê°ì •íƒœê·¸', ''):
                    questions.append("ğŸ˜° ê°ì •ì  íŒë‹¨ìœ¼ë¡œ ì¸í•œ ê³¼ê±° ì†ì‹¤ì„ ì–´ë–»ê²Œ ë°©ì§€í•  ìˆ˜ ìˆì„ê¹Œìš”?")
                
            else:  # ìˆ˜ìµ ê²½í—˜
                questions.append(
                    f"ğŸ“ˆ ê³¼ê±° {trade['ì¢…ëª©ëª…']} ê±°ë˜ì—ì„œ {trade['ìˆ˜ìµë¥ ']:.1f}% ìˆ˜ìµì„ ë‚¸ ì„±ê³µ ìš”ì¸ì„ "
                    f"ì´ë²ˆì—ë„ ì ìš©í•  ìˆ˜ ìˆì„ê¹Œìš”?"
                )
        
        # íŒ¨í„´ ê¸°ë°˜ ì§ˆë¬¸
        emotion_pattern = self._detect_emotion_pattern(similar_experiences)
        if emotion_pattern:
            questions.append(f"ğŸ§  ê³¼ê±° '{emotion_pattern}' íŒ¨í„´ì´ ë°˜ë³µë˜ê³  ìˆìŠµë‹ˆë‹¤. ì´ë²ˆì—” ì–´ë–»ê²Œ ë‹¤ë¥´ê²Œ ì ‘ê·¼í•˜ì‹œê² ë‚˜ìš”?")
        
        # ê¸°ë³¸ ì„±ì°° ì§ˆë¬¸
        questions.extend([
            "â° ì´ íˆ¬ì ê²°ì •ì„ 24ì‹œê°„ í›„ì—ë„ ê°™ì€ ë§ˆìŒìœ¼ë¡œ í•  ìˆ˜ ìˆë‚˜ìš”?",
            "ğŸ“Š ê°ê´€ì  ë°ì´í„°ì™€ ì£¼ê´€ì  ëŠë‚Œ ì¤‘ ì–´ëŠ ìª½ì— ë” ì˜ì¡´í•˜ê³  ìˆë‚˜ìš”?",
            "ğŸª ë§Œì•½ ì´ íˆ¬ìê°€ ì‹¤íŒ¨í•œë‹¤ë©´, ê°€ì¥ í° ì›ì¸ì€ ë¬´ì—‡ì¼ ê²ƒ ê°™ë‚˜ìš”?"
        ])
        
        return questions[:5]  # ìµœëŒ€ 5ê°œê¹Œì§€
    
    def generate_insights_for_trade(self, trade_data: pd.Series, username: str) -> Dict:
        """íŠ¹ì • ê±°ë˜ì— ëŒ€í•œ ê±°ìš¸ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        try:
            # í†µí•©ëœ ë°ì´í„° ì†ŒìŠ¤ì—ì„œ ê±°ë˜ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            trades_list = get_user_trading_history(username)
            all_trades = self._convert_to_dataframe(trades_list)
            
            if all_trades.empty:
                return {}
            
            insights = {}
            
            # 1. ë™ì¼ ì¢…ëª© ê³¼ê±° ê±°ë˜ íŒ¨í„´
            same_stock_trades = all_trades[all_trades['ì¢…ëª©ëª…'] == trade_data['ì¢…ëª©ëª…']]
            if len(same_stock_trades) > 1:
                insights['same_stock_pattern'] = self._analyze_same_stock_pattern(same_stock_trades)
            
            # 2. ìœ ì‚¬í•œ ê°ì • ìƒíƒœ ê±°ë˜ë“¤
            same_emotion_trades = all_trades[all_trades['ê°ì •íƒœê·¸'] == trade_data.get('ê°ì •íƒœê·¸')]
            if len(same_emotion_trades) > 1:
                insights['emotion_pattern'] = self._analyze_emotion_pattern(same_emotion_trades)
            
            # 3. ì‹œê¸°ì  íŒ¨í„´ (ê°™ì€ ë‹¬, ê°™ì€ ìš”ì¼ ë“±)
            trade_month = pd.to_datetime(trade_data['ê±°ë˜ì¼ì‹œ']).month
            same_month_trades = all_trades[pd.to_datetime(all_trades['ê±°ë˜ì¼ì‹œ']).dt.month == trade_month]
            if len(same_month_trades) > 3:
                insights['seasonal_pattern'] = self._analyze_seasonal_pattern(same_month_trades, trade_month)
            
            # 4. ê±°ë˜ ê·œëª¨ íŒ¨í„´
            trade_amount = trade_data.get('ìˆ˜ëŸ‰', 0) * trade_data.get('ê°€ê²©', 0)
            insights['amount_pattern'] = self._analyze_amount_pattern(all_trades, trade_amount)
            
            return insights
            
        except Exception as e:
            print(f"ê±°ë˜ ì¸ì‚¬ì´íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return {}
    
    def get_recommended_review_trades(self, username: str) -> Optional[pd.DataFrame]:
        """ë³µê¸° ì¶”ì²œ ê±°ë˜ ì„ ë³„"""
        try:
            # í†µí•©ëœ ë°ì´í„° ì†ŒìŠ¤ì—ì„œ ê±°ë˜ ë°ì´í„° ê°€ì ¸ì˜¤ê¸°
            trades_list = get_user_trading_history(username)
            trades_data = self._convert_to_dataframe(trades_list)
            
            if trades_data.empty:
                return None
            
            # ë³µê¸° ê°€ì¹˜ê°€ ë†’ì€ ê±°ë˜ ì„ ë³„ ê¸°ì¤€:
            # 1. ê·¹ë‹¨ì  ìˆ˜ìµë¥  (Â±20% ì´ìƒ)
            # 2. ê°•í•œ ê°ì • íƒœê·¸ (#ê³µí¬, #ìš•ì‹¬, #íŒ¨ë‹‰ ë“±)
            # 3. ìµœê·¼ 3ê°œì›” ë‚´ ê±°ë˜
            
            extreme_returns = trades_data[abs(trades_data['ìˆ˜ìµë¥ ']) > 15]
            emotional_trades = trades_data[trades_data['ê°ì •íƒœê·¸'].isin(['#ê³µí¬', '#ìš•ì‹¬', '#íŒ¨ë‹‰', '#ì¶”ê²©ë§¤ìˆ˜'])]
            recent_cutoff = datetime.now() - timedelta(days=90)
            recent_trades = trades_data[pd.to_datetime(trades_data['ê±°ë˜ì¼ì‹œ']) > recent_cutoff]
            
            # ì ìˆ˜ ê¸°ë°˜ ì¶”ì²œ ì‹œìŠ¤í…œ
            trades_copy = trades_data.copy()
            trades_copy['review_score'] = 0
            
            # ê·¹ë‹¨ì  ìˆ˜ìµë¥ ì— ë†’ì€ ì ìˆ˜
            trades_copy.loc[abs(trades_copy['ìˆ˜ìµë¥ ']) > 20, 'review_score'] += 3
            trades_copy.loc[abs(trades_copy['ìˆ˜ìµë¥ ']) > 10, 'review_score'] += 2
            
            # ê°ì •ì  ê±°ë˜ì— ì ìˆ˜ ì¶”ê°€
            emotional_tags = ['#ê³µí¬', '#ìš•ì‹¬', '#íŒ¨ë‹‰', '#ì¶”ê²©ë§¤ìˆ˜', '#ë¶ˆì•ˆ']
            trades_copy.loc[trades_copy['ê°ì •íƒœê·¸'].isin(emotional_tags), 'review_score'] += 2
            
            # ìµœê·¼ ê±°ë˜ì— ì ìˆ˜ ì¶”ê°€
            trades_copy.loc[pd.to_datetime(trades_copy['ê±°ë˜ì¼ì‹œ']) > recent_cutoff, 'review_score'] += 1
            
            # ìƒìœ„ ì ìˆ˜ ê±°ë˜ë“¤ ë°˜í™˜
            return trades_copy.nlargest(10, 'review_score')
            
        except Exception as e:
            print(f"ì¶”ì²œ ê±°ë˜ ì„ ë³„ ì¤‘ ì˜¤ë¥˜: {str(e)}")
            return None
    
    def generate_learning_scenarios(self) -> List[Dict]:
        """
        ì‹ ê·œ ì‚¬ìš©ìë¥¼ ìœ„í•œ í•™ìŠµ ì‹œë‚˜ë¦¬ì˜¤ ìƒì„±
        ë‹¤ë¥¸ ì‚¬ìš©ìë“¤ì˜ íŒ¨í„´ì„ ìµëª…í™”í•˜ì—¬ í•™ìŠµ ìë£Œë¡œ ì œê³µ
        """
        scenarios = [
            {
                'scenario_id': 'fear_selling_lesson',
                'title': 'ê³µí¬ë§¤ë„ì˜ êµí›ˆ',
                'description': 'ì‹œì¥ ê¸‰ë½ ì‹œ ê°ì •ì  ë§¤ë„ì˜ ìœ„í—˜ì„±ì„ ë³´ì—¬ì£¼ëŠ” ì‹œë‚˜ë¦¬ì˜¤',
                'example_trades': [
                    {
                        'ìƒí™©': 'ì½”ìŠ¤í”¼ 3% ê¸‰ë½ ìƒí™©',
                        'íˆ¬ìì_ë°˜ì‘': 'ë¬´ì„œì›Œì„œ ì „ëŸ‰ ë§¤ë„',
                        'ê²°ê³¼': '-15% ì†ì‹¤',
                        'êµí›ˆ': 'ì‹œì¥ ë³€ë™ì„±ì€ ì¼ì‹œì ì¼ ìˆ˜ ìˆìŒ'
                    }
                ],
                'key_questions': [
                    "ì´ëŸ° ìƒí™©ì—ì„œ 24ì‹œê°„ ê¸°ë‹¤ë ¸ë‹¤ë©´ ì–´ë–»ê²Œ ë˜ì—ˆì„ê¹Œìš”?",
                    "ê°ì •ì  íŒë‹¨ê³¼ í•©ë¦¬ì  ë¶„ì„ì˜ ì°¨ì´ëŠ” ë¬´ì—‡ì¼ê¹Œìš”?"
                ]
            },
            {
                'scenario_id': 'fomo_buying_lesson', 
                'title': 'FOMO ë§¤ìˆ˜ì˜ í•¨ì •',
                'description': 'ê¸‰ë“±ì£¼ ì¶”ê²©ë§¤ìˆ˜ì˜ ìœ„í—˜ì„±ì„ ë³´ì—¬ì£¼ëŠ” ì‹œë‚˜ë¦¬ì˜¤',
                'example_trades': [
                    {
                        'ìƒí™©': 'íŠ¹ì • ì¢…ëª© ì—°ì† ìƒí•œê°€',
                        'íˆ¬ìì_ë°˜ì‘': 'ë†“ì¹˜ê¸° ì•„ê¹Œì›Œì„œ ì¶”ê²©ë§¤ìˆ˜',
                        'ê²°ê³¼': '-20% ì†ì‹¤',
                        'êµí›ˆ': 'ê¸‰ë“± í›„ì—ëŠ” ì¡°ì •ì´ ì˜¬ ìˆ˜ ìˆìŒ'
                    }
                ],
                'key_questions': [
                    "ì™œ ëª¨ë“  ì‚¬ëŒì´ ì‚¬ê³  ìˆì„ ë•Œ ê²½ê³„í•´ì•¼ í• ê¹Œìš”?",
                    "ì ì • ë§¤ìˆ˜ íƒ€ì´ë°ì„ ì–´ë–»ê²Œ íŒë‹¨í•  ìˆ˜ ìˆì„ê¹Œìš”?"
                ]
            },
            {
                'scenario_id': 'rational_success',
                'title': 'í•©ë¦¬ì  íˆ¬ìì˜ ì„±ê³¼',
                'description': 'ì°¨ë¶„í•œ ë¶„ì„ì„ í†µí•œ ì„±ê³µ ì‚¬ë¡€',
                'example_trades': [
                    {
                        'ìƒí™©': 'ì‹œì¥ ë¶ˆì•ˆì • ì† ì €í‰ê°€ ì¢…ëª© ë°œê²¬',
                        'íˆ¬ìì_ë°˜ì‘': 'í€ë”ë©˜í„¸ ë¶„ì„ í›„ ì‹ ì¤‘í•œ ë§¤ìˆ˜',
                        'ê²°ê³¼': '+25% ìˆ˜ìµ',
                        'êµí›ˆ': 'ìœ„ê¸°ê°€ ê¸°íšŒê°€ ë  ìˆ˜ ìˆìŒ'
                    }
                ],
                'key_questions': [
                    "ì‹œì¥ì´ ë¶ˆì•ˆí•  ë•Œ ê¸°íšŒë¥¼ ì°¾ëŠ” ë°©ë²•ì€?",
                    "ë‹¤ë¥¸ ì‚¬ëŒì´ íŒ” ë•Œ ì‚¬ëŠ” ìš©ê¸°ëŠ” ì–´ë””ì„œ ë‚˜ì˜¬ê¹Œìš”?"
                ]
            }
        ]
        
        return scenarios
    
    def get_investment_principles_learning_path(self, selected_principle: str) -> Dict:
        """
        ì„ íƒí•œ íˆ¬ì ì›ì¹™ì— ë”°ë¥¸ í•™ìŠµ ê²½ë¡œ ì œê³µ
        """
        learning_paths = {
            "ì›ŒëŸ° ë²„í•": {
                'level_1': {
                    'title': 'ê¸°ì—… ì´í•´í•˜ê¸°',
                    'tasks': [
                        'ê´€ì‹¬ ìˆëŠ” ê¸°ì—… 3ê°œì˜ ì‚¬ì—…ëª¨ë¸ ì¡°ì‚¬',
                        'ê° ê¸°ì—…ì˜ ê²½ìŸìš°ìœ„ ìš”ì†Œ íŒŒì•…',
                        'ìµœê·¼ 3ë…„ê°„ ì¬ë¬´ì œí‘œ ê°„ë‹¨ ë¶„ì„'
                    ],
                    'simulation_scenario': 'ê°€ìƒì˜ ìš°ëŸ‰ê¸°ì—… ë¶„ì„ ì‹¤ìŠµ'
                },
                'level_2': {
                    'title': 'ì¥ê¸° ê´€ì  ê¸°ë¥´ê¸°',
                    'tasks': [
                        '10ë…„ í›„ ê° ê¸°ì—…ì´ ì–´ë–»ê²Œ ë ì§€ ì˜ˆì¸¡',
                        'ë‹¨ê¸° ë³€ë™ì— í”ë“¤ë¦¬ì§€ ì•ŠëŠ” ì—°ìŠµ',
                        'ë‚´ì¬ê°€ì¹˜ ê³„ì‚° ê¸°ì´ˆ í•™ìŠµ'
                    ],
                    'simulation_scenario': 'ì‹œì¥ ë³€ë™ì„± ì†ì—ì„œë„ ë³´ìœ  ì—°ìŠµ'
                }
            },
            "í”¼í„° ë¦°ì¹˜": {
                'level_1': {
                    'title': 'ì¼ìƒì—ì„œ íˆ¬ì ì•„ì´ë””ì–´ ì°¾ê¸°',
                    'tasks': [
                        'ìì£¼ ì´ìš©í•˜ëŠ” ì„œë¹„ìŠ¤/ì œí’ˆ íšŒì‚¬ ì¡°ì‚¬',
                        'ì„±ì¥í•˜ëŠ” íŠ¸ë Œë“œ íŒŒì•…í•˜ê¸°',
                        'PEG ë¹„ìœ¨ ê³„ì‚° ë°©ë²• í•™ìŠµ'
                    ],
                    'simulation_scenario': 'ìƒí™œ ì† ë°œê²¬í•œ ê¸°ì—… ë¶„ì„ ì‹¤ìŠµ'
                },
                'level_2': {
                    'title': 'ì„±ì¥ì£¼ ë°œêµ´í•˜ê¸°',
                    'tasks': [
                        'ë§¤ì¶œ ì„±ì¥ë¥  20% ì´ìƒ ê¸°ì—… ì°¾ê¸°',
                        'ì‚°ì—… ë‚´ ê²½ìŸ ìƒí™© ë¶„ì„',
                        'ì„±ì¥ ì§€ì† ê°€ëŠ¥ì„± í‰ê°€'
                    ],
                    'simulation_scenario': 'ê³ ì„±ì¥ ê¸°ì—… íˆ¬ì ì‹œë®¬ë ˆì´ì…˜'
                }
            },
            "ë²¤ì €ë¯¼ ê·¸ë ˆì´ì—„": {
                'level_1': {
                    'title': 'ì•ˆì „ ë§ˆì§„ ì´í•´í•˜ê¸°',
                    'tasks': [
                        'ë‚´ì¬ê°€ì¹˜ ê³„ì‚° ê¸°ì´ˆ í•™ìŠµ',
                        'PBR, PER ë“± ë°¸ë¥˜ì—ì´ì…˜ ì§€í‘œ ì´í•´',
                        'ì¬ë¬´ ê±´ì „ì„± ì²´í¬ë¦¬ìŠ¤íŠ¸ ì‘ì„±'
                    ],
                    'simulation_scenario': 'ì €í‰ê°€ ì¢…ëª© ë°œêµ´ ì‹¤ìŠµ'
                },
                'level_2': {
                    'title': 'ë¶„ì‚° íˆ¬ì ì‹¤ìŠµ',
                    'tasks': [
                        '10-15ê°œ ì¢…ëª©ìœ¼ë¡œ í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì„±',
                        'ì„¹í„°ë³„ ë¶„ì‚° ì „ëµ ìˆ˜ë¦½',
                        'ìœ„í—˜ ê´€ë¦¬ ì›ì¹™ ì •ë¦½'
                    ],
                    'simulation_scenario': 'ì•ˆì „í•œ í¬íŠ¸í´ë¦¬ì˜¤ êµ¬ì¶• ì—°ìŠµ'
                }
            }
        }
        
        return learning_paths.get(selected_principle, {})
    
    def create_mirror_report(
        self, 
        username: str, 
        current_situation: str,
        similar_experiences: List[Dict] = None
    ) -> Dict:
        """ì¢…í•© ê±°ìš¸ ë¦¬í¬íŠ¸ ìƒì„±"""
        report = {
            'timestamp': datetime.now(),
            'username': username,
            'current_situation': current_situation,
            'mirror_analysis': {}
        }
        
        try:
            # ìœ ì‚¬ ê²½í—˜ì´ ì œê³µë˜ì§€ ì•Šì•˜ë‹¤ë©´ ì°¾ê¸°
            if similar_experiences is None:
                similar_experiences = self.find_similar_experiences(current_situation, username)
            
            if similar_experiences:
                report['mirror_analysis']['similar_count'] = len(similar_experiences)
                report['mirror_analysis']['experiences'] = similar_experiences
                
                # íŒ¨í„´ ìš”ì•½
                success_count = sum(1 for exp in similar_experiences if exp['trade_data']['ìˆ˜ìµë¥ '] > 0)
                failure_count = len(similar_experiences) - success_count
                
                report['mirror_analysis']['pattern_summary'] = {
                    'success_cases': success_count,
                    'failure_cases': failure_count,
                    'dominant_emotion': self._detect_emotion_pattern(similar_experiences)
                }
                
                # ê±°ìš¸ ì§ˆë¬¸ ìƒì„±
                report['mirror_questions'] = self.generate_mirror_questions(
                    similar_experiences, current_situation
                )
                
                # í•µì‹¬ ì¸ì‚¬ì´íŠ¸
                report['key_insights'] = self._generate_key_insights(similar_experiences)
                
            else:
                report['mirror_analysis']['message'] = "ìœ ì‚¬í•œ ê³¼ê±° ê²½í—˜ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤."
                report['mirror_questions'] = self.generate_mirror_questions([], current_situation)
            
            return report
            
        except Exception as e:
            report['error'] = f"ë¦¬í¬íŠ¸ ìƒì„± ì¤‘ ì˜¤ë¥˜: {str(e)}"
            return report
    
    def _clean_text(self, text: str) -> str:
        """í…ìŠ¤íŠ¸ ì „ì²˜ë¦¬"""
        if not isinstance(text, str):
            return ""
        
        # ê¸°ë³¸ ì •ì œ
        text = text.lower().strip()
        
        # íŠ¹ìˆ˜ë¬¸ì ì œê±° (í•œê¸€, ì˜ë¬¸, ìˆ«ì, ê³µë°±ë§Œ ìœ ì§€)
        text = re.sub(r'[^\w\sê°€-í£]', ' ', text)
        
        # ì¤‘ë³µ ê³µë°± ì œê±°
        text = re.sub(r'\s+', ' ', text)
        
        # ë¶ˆìš©ì–´ ì œê±°
        words = text.split()
        words = [word for word in words if word not in self.korean_stopwords]
        
        return ' '.join(words)
    
    def _analyze_base_patterns(self, trades_data: pd.DataFrame) -> Dict:
        """ê¸°ë³¸ ê±°ë˜ íŒ¨í„´ ë¶„ì„"""
        patterns = {}
        
        # 1. ê°ì •ë³„ ì„±ê³¼ ë¶„ì„
        emotion_performance = trades_data.groupby('ê°ì •íƒœê·¸')['ìˆ˜ìµë¥ '].agg(['mean', 'count']).round(2)
        patterns['emotion_performance'] = emotion_performance.to_dict('index')
        
        # 2. ì›”ë³„ ê±°ë˜ íŒ¨í„´
        trades_data['month'] = pd.to_datetime(trades_data['ê±°ë˜ì¼ì‹œ']).dt.month
        monthly_pattern = trades_data.groupby('month')['ìˆ˜ìµë¥ '].agg(['mean', 'count']).round(2)
        patterns['monthly_pattern'] = monthly_pattern.to_dict('index')
        
        # 3. ì¢…ëª©ë³„ ì„±ê³¼
        stock_performance = trades_data.groupby('ì¢…ëª©ëª…')['ìˆ˜ìµë¥ '].agg(['mean', 'count']).round(2)
        patterns['stock_performance'] = stock_performance.to_dict('index')
        
        # 4. ê±°ë˜ êµ¬ë¶„ë³„ ì„±ê³¼
        trade_type_performance = trades_data.groupby('ê±°ë˜êµ¬ë¶„')['ìˆ˜ìµë¥ '].agg(['mean', 'count']).round(2)
        patterns['trade_type_performance'] = trade_type_performance.to_dict('index')
        
        return patterns
    
    def _determine_insight_type(self, trade_info: pd.Series) -> str:
        """ì¸ì‚¬ì´íŠ¸ ìœ í˜• ê²°ì •"""
        if trade_info['ìˆ˜ìµë¥ '] > 10:
            return "success_pattern"
        elif trade_info['ìˆ˜ìµë¥ '] < -10:
            return "failure_pattern" 
        elif trade_info.get('ê°ì •íƒœê·¸') in ['#ê³µí¬', '#íŒ¨ë‹‰']:
            return "emotional_pattern"
        else:
            return "neutral_pattern"
    
    def _extract_key_lesson(self, trade_info: pd.Series) -> str:
        """í•µì‹¬ êµí›ˆ ì¶”ì¶œ"""
        memo = trade_info.get('ë©”ëª¨', '')
        emotion = trade_info.get('ê°ì •íƒœê·¸', '')
        return_pct = trade_info.get('ìˆ˜ìµë¥ ', 0)
        
        if return_pct > 15:
            return f"ì„±ê³µ ìš”ì¸: {emotion} ìƒíƒœì—ì„œë„ ì¢‹ì€ ê²°ê³¼"
        elif return_pct < -15:
            return f"ì£¼ì˜ ì‚¬í•­: {emotion} ê°ì •ì´ ì†ì‹¤ë¡œ ì´ì–´ì§"
        else:
            return f"í‰ë²”í•œ ê²°ê³¼: {emotion} ê°ì •ì˜ ì˜í–¥ ë¶„ì„ í•„ìš”"
    
    def _detect_emotion_pattern(self, similar_experiences: List[Dict]) -> str:
        """ê°ì • íŒ¨í„´ ê°ì§€"""
        emotions = [exp['trade_data'].get('ê°ì •íƒœê·¸', '') for exp in similar_experiences]
        emotion_counts = pd.Series(emotions).value_counts()
        
        if len(emotion_counts) > 0:
            return emotion_counts.index[0]  # ê°€ì¥ ë¹ˆë²ˆí•œ ê°ì •
        return ""
    
    def _analyze_same_stock_pattern(self, same_stock_trades: pd.DataFrame) -> Dict:
        """ë™ì¼ ì¢…ëª© ê±°ë˜ íŒ¨í„´ ë¶„ì„"""
        return {
            'total_trades': len(same_stock_trades),
            'avg_return': round(same_stock_trades['ìˆ˜ìµë¥ '].mean(), 2),
            'win_rate': round((same_stock_trades['ìˆ˜ìµë¥ '] > 0).mean() * 100, 1),
            'best_return': round(same_stock_trades['ìˆ˜ìµë¥ '].max(), 2),
            'worst_return': round(same_stock_trades['ìˆ˜ìµë¥ '].min(), 2),
            'most_common_emotion': same_stock_trades['ê°ì •íƒœê·¸'].mode().iloc[0] if len(same_stock_trades) > 0 else None
        }
    
    def _analyze_emotion_pattern(self, emotion_trades: pd.DataFrame) -> Dict:
        """ê°ì •ë³„ ê±°ë˜ íŒ¨í„´ ë¶„ì„"""
        return {
            'total_trades': len(emotion_trades),
            'avg_return': round(emotion_trades['ìˆ˜ìµë¥ '].mean(), 2),
            'win_rate': round((emotion_trades['ìˆ˜ìµë¥ '] > 0).mean() * 100, 1),
            'volatility': round(emotion_trades['ìˆ˜ìµë¥ '].std(), 2),
            'advice': self._get_emotion_advice(emotion_trades['ê°ì •íƒœê·¸'].iloc[0])
        }
    
    def _analyze_seasonal_pattern(self, month_trades: pd.DataFrame, month: int) -> Dict:
        """ê³„ì ˆì /ì›”ë³„ ê±°ë˜ íŒ¨í„´ ë¶„ì„"""
        month_names = {
            1: '1ì›”', 2: '2ì›”', 3: '3ì›”', 4: '4ì›”', 5: '5ì›”', 6: '6ì›”',
            7: '7ì›”', 8: '8ì›”', 9: '9ì›”', 10: '10ì›”', 11: '11ì›”', 12: '12ì›”'
        }
        
        return {
            'month_name': month_names.get(month, f'{month}ì›”'),
            'total_trades': len(month_trades),
            'avg_return': round(month_trades['ìˆ˜ìµë¥ '].mean(), 2),
            'pattern_strength': 'strong' if len(month_trades) > 10 else 'weak'
        }
    
    def _analyze_amount_pattern(self, all_trades: pd.DataFrame, current_amount: float) -> Dict:
        """ê±°ë˜ ê¸ˆì•¡ë³„ íŒ¨í„´ ë¶„ì„"""
        all_trades = all_trades.copy()
        all_trades['ê±°ë˜ê¸ˆì•¡'] = all_trades['ìˆ˜ëŸ‰'] * all_trades['ê°€ê²©']
        
        # ê±°ë˜ ê¸ˆì•¡ êµ¬ê°„ë³„ ë¶„ì„
        percentiles = all_trades['ê±°ë˜ê¸ˆì•¡'].quantile([0.25, 0.5, 0.75])
        
        if current_amount <= percentiles[0.25]:
            size_category = "ì†Œì•¡"
        elif current_amount <= percentiles[0.75]:
            size_category = "ë³´í†µ"
        else:
            size_category = "ëŒ€ì•¡"
        
        # í•´ë‹¹ êµ¬ê°„ì˜ í‰ê·  ìˆ˜ìµë¥ 
        if size_category == "ì†Œì•¡":
            similar_amount_trades = all_trades[all_trades['ê±°ë˜ê¸ˆì•¡'] <= percentiles[0.25]]
        elif size_category == "ë³´í†µ":
            similar_amount_trades = all_trades[
                (all_trades['ê±°ë˜ê¸ˆì•¡'] > percentiles[0.25]) & 
                (all_trades['ê±°ë˜ê¸ˆì•¡'] <= percentiles[0.75])
            ]
        else:
            similar_amount_trades = all_trades[all_trades['ê±°ë˜ê¸ˆì•¡'] > percentiles[0.75]]
        
        return {
            'size_category': size_category,
            'avg_return_in_category': round(similar_amount_trades['ìˆ˜ìµë¥ '].mean(), 2),
            'trades_in_category': len(similar_amount_trades),
            'risk_level': 'high' if size_category == "ëŒ€ì•¡" else 'medium' if size_category == "ë³´í†µ" else 'low'
        }
    
    def _get_emotion_advice(self, emotion: str) -> str:
        """ê°ì •ë³„ ì¡°ì–¸"""
        advice_map = {
            '#ê³µí¬': "ê³µí¬ ê°ì •ì€ ì¢…ì¢… ë¹„í•©ë¦¬ì  íŒë‹¨ìœ¼ë¡œ ì´ì–´ì§‘ë‹ˆë‹¤. ê°ê´€ì  ê·¼ê±°ë¥¼ ë‹¤ì‹œ ê²€í† í•´ë³´ì„¸ìš”.",
            '#ìš•ì‹¬': "ìš•ì‹¬ì€ ìœ„í—˜ ê´€ë¦¬ë¥¼ ì†Œí™€íˆ ë§Œë“¤ ìˆ˜ ìˆìŠµë‹ˆë‹¤. ì ì • íˆ¬ì ê·œëª¨ë¥¼ ì§€í‚¤ì„¸ìš”.",
            '#íŒ¨ë‹‰': "íŒ¨ë‹‰ ìƒíƒœì—ì„œëŠ” 24ì‹œê°„ ëƒ‰ê°ê¸°ê°„ì„ ê°–ëŠ” ê²ƒì´ ë„ì›€ì´ ë©ë‹ˆë‹¤.",
            '#ì¶”ê²©ë§¤ìˆ˜': "ê¸‰ë“± í›„ ì¶”ê²©ë§¤ìˆ˜ëŠ” ê³ ì ë§¤ìˆ˜ ìœ„í—˜ì´ ë†’ìŠµë‹ˆë‹¤. ì‹ ì¤‘í•˜ê²Œ ì ‘ê·¼í•˜ì„¸ìš”.",
            '#ë¶ˆì•ˆ': "ë¶ˆì•ˆê°ì´ í´ ë•ŒëŠ” íˆ¬ì ë¹„ì¤‘ì„ ì¤„ì´ëŠ” ê²ƒë„ ì¢‹ì€ ì „ëµì…ë‹ˆë‹¤.",
            '#í™•ì‹ ': "í™•ì‹ ì´ ê³¼ë„í•  ë•Œë„ ìœ„í—˜í•©ë‹ˆë‹¤. ë°˜ëŒ€ ì‹œë‚˜ë¦¬ì˜¤ë„ ê³ ë ¤í•´ë³´ì„¸ìš”.",
            '#í•©ë¦¬ì ': "í•©ë¦¬ì  ì ‘ê·¼ì„ ìœ ì§€í•˜ë˜, ê°ì •ì„ ì™„ì „íˆ ë°°ì œí•  í•„ìš”ëŠ” ì—†ìŠµë‹ˆë‹¤."
        }
        return advice_map.get(emotion, "ê°ì •ê³¼ ì´ì„±ì˜ ê· í˜•ì„ ì˜ ë§ì¶°ë³´ì„¸ìš”.")
    
    def _generate_key_insights(self, similar_experiences: List[Dict]) -> List[str]:
        """í•µì‹¬ ì¸ì‚¬ì´íŠ¸ ìƒì„±"""
        insights = []
        
        if not similar_experiences:
            return ["ê³¼ê±° ìœ ì‚¬ ê²½í—˜ì´ ë¶€ì¡±í•©ë‹ˆë‹¤. ì‹ ì¤‘í•œ ì ‘ê·¼ì„ ê¶Œì¥í•©ë‹ˆë‹¤."]
        
        # ìˆ˜ìµë¥  ê¸°ë°˜ ì¸ì‚¬ì´íŠ¸
        returns = [exp['trade_data']['ìˆ˜ìµë¥ '] for exp in similar_experiences]
        avg_return = np.mean(returns)
        
        if avg_return > 5:
            insights.append(f"ğŸ¯ ìœ ì‚¬í•œ ìƒí™©ì—ì„œ í‰ê·  {avg_return:.1f}%ì˜ ìˆ˜ìµì„ ê¸°ë¡í–ˆìŠµë‹ˆë‹¤.")
        elif avg_return < -5:
            insights.append(f"âš ï¸ ìœ ì‚¬í•œ ìƒí™©ì—ì„œ í‰ê·  {abs(avg_return):.1f}%ì˜ ì†ì‹¤ì´ ë°œìƒí–ˆìŠµë‹ˆë‹¤.")
        else:
            insights.append("ğŸ“Š ìœ ì‚¬í•œ ìƒí™©ì—ì„œ ë³´í†µì˜ ê²°ê³¼ë¥¼ ë³´ì˜€ìŠµë‹ˆë‹¤.")
        
        # ê°ì • íŒ¨í„´ ì¸ì‚¬ì´íŠ¸
        emotions = [exp['trade_data'].get('ê°ì •íƒœê·¸', '') for exp in similar_experiences]
        emotion_series = pd.Series(emotions)
        if len(emotion_series) > 0:
            most_common_emotion = emotion_series.mode().iloc[0]
            insights.append(f"ğŸ§  ê³¼ê±° ìœ ì‚¬ ìƒí™©ì—ì„œ ì£¼ë¡œ '{most_common_emotion}' ê°ì •ì´ ë‚˜íƒ€ë‚¬ìŠµë‹ˆë‹¤.")
        
        # ì‹œê¸°ì  íŒ¨í„´
        dates = [pd.to_datetime(exp['trade_data']['ê±°ë˜ì¼ì‹œ']) for exp in similar_experiences]
        if len(dates) > 1:
            months = [d.month for d in dates]
            if len(set(months)) == 1:
                month_name = f"{months[0]}ì›”"
                insights.append(f"ğŸ“… {month_name}ì— ìœ ì‚¬í•œ íŒ¨í„´ì´ ë°˜ë³µë˜ëŠ” ê²½í–¥ì´ ìˆìŠµë‹ˆë‹¤.")
        
        return insights[:3]  # ìµœëŒ€ 3ê°œê¹Œì§€