#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
KB AI Challenge - KB Reflex íˆ¬ì ì‹¬ë¦¬ ë¶„ì„ ëª¨ë¸ (ì‹œì—°ìš© ê³ ë„í™” ë²„ì „)
ì‹œì—° ì•ˆì •ì„±ê³¼ ë‚®ì€ ì˜¤ë‹µ ë¦¬ìŠ¤í¬ì— ìµœì í™”ëœ 7í´ë˜ìŠ¤/4í´ë˜ìŠ¤ ë™ì‹œ í•™ìŠµ ì‹œìŠ¤í…œ

í•µì‹¬ ì„¤ê³„ ì›ì¹™:
1. ì‹œì—° ë¦¬ìŠ¤í¬ í†µì œ: ë¶ˆí™•ì‹¤ì„± ê±°ë¶€ ë¡œì§ìœ¼ë¡œ ì• ë§¤í•œ ì˜ˆì¸¡ íšŒí”¼
2. ëˆ„ìˆ˜ ë°©ì§€: ì‹œì—° í›„ë³´ ë¬¸ì¥ì„ ì§ì ‘ í•™ìŠµì— ì‚¬ìš©í•˜ì§€ ì•Šê³  ì–´íœ˜ ìƒê´€ë§Œ í™œìš©
3. ì¼ë°˜í™” ë³´ì¡´: ê³¼ë„í•œ ì¦ê°•/í¸í–¥ ë°©ì§€ë¡œ ì‹¤ì œ ì„±ëŠ¥ ìœ ì§€
4. ì‚¬ìš©ì ë‹¨ìœ„ í‰ê°€: GroupKFoldë¡œ í˜„ì‹¤ì  ì„±ëŠ¥ ì¸¡ì •
5. íˆ¬ëª…í•œ ë¦¬í¬íŒ…: ëª¨ë“  ì§€í‘œì™€ í•œê³„ì  ëª…ì‹œ
"""

import os
import json
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from typing import Dict, List, Tuple, Any, Optional, Union
from pathlib import Path
import warnings
import time
import random
import sys
import argparse
from collections import Counter, defaultdict
import pickle

# í”„ë¡œì íŠ¸ ë£¨íŠ¸ ì„¤ì •
current_file = Path(__file__)
project_root = current_file.parent.parent
sys.path.insert(0, str(project_root))

warnings.filterwarnings('ignore')

import torch
import torch.nn as nn
from torch.utils.data import Dataset, DataLoader
from transformers import (
    AutoTokenizer, 
    AutoModelForSequenceClassification,
    Trainer,
    TrainingArguments,
    EarlyStoppingCallback,
    MarianMTModel,
    MarianTokenizer
)
from sklearn.model_selection import train_test_split, GroupKFold, StratifiedKFold
from sklearn.preprocessing import LabelEncoder
from sklearn.metrics import (
    accuracy_score, classification_report, f1_score, 
    confusion_matrix, precision_recall_fscore_support
)
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.metrics.pairwise import cosine_similarity

# ì¤‘ì•™ ë°ì´í„° ê´€ë¦¬ì import - ë‹¤ì–‘í•œ ê²½ë¡œ ì‹œë„
get_data_manager = None
import_paths = [
    "db.central_data_manager",
    "central_data_manager", 
    "db.central_data_manager",
    "REFLEX.db.central_data_manager",
    "sentiment_model.db.central_data_manager"
]

for import_path in import_paths:
    try:
        if import_path == "db.central_data_manager":
            from db.central_data_manager import get_data_manager
        elif import_path == "central_data_manager":
            from central_data_manager import get_data_manager
        elif import_path == "REFLEX.db.central_data_manager":
            from REFLEX.db.central_data_manager import get_data_manager
        elif import_path == "sentiment_model.db.central_data_manager":
            from sentiment_model.db.central_data_manager import get_data_manager
        else:
            # ë™ì  import
            import importlib
            module = importlib.import_module(import_path)
            get_data_manager = getattr(module, 'get_data_manager')
        
        print(f"âœ… ì¤‘ì•™ ë°ì´í„° ê´€ë¦¬ì ë¡œë“œ ì„±ê³µ: {import_path}")
        break
    except (ImportError, AttributeError, ModuleNotFoundError) as e:
        continue

if get_data_manager is None:
    print("âš ï¸ ëª¨ë“  ê²½ë¡œì—ì„œ ì¤‘ì•™ ë°ì´í„° ê´€ë¦¬ìë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    print("ğŸ’¡ ë‹¤ìŒ ìœ„ì¹˜ë“¤ì„ í™•ì¸í•´ì£¼ì„¸ìš”:")
    for path in import_paths:
        print(f"   - {path}")
    print("ğŸ“ í˜„ì¬ í”„ë¡œì íŠ¸ êµ¬ì¡°ë¥¼ í™•ì¸í•˜ê³  ì˜¬ë°”ë¥¸ ê²½ë¡œë¡œ ìˆ˜ì •í•´ì£¼ì„¸ìš”.")
    print("ğŸ”„ Mock ë°ì´í„°ë¡œ ì§„í–‰í•©ë‹ˆë‹¤.")

# ì¬í˜„ì„±ì„ ìœ„í•œ ì‹œë“œ ê³ ì •
RANDOM_SEED = 42
torch.manual_seed(RANDOM_SEED)
np.random.seed(RANDOM_SEED)
random.seed(RANDOM_SEED)

# 7í´ë˜ìŠ¤ â†’ 4í´ë˜ìŠ¤ ë§¤í•‘ (ì‹œì—° ì•ˆì •ì„±ì„ ìœ„í•œ ë‹¨ìˆœí™”)
LABEL_7TO4_MAPPING = {
    'ê³µí¬': 'ë¶€ì •',     # ëª…í™•í•œ ë¶€ì • ê°ì •
    'ë¶ˆì•ˆ': 'ë¶€ì •',     # ëª…í™•í•œ ë¶€ì • ê°ì •  
    'í›„íšŒ': 'ë¶€ì •',     # ëª…í™•í•œ ë¶€ì • ê°ì •
    'ëƒ‰ì •': 'ì¤‘ë¦½',     # ì´ì„±ì  íŒë‹¨
    'í™•ì‹ ': 'ê¸ì •',     # ëª…í™•í•œ ê¸ì • ê°ì •
    'í¥ë¶„': 'ê¸ì •',     # ëª…í™•í•œ ê¸ì • ê°ì •
    'ìš•ì‹¬': 'íƒìš•'      # ë…ë¦½ì ì¸ ìœ„í—˜ ê°ì •
}

class CBLoss(nn.Module):
    """Class-Balanced Loss for ë¶ˆê· í˜• ë°ì´í„°ì…‹"""
    def __init__(self, samples_per_class, beta=0.9999, gamma=2.0):
        super(CBLoss, self).__init__()
        effective_num = 1.0 - np.power(beta, samples_per_class)
        weights = (1.0 - beta) / np.array(effective_num)
        weights = weights / np.sum(weights) * len(weights)
        self.weights = torch.tensor(weights, dtype=torch.float32)
        self.gamma = gamma
        
    def forward(self, logits, labels):
        """CB Loss ê³„ì‚°"""
        if logits.device != self.weights.device:
            self.weights = self.weights.to(logits.device)
        
        ce_loss = nn.CrossEntropyLoss(reduction='none')(logits, labels)
        pt = torch.exp(-ce_loss)
        focal_weight = (1 - pt) ** self.gamma
        cb_weight = self.weights[labels]
        loss = focal_weight * cb_weight * ce_loss
        return loss.mean()

class FocalLoss(nn.Module):
    """Focal Loss for ì–´ë ¤ìš´ ìƒ˜í”Œ ì§‘ì¤‘ í•™ìŠµ"""
    def __init__(self, alpha=1, gamma=2, weight=None):
        super(FocalLoss, self).__init__()
        self.alpha = alpha
        self.gamma = gamma
        self.weight = weight
        
    def forward(self, logits, labels):
        """Focal Loss ê³„ì‚°"""
        ce_loss = nn.CrossEntropyLoss(reduction='none', weight=self.weight)(logits, labels)
        pt = torch.exp(-ce_loss)
        focal_loss = self.alpha * (1 - pt) ** self.gamma * ce_loss
        return focal_loss.mean()

class CustomTrainer(Trainer):
    """ì»¤ìŠ¤í…€ ì†ì‹¤ í•¨ìˆ˜ë¥¼ ì§€ì›í•˜ëŠ” íŠ¸ë ˆì´ë„ˆ"""
    def __init__(self, loss_type='weighted_ce', class_weights=None, samples_per_class=None, **kwargs):
        super().__init__(**kwargs)
        self.loss_type = loss_type
        self.class_weights = class_weights
        self.samples_per_class = samples_per_class
        
        # ì†ì‹¤ í•¨ìˆ˜ ì´ˆê¸°í™”
        if loss_type == 'focal':
            self.loss_fn = FocalLoss(weight=class_weights)
        elif loss_type == 'cbloss' and samples_per_class is not None:
            self.loss_fn = CBLoss(samples_per_class)
        else:  # weighted_ce
            self.loss_fn = None  # ê¸°ë³¸ CrossEntropyLoss ì‚¬ìš©
    
    def compute_loss(self, model, inputs, return_outputs=False, num_items_in_batch=None):
        """ì»¤ìŠ¤í…€ ì†ì‹¤ ê³„ì‚° - ìƒˆë¡œìš´ transformers ë²„ì „ í˜¸í™˜"""
        labels = inputs.get("labels")
        outputs = model(**inputs)
        logits = outputs.get("logits")
        
        if self.loss_fn is not None:
            loss = self.loss_fn(logits, labels)
        else:
            # ê¸°ë³¸ weighted CrossEntropyLoss
            if self.class_weights is not None:
                if self.class_weights.device != logits.device:
                    self.class_weights = self.class_weights.to(logits.device)
                loss_fn = nn.CrossEntropyLoss(weight=self.class_weights)
            else:
                loss_fn = nn.CrossEntropyLoss()
            loss = loss_fn(logits, labels)
        
        return (loss, outputs) if return_outputs else loss

class DemoAwareAugmentation:
    """ì‹œì—° ì•ˆì •ì„±ì„ ìœ„í•œ ë³´ìˆ˜ì  ë°ì´í„° ì¦ê°• (ëˆ„ìˆ˜ ë°©ì§€)"""
    
    def __init__(self, demo_csv_path: Optional[str] = None):
        self.demo_csv_path = demo_csv_path
        self.demo_texts = []
        self.demo_vocab_weights = {}
        self.translation_available = False
        
        # ì‹œì—° í›„ë³´ ë¬¸ì¥ ë¡œë“œ (ëˆ„ìˆ˜ ë°©ì§€: ì§ì ‘ í•™ìŠµì— ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)
        if demo_csv_path and os.path.exists(demo_csv_path):
            self._load_demo_candidates()
            self._compute_vocab_weights()
        
        # ë²ˆì—­ ëª¨ë¸ ì´ˆê¸°í™” ì‹œë„
        self._setup_translation()
        
        print(f"ğŸ¯ ì‹œì—° ì¸ì‹ ì¦ê°•ê¸° ì´ˆê¸°í™” ì™„ë£Œ")
        print(f"   - ì‹œì—° í›„ë³´: {len(self.demo_texts)}ê°œ")
        print(f"   - ë²ˆì—­ ê¸°ëŠ¥: {'âœ…' if self.translation_available else 'âŒ'}")
        print(f"   - ëˆ„ìˆ˜ ë°©ì§€: ì‹œì—° ë¬¸ì¥ ì§ì ‘ í•™ìŠµ ê¸ˆì§€")
    
    def _load_demo_candidates(self):
        """ì‹œì—° í›„ë³´ ë¬¸ì¥ ë¡œë“œ (í•™ìŠµ ë°ì´í„°ë¡œ ì ˆëŒ€ ì‚¬ìš©í•˜ì§€ ì•ŠìŒ)"""
        try:
            demo_df = pd.read_csv(self.demo_csv_path)
            if 'text' in demo_df.columns:
                self.demo_texts = demo_df['text'].dropna().tolist()
                print(f"ğŸ“„ ì‹œì—° í›„ë³´ ë¡œë“œ: {len(self.demo_texts)}ê°œ ë¬¸ì¥")
            else:
                print(f"âš ï¸ ì‹œì—° CSVì— 'text' ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {list(demo_df.columns)}")
        except Exception as e:
            print(f"âŒ ì‹œì—° í›„ë³´ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    def _compute_vocab_weights(self):
        """ì‹œì—° í›„ë³´ì™€ì˜ ì–´íœ˜ ìƒê´€ë„ ê³„ì‚° (TF-IDF ê¸°ë°˜)"""
        if not self.demo_texts:
            return
        
        try:
            # ê°„ë‹¨í•œ TF-IDF ë²¡í„°í™”
            vectorizer = TfidfVectorizer(max_features=1000, stop_words=None, lowercase=True)
            demo_vectors = vectorizer.fit_transform(self.demo_texts)
            vocab = vectorizer.get_feature_names_out()
            
            # ì–´íœ˜ë³„ ê°€ì¤‘ì¹˜ ê³„ì‚° (ë¹ˆë„ ê¸°ë°˜)
            feature_weights = np.mean(demo_vectors.toarray(), axis=0)
            self.demo_vocab_weights = dict(zip(vocab, feature_weights))
            
            print(f"ğŸ” ì–´íœ˜ ìƒê´€ë„ ê³„ì‚° ì™„ë£Œ: {len(self.demo_vocab_weights)}ê°œ í† í°")
            
        except Exception as e:
            print(f"âš ï¸ ì–´íœ˜ ê°€ì¤‘ì¹˜ ê³„ì‚° ì‹¤íŒ¨: {e}")
    
    def _setup_translation(self):
        """ë²ˆì—­ ëª¨ë¸ ì„¤ì • (Back Translationìš©)"""
        try:
            self.ko_to_en_tokenizer = MarianTokenizer.from_pretrained("Helsinki-NLP/opus-mt-ko-en")
            self.ko_to_en_model = MarianMTModel.from_pretrained("Helsinki-NLP/opus-mt-ko-en")
            self.en_to_ko_tokenizer = MarianTokenizer.from_pretrained("Helsinki-NLP/opus-mt-en-ko")
            self.en_to_ko_model = MarianMTModel.from_pretrained("Helsinki-NLP/opus-mt-en-ko")
            self.translation_available = True
            print("âœ… ë²ˆì—­ ëª¨ë¸ ë¡œë“œ ì™„ë£Œ")
        except Exception as e:
            print(f"âš ï¸ ë²ˆì—­ ëª¨ë¸ ë¡œë“œ ì‹¤íŒ¨: {str(e)[:100]}... (ì¦ê°• ê¸°ëŠ¥ ì œí•œ)")
    
    def _get_demo_similarity_weight(self, text: str) -> float:
        """ì‹œì—° í›„ë³´ì™€ì˜ ìœ ì‚¬ë„ ê¸°ë°˜ ê°€ì¤‘ì¹˜ ê³„ì‚° (ëˆ„ìˆ˜ ì—†ëŠ” ë°©ì‹)"""
        if not self.demo_vocab_weights:
            return 1.0
        
        # í…ìŠ¤íŠ¸ì˜ í† í°ë“¤ì´ ì‹œì—° ì–´íœ˜ì™€ ì–¼ë§ˆë‚˜ ê²¹ì¹˜ëŠ”ì§€ ê³„ì‚°
        tokens = text.lower().split()
        overlap_score = sum(self.demo_vocab_weights.get(token, 0) for token in tokens)
        
        # ë³´ìˆ˜ì  ê°€ì¤‘ì¹˜: 1.0~1.2 ë²”ìœ„ë¡œ ì œí•œ (ê³¼ë„í•œ í¸í–¥ ë°©ì§€)
        return min(1.2, 1.0 + overlap_score * 0.1)
    
    def back_translate(self, text: str) -> str:
        """Back Translation: í•œêµ­ì–´ â†’ ì˜ì–´ â†’ í•œêµ­ì–´"""
        if not self.translation_available:
            return text
        
        try:
            # í•œêµ­ì–´ â†’ ì˜ì–´
            inputs = self.ko_to_en_tokenizer(text, return_tensors="pt", truncation=True, max_length=128)
            outputs = self.ko_to_en_model.generate(**inputs, max_length=128, do_sample=True, temperature=0.7)
            english = self.ko_to_en_tokenizer.decode(outputs[0], skip_special_tokens=True)
            
            # ì˜ì–´ â†’ í•œêµ­ì–´
            inputs = self.en_to_ko_tokenizer(english, return_tensors="pt", truncation=True, max_length=128)
            outputs = self.en_to_ko_model.generate(**inputs, max_length=128, do_sample=True, temperature=0.7)
            back_korean = self.en_to_ko_tokenizer.decode(outputs[0], skip_special_tokens=True)
            
            return back_korean.strip() if back_korean.strip() != text else text
            
        except Exception:
            return text
    
    def synonym_replace(self, text: str) -> str:
        """íˆ¬ì ê´€ë ¨ ë™ì˜ì–´ êµì²´"""
        synonyms = {
            'ë§¤ìˆ˜': ['êµ¬ë§¤', 'ë§¤ì…', 'ì·¨ë“'],
            'ë§¤ë„': ['íŒë§¤', 'ë§¤ê°', 'ì²˜ë¶„'],
            'ê¸‰ë“±': ['ìƒìŠ¹', 'í­ë“±', 'ì˜¤ë¦„'],
            'ê¸‰ë½': ['í•˜ë½', 'í­ë½', 'ë–¨ì–´ì§'],
            'ë¶ˆì•ˆ': ['ê±±ì •', 'ìš°ë ¤', 'ë‘ë ¤ì›€'],
            'í™•ì‹ ': ['ë¯¿ìŒ', 'ì‹ ë…', 'ìì‹ ê°'],
            'ì†ì ˆ': ['ì†í•´ë§¤ë„', 'ì†ì‹¤ì •ë¦¬', 'ì»·ë¡œìŠ¤'],
            'ë¬¼íƒ€ê¸°': ['ì¶”ê°€ë§¤ìˆ˜', 'í‰ë‹¨ê°€ë‚®ì¶”ê¸°'],
            'ì¡´ë²„': ['ì¥ê¸°ë³´ìœ ', 'í™€ë”©'],
            'ëŒ€ë°•': ['í°ìˆ˜ìµ', 'ê³ ìˆ˜ìµ']
        }
        
        words = text.split()
        result = []
        
        for word in words:
            # 30% í™•ë¥ ë¡œ ë™ì˜ì–´ êµì²´ (ë³´ìˆ˜ì )
            if random.random() < 0.3:
                for original, replacements in synonyms.items():
                    if original in word:
                        replacement = random.choice(replacements)
                        word = word.replace(original, replacement)
                        break
            result.append(word)
        
        return ' '.join(result)
    
    def insert_filler(self, text: str) -> str:
        """ìì—°ìŠ¤ëŸ¬ìš´ ë¶€ê°€ì–´ ì‚½ì…"""
        fillers = ['ì •ë§ë¡œ', 'ì‚¬ì‹¤', 'ì‹¤ì œë¡œ', 'ê·¸ëŸ°ë°', 'ì•„ë¬´ë˜ë„', 'í™•ì‹¤íˆ', 'ë‹¹ì—°íˆ']
        words = text.split()
        
        if len(words) >= 3 and random.random() < 0.2:  # 20% í™•ë¥ 
            pos = random.randint(1, len(words) - 1)
            filler = random.choice(fillers)
            words.insert(pos, filler)
        
        return ' '.join(words)
    
    def augment_with_demo_awareness(self, texts: List[str], labels: List[str], 
                                  augment_ratio: float = 1.2, minority_only: bool = True) -> Tuple[List[str], List[str]]:
        """ì‹œì—° ì¸ì‹ ì¦ê°• (ëˆ„ìˆ˜ ë°©ì§€í•˜ë©´ì„œ ì•ˆì •ì„± í–¥ìƒ)"""
        
        print(f"ğŸ”„ ì‹œì—° ì¸ì‹ ë°ì´í„° ì¦ê°• ì‹œì‘")
        print(f"   - ì¦ê°• ë¹„ìœ¨: {augment_ratio:.1f}x (ë³´ìˆ˜ì  ìƒí•œ)")
        print(f"   - ì†Œìˆ˜ í´ë˜ìŠ¤ë§Œ: {minority_only}")
        print(f"   - ëˆ„ìˆ˜ ë°©ì§€: ì‹œì—° ë¬¸ì¥ ì§ì ‘ ì‚¬ìš© ê¸ˆì§€")
        
        augmented_texts = texts.copy()
        augmented_labels = labels.copy()
        
        # ë¼ë²¨ë³„ ê°œìˆ˜ ê³„ì‚°
        label_counts = Counter(labels)
        total_original = len(texts)
        target_total = int(total_original * augment_ratio)
        
        print(f"ğŸ“Š ì›ë³¸ ë¶„í¬: {dict(label_counts)}")
        
        for label, count in label_counts.items():
            # ì†Œìˆ˜ í´ë˜ìŠ¤ë§Œ ì¦ê°•í•˜ëŠ” ê²½ìš°
            if minority_only:
                median_count = np.median(list(label_counts.values()))
                if count >= median_count:
                    continue
            
            # ëª©í‘œ ê°œìˆ˜ ê³„ì‚° (ê³¼ë„í•˜ê²Œ ëŠ˜ë¦¬ì§€ ì•ŠìŒ)
            target_count = min(count * 2, int(count * augment_ratio))  # ìµœëŒ€ 2ë°°
            need_count = target_count - count
            
            if need_count <= 0:
                continue
            
            # í•´ë‹¹ ë¼ë²¨ì˜ í…ìŠ¤íŠ¸ë“¤
            label_texts = [text for text, lbl in zip(texts, labels) if lbl == label]
            generated = 0
            
            for _ in range(need_count * 3):  # ì—¬ìœ ë¶„ìœ¼ë¡œ 3ë°° ì‹œë„
                if generated >= need_count:
                    break
                
                # ì›ë³¸ í…ìŠ¤íŠ¸ ì„ íƒ
                source_text = random.choice(label_texts)
                
                # ì‹œì—° ìœ ì‚¬ë„ ê¸°ë°˜ ê°€ì¤‘ ìƒ˜í”Œë§ (ëˆ„ìˆ˜ ì—†ì´)
                demo_weight = self._get_demo_similarity_weight(source_text)
                if random.random() > demo_weight / 1.2:  # ê°€ì¤‘ì¹˜ ì ìš©
                    continue
                
                # ì¦ê°• ë°©ë²• ì„ íƒ
                methods = ['synonym', 'filler']
                if self.translation_available:
                    methods.append('back_translate')
                
                method = random.choice(methods)
                
                # ì¦ê°• ì‹¤í–‰
                if method == 'back_translate':
                    aug_text = self.back_translate(source_text)
                elif method == 'synonym':
                    aug_text = self.synonym_replace(source_text)
                else:  # filler
                    aug_text = self.insert_filler(source_text)
                
                # ìœ íš¨ì„± ê²€ì‚¬ (ëˆ„ìˆ˜ ë°©ì§€)
                if self._is_valid_augmented_text(aug_text, source_text):
                    augmented_texts.append(aug_text)
                    augmented_labels.append(label)
                    generated += 1
            
            print(f"   {label}: {count} â†’ {count + generated} (+{generated})")
        
        print(f"âœ… ì¦ê°• ì™„ë£Œ: {len(augmented_texts)}ê°œ ({len(augmented_texts) - total_original:+d})")
        
        return augmented_texts, augmented_labels
    
    def _is_valid_augmented_text(self, aug_text: str, original_text: str) -> bool:
        """ì¦ê°• í…ìŠ¤íŠ¸ ìœ íš¨ì„± ê²€ì‚¬ (ëˆ„ìˆ˜ ë°©ì§€)"""
        # 1. ìµœì†Œ ê¸¸ì´ ì²´í¬
        if len(aug_text.strip()) < 5:
            return False
        
        # 2. ì›ë³¸ê³¼ ë™ì¼í•œì§€ ì²´í¬
        if aug_text.strip() == original_text.strip():
            return False
        
        # 3. ì‹œì—° í›„ë³´ì™€ ë™ì¼/ë§¤ìš° ìœ ì‚¬í•œì§€ ì²´í¬ (ëˆ„ìˆ˜ ë°©ì§€)
        for demo_text in self.demo_texts:
            if aug_text.strip() == demo_text.strip():
                return False
            # 90% ì´ìƒ ê²¹ì¹˜ë©´ ê±°ë¶€
            if self._text_similarity(aug_text, demo_text) > 0.9:
                return False
        
        # 4. ê¸ˆì§€ì–´ ì²´í¬
        banned_words = ['í…ŒìŠ¤íŠ¸', 'test', 'ìƒ˜í”Œ', 'sample']
        if any(word in aug_text.lower() for word in banned_words):
            return False
        
        return True
    
    def _text_similarity(self, text1: str, text2: str) -> float:
        """ê°„ë‹¨í•œ í…ìŠ¤íŠ¸ ìœ ì‚¬ë„ ê³„ì‚°"""
        words1 = set(text1.lower().split())
        words2 = set(text2.lower().split())
        if not words1 or not words2:
            return 0.0
        return len(words1 & words2) / len(words1 | words2)

class InvestmentEmotionDataset(Dataset):
    """íˆ¬ì ê°ì • ë¶„ì„ ë°ì´í„°ì…‹"""
    
    def __init__(self, texts: List[str], labels: List[int], tokenizer, max_length: int = 192):
        self.texts = texts
        self.labels = labels
        self.tokenizer = tokenizer
        self.max_length = max_length
    
    def __len__(self) -> int:
        return len(self.texts)
    
    def __getitem__(self, idx: int) -> Dict[str, torch.Tensor]:
        text = str(self.texts[idx])
        label = self.labels[idx]
        
        encoding = self.tokenizer(
            text,
            truncation=True,
            padding='max_length',
            max_length=self.max_length,
            return_tensors='pt'
        )
        
        return {
            'input_ids': encoding['input_ids'].flatten(),
            'attention_mask': encoding['attention_mask'].flatten(),
            'labels': torch.tensor(label, dtype=torch.long)
        }

def load_data_from_central_manager() -> pd.DataFrame:
    """ì¤‘ì•™ ë°ì´í„° ê´€ë¦¬ìì—ì„œ ë°ì´í„° ë¡œë“œ"""
    if get_data_manager is None:
        # Mock ë°ì´í„° ìƒì„± (í…ŒìŠ¤íŠ¸ìš©) - ë” í˜„ì‹¤ì ì¸ ë°ì´í„°
        print("ğŸ“Š Mock ë°ì´í„° ìƒì„± ì¤‘...")
        mock_data = []
        emotions = ['ê³µí¬', 'ëƒ‰ì •', 'ë¶ˆì•ˆ', 'ìš•ì‹¬', 'í™•ì‹ ', 'í›„íšŒ', 'í¥ë¶„']
        
        # ë” ë‹¤ì–‘í•˜ê³  í˜„ì‹¤ì ì¸ íˆ¬ì ë©”ëª¨ í…œí”Œë¦¿
        memo_templates = {
            'ê³µí¬': [
                "ì½”ìŠ¤í”¼ê°€ ë„ˆë¬´ ë–¨ì–´ì ¸ì„œ ë¬´ì„œì›Œì„œ ì „ëŸ‰ ë§¤ë„í–ˆì–´ìš”",
                "í­ë½ì¥ì—ì„œ íŒ¨ë‹‰ë§¤ë„ í•´ë²„ë ¸ìŠµë‹ˆë‹¤",
                "ì†ì‹¤ì´ ë¬´ì„œì›Œì„œ ê¸‰í•˜ê²Œ ì†ì ˆí–ˆì–´ìš”",
                "í•˜ë½ì¥ì´ ë‘ë ¤ì›Œì„œ ëª¨ë“  í¬ì§€ì…˜ ì •ë¦¬",
                "ê³µí¬ê°ì— íœ©ì“¸ë ¤ì„œ ì €ê°€ì— íŒ”ì•˜ìŠµë‹ˆë‹¤"
            ],
            'ëƒ‰ì •': [
                "ê¸°ìˆ ì  ë¶„ì„ ê²°ê³¼ ì ì • ë§¤ìˆ˜ íƒ€ì´ë°ìœ¼ë¡œ íŒë‹¨ë¨",
                "í€ë”ë©˜í„¸ ë¶„ì„ í›„ ëƒ‰ì •í•˜ê²Œ ë§¤ìˆ˜ ê²°ì •",
                "ì°¨íŠ¸ ë¶„ì„ ê²°ê³¼ì— ë”°ë¼ ë§¤ë„í–ˆìŠµë‹ˆë‹¤",
                "ì¬ë¬´ì œí‘œ ê²€í†  í›„ í•©ë¦¬ì  íŒë‹¨ìœ¼ë¡œ ë§¤ìˆ˜",
                "ì‹œì¥ ìƒí™©ì„ ë¶„ì„í•œ ê²°ê³¼ ë§¤ë„ íƒ€ì´ë°"
            ],
            'ë¶ˆì•ˆ': [
                "ì†ì‹¤ì´ ë„ˆë¬´ ì»¤ì„œ ë¶ˆì•ˆí•´ì„œ ì¼ë¶€ ë§¤ë„í–ˆìŠµë‹ˆë‹¤",
                "ê³„ì† ë–¨ì–´ì§ˆê¹Œë´ ë¶ˆì•ˆí•´ì„œ íŒ”ì•˜ì–´ìš”",
                "ë¶ˆì•ˆê° ë•Œë¬¸ì— ë°˜ì ˆë§Œ ë§¤ë„í–ˆìŠµë‹ˆë‹¤",
                "í•˜ë½ì´ ì§€ì†ë ê¹Œ ê±±ì •ë˜ì–´ ì¼ë¶€ ë§¤ë„",
                "ì•ìœ¼ë¡œê°€ ë¶ˆì•ˆí•´ì„œ í¬ì§€ì…˜ ì¤„ì˜€ì–´ìš”"
            ],
            'ìš•ì‹¬': [
                "ë‹¤ë“¤ ì‚¬ë¼ê³  í•´ì„œ ìš•ì‹¬ë‚´ì„œ ì¶”ê°€ ë§¤ìˆ˜í–ˆì–´ìš”",
                "ë” ì˜¤ë¥¼ ê²ƒ ê°™ì•„ì„œ ìš•ì‹¬ë¶€ë ¤ ë¬¼íƒ€ê¸°",
                "ëŒ€ë°•ë‚  ê²ƒ ê°™ì•„ì„œ ìš•ì‹¬ë‚´ì„œ ì˜¬ì¸",
                "ìš•ì‹¬ì´ ë‚˜ì„œ ë¹šë‚´ì„œ ì¶”ê°€ ë§¤ìˆ˜",
                "í° ìˆ˜ìµì„ ìœ„í•´ ìš•ì‹¬ë¶€ë ¤ì„œ ë ˆë²„ë¦¬ì§€"
            ],
            'í™•ì‹ ': [
                "ì™„ë²½í•œ ë¶„ì„ í›„ í™•ì‹ ì„ ê°€ì§€ê³  ë§¤ìˆ˜í–ˆìŠµë‹ˆë‹¤",
                "ì´ ì¢…ëª©ì€ í™•ì‹¤í•˜ë‹¤ê³  ìƒê°í•´ì„œ ë§¤ìˆ˜",
                "ë¶„ëª…íˆ ì˜¤ë¥¼ ê±°ë¼ëŠ” í™•ì‹ ìœ¼ë¡œ ë§¤ìˆ˜",
                "í™•ì‹¤í•œ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ ë§¤ìˆ˜ ê²°ì •",
                "100% í™•ì‹ ì„ ê°€ì§€ê³  ëŒ€ëŸ‰ ë§¤ìˆ˜"
            ],
            'í›„íšŒ': [
                "ë„ˆë¬´ ì¼ì° íŒ ê²ƒ ê°™ì•„ì„œ í›„íšŒë©ë‹ˆë‹¤",
                "ë” ê¸°ë‹¤ë ¸ì–´ì•¼ í–ˆëŠ”ë° í›„íšŒìŠ¤ëŸ¬ì›Œìš”",
                "ì„±ê¸‰í•˜ê²Œ íŒ”ì•„ì„œ í›„íšŒí•˜ê³  ìˆìŠµë‹ˆë‹¤",
                "ì¢€ ë” ì°¸ì•˜ìœ¼ë©´ ì¢‹ì•˜ì„ í…ë° í›„íšŒë¨",
                "íƒ€ì´ë°ì„ ì˜ëª» ì¡ì•„ì„œ í›„íšŒìŠ¤ëŸ½ìŠµë‹ˆë‹¤"
            ],
            'í¥ë¶„': [
                "ê¸‰ë“± ì†Œì‹ì— í¥ë¶„í•´ì„œ ëŒ€ëŸ‰ ë§¤ìˆ˜í–ˆì–´ìš”",
                "ìƒí•œê°€ ë‰´ìŠ¤ì— í¥ë¶„í•´ì„œ ì¶”ê°€ ë§¤ìˆ˜",
                "ëŒ€ë°• ì†Œì‹ì— í¥ë¶„í•´ì„œ ì˜¬ì¸í–ˆìŠµë‹ˆë‹¤",
                "ê¸‰ë“±ì— í¥ë¶„í•´ì„œ ì´ì„±ì„ ìƒê³  ë§¤ìˆ˜",
                "ì¢‹ì€ ë‰´ìŠ¤ì— í¥ë¶„í•´ì„œ ì¦‰ì‹œ ë§¤ìˆ˜"
            ]
        }
        
        # ì‚¬ìš©ìë³„ ë‹¤ì–‘í•œ íŒ¨í„´ ìƒì„±
        user_count = 72  # ì‚¬ìš©ì ìˆ˜
        records_per_emotion = 72  # ê°ì •ë³„ ë ˆì½”ë“œ ìˆ˜
        
        for emotion in emotions:
            templates = memo_templates[emotion]
            for i in range(records_per_emotion):
                user_id = (i % user_count) + 1
                template_idx = i % len(templates)
                base_memo = templates[template_idx]
                
                # ì•½ê°„ì˜ ë³€í˜• ì¶”ê°€
                variations = [
                    f"{base_memo}",
                    f"{base_memo} (ë³€í˜•_{i})",
                    f"ì •ë§ {base_memo}",
                    f"ê²°êµ­ {base_memo}",
                    f"ì‚¬ì‹¤ {base_memo}"
                ]
                
                memo = variations[i % len(variations)]
                
                mock_data.append({
                    'username': f'user_{user_id}',
                    'ë©”ëª¨': memo,
                    'ê°ì •íƒœê·¸': emotion
                })
        
        print(f"âœ… Mock ë°ì´í„° ìƒì„± ì™„ë£Œ: {len(mock_data)}ê°œ ë ˆì½”ë“œ")
        print(f"ğŸ‘¥ ê°€ìƒ ì‚¬ìš©ì: {user_count}ëª…")
        return pd.DataFrame(mock_data)
    
    print("ğŸ”— ì¤‘ì•™ ë°ì´í„° ê´€ë¦¬ì ì—°ê²° ì‹œë„ ì¤‘...")
    try:
        data_manager = get_data_manager()
        all_users = data_manager.get_all_users()
        print(f"ğŸ‘¥ ì´ {len(all_users)}ëª…ì˜ ì‚¬ìš©ì ë°œê²¬")
        
        all_trades = []
        for user in all_users:
            user_trades = data_manager.get_user_trades(user.username)
            if user_trades:
                for trade in user_trades:
                    trade['username'] = user.username  # ì‚¬ìš©ì ì •ë³´ ì¶”ê°€
                all_trades.extend(user_trades)
        
        if not all_trades:
            raise ValueError("ë¡œë“œí•  ìˆ˜ ìˆëŠ” ê±°ë˜ ë°ì´í„°ê°€ ì—†ìŠµë‹ˆë‹¤.")
        
        df = pd.DataFrame(all_trades)
        print(f"âœ… ì‹¤ì œ ë°ì´í„° ë¡œë“œ ì™„ë£Œ: {len(df)}ê°œ ë ˆì½”ë“œ")
        return df
        
    except Exception as e:
        print(f"âŒ ì¤‘ì•™ ë°ì´í„° ë¡œë“œ ì‹¤íŒ¨: {e}")
        print("ğŸ”„ Mock ë°ì´í„°ë¡œ fallback...")
        return load_data_from_central_manager()  # Mock ë°ì´í„°ë¡œ ì¬ê·€ í˜¸ì¶œ

def create_7_to_4_mapping(df: pd.DataFrame) -> pd.DataFrame:
    """7í´ë˜ìŠ¤ë¥¼ 4í´ë˜ìŠ¤ë¡œ ë§¤í•‘"""
    df = df.copy()
    df['ê°ì •íƒœê·¸_4cls'] = df['ê°ì •íƒœê·¸'].map(LABEL_7TO4_MAPPING)
    
    # ë§¤í•‘ë˜ì§€ ì•Šì€ ë¼ë²¨ ì²˜ë¦¬
    unmapped = df[df['ê°ì •íƒœê·¸_4cls'].isna()]
    if len(unmapped) > 0:
        print(f"âš ï¸ ë§¤í•‘ë˜ì§€ ì•Šì€ ë¼ë²¨: {unmapped['ê°ì •íƒœê·¸'].unique()}")
        df = df.dropna(subset=['ê°ì •íƒœê·¸_4cls'])
    
    return df

def compute_class_weights(labels: List[str]) -> torch.Tensor:
    """í´ë˜ìŠ¤ ë¶ˆê· í˜• ë³´ì •ì„ ìœ„í•œ ê°€ì¤‘ì¹˜ ê³„ì‚°"""
    label_counts = Counter(labels)
    total = len(labels)
    num_classes = len(label_counts)
    
    weights = []
    for i in range(num_classes):
        # sklearnì˜ 'balanced' ì „ëµê³¼ ë™ì¼
        weight = total / (num_classes * label_counts[list(label_counts.keys())[i]])
        weights.append(weight)
    
    return torch.FloatTensor(weights)

def create_oof_predictions(df: pd.DataFrame, class_type: str = '7cls', 
                          model_name: str = "beomi/KcELECTRA-base",
                          loss_type: str = 'weighted_ce',
                          augment_ratio: float = 1.2,
                          minority_only: bool = True,
                          demo_csv: Optional[str] = None,
                          n_folds: int = 5) -> Dict[str, Any]:
    """ì‚¬ìš©ì ë‹¨ìœ„ GroupKFoldë¡œ OOF ì˜ˆì¸¡ ìƒì„±"""
    
    print(f"ğŸ”„ {class_type} OOF ì˜ˆì¸¡ ìƒì„± ì‹œì‘ (GroupKFold {n_folds}-Fold)")
    
    # ë¼ë²¨ ì»¬ëŸ¼ ì„ íƒ
    label_col = 'ê°ì •íƒœê·¸' if class_type == '7cls' else 'ê°ì •íƒœê·¸_4cls'
    
    # ë¼ë²¨ ì¸ì½”ë”©
    label_encoder = LabelEncoder()
    df['label_encoded'] = label_encoder.fit_transform(df[label_col])
    
    label_to_id = {label: idx for idx, label in enumerate(label_encoder.classes_)}
    id_to_label = {idx: label for label, idx in label_to_id.items()}
    
    # GroupKFold ì„¤ì • (ì‚¬ìš©ì ë‹¨ìœ„ ë¶„í• )
    gkf = GroupKFold(n_splits=n_folds)
    groups = df['username'].values
    
    oof_predictions = np.zeros(len(df))
    oof_probabilities = np.zeros((len(df), len(label_to_id)))
    fold_scores = []
    
    # ê° Foldë³„ í•™ìŠµ
    for fold, (train_idx, val_idx) in enumerate(gkf.split(df, df['label_encoded'], groups)):
        print(f"\nğŸ“Š Fold {fold + 1}/{n_folds}")
        
        train_df = df.iloc[train_idx].copy()
        val_df = df.iloc[val_idx].copy()
        
        print(f"   í›ˆë ¨: {len(train_df)}ê°œ ({len(train_df['username'].unique())}ëª…)")
        print(f"   ê²€ì¦: {len(val_df)}ê°œ ({len(val_df['username'].unique())}ëª…)")
        
        # ë°ì´í„° ì¦ê°• (í›ˆë ¨ ë°ì´í„°ë§Œ)
        augmenter = DemoAwareAugmentation(demo_csv)
        train_texts, train_labels = augmenter.augment_with_demo_awareness(
            train_df['ë©”ëª¨'].tolist(),
            train_df[label_col].tolist(),
            augment_ratio=augment_ratio,
            minority_only=minority_only
        )
        
        # ì¦ê°•ëœ ë¼ë²¨ ì¸ì½”ë”©
        train_labels_encoded = [label_to_id[label] for label in train_labels]
        val_labels_encoded = val_df['label_encoded'].tolist()
        
        # ëª¨ë¸ ì´ˆê¸°í™”
        tokenizer = AutoTokenizer.from_pretrained(model_name)
        model = AutoModelForSequenceClassification.from_pretrained(
            model_name,
            num_labels=len(label_to_id),
            hidden_dropout_prob=0.2,
            attention_probs_dropout_prob=0.2
        )
        
        # ë°ì´í„°ì…‹ ìƒì„±
        train_dataset = InvestmentEmotionDataset(train_texts, train_labels_encoded, tokenizer)
        val_dataset = InvestmentEmotionDataset(val_df['ë©”ëª¨'].tolist(), val_labels_encoded, tokenizer)
        
        # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°
        class_weights = compute_class_weights(train_labels)
        samples_per_class = [train_labels.count(label) for label in label_encoder.classes_]
        
        # í›ˆë ¨ ì„¤ì •
        output_dir = f"./temp_fold_{fold}"
        training_args = TrainingArguments(
            output_dir=output_dir,
            num_train_epochs=3,  # Foldë³„ë¡œëŠ” ì§§ê²Œ
            per_device_train_batch_size=8,
            per_device_eval_batch_size=16,
            warmup_ratio=0.1,
            weight_decay=0.01,
            learning_rate=2e-5,
            logging_steps=50,
            eval_strategy="no",  # Fold ë‚´ì—ì„œëŠ” ê²€ì¦ ì—†ì´
            save_strategy="no",
            remove_unused_columns=False,
            dataloader_num_workers=0,
            fp16=torch.cuda.is_available(),
            report_to=None,
        )
        
        # íŠ¸ë ˆì´ë„ˆ ì´ˆê¸°í™”
        trainer = CustomTrainer(
            loss_type=loss_type,
            class_weights=class_weights,
            samples_per_class=samples_per_class,
            model=model,
            args=training_args,
            train_dataset=train_dataset,
            tokenizer=tokenizer,
        )
        
        # í›ˆë ¨
        trainer.train()
        
        # ê²€ì¦ ì˜ˆì¸¡
        predictions = trainer.predict(val_dataset)
        val_pred_probs = torch.softmax(torch.from_numpy(predictions.predictions), dim=-1).numpy()
        val_pred_labels = np.argmax(val_pred_probs, axis=1)
        
        # OOF ì €ì¥
        oof_predictions[val_idx] = val_pred_labels
        oof_probabilities[val_idx] = val_pred_probs
        
        # Fold ì„±ëŠ¥ ê³„ì‚°
        fold_acc = accuracy_score(val_labels_encoded, val_pred_labels)
        fold_f1_macro = f1_score(val_labels_encoded, val_pred_labels, average='macro')
        fold_f1_weighted = f1_score(val_labels_encoded, val_pred_labels, average='weighted')
        
        fold_scores.append({
            'fold': fold + 1,
            'accuracy': fold_acc,
            'f1_macro': fold_f1_macro,
            'f1_weighted': fold_f1_weighted
        })
        
        print(f"   Fold {fold + 1} ì„±ëŠ¥: Acc={fold_acc:.4f}, F1_macro={fold_f1_macro:.4f}")
        
        # ì„ì‹œ í´ë” ì •ë¦¬
        import shutil
        if os.path.exists(output_dir):
            shutil.rmtree(output_dir)
    
    # ì „ì²´ OOF ì„±ëŠ¥ ê³„ì‚°
    oof_acc = accuracy_score(df['label_encoded'], oof_predictions)
    oof_f1_macro = f1_score(df['label_encoded'], oof_predictions, average='macro')
    oof_f1_weighted = f1_score(df['label_encoded'], oof_predictions, average='weighted')
    
    print(f"\nğŸ¯ {class_type} OOF ìµœì¢… ì„±ëŠ¥:")
    print(f"   ì •í™•ë„: {oof_acc:.4f}")
    print(f"   F1 Macro: {oof_f1_macro:.4f}")
    print(f"   F1 Weighted: {oof_f1_weighted:.4f}")
    
    return {
        'predictions': oof_predictions,
        'probabilities': oof_probabilities,
        'fold_scores': fold_scores,
        'overall_scores': {
            'accuracy': oof_acc,
            'f1_macro': oof_f1_macro,
            'f1_weighted': oof_f1_weighted
        },
        'label_to_id': label_to_id,
        'id_to_label': id_to_label,
        'true_labels': df['label_encoded'].values
    }

def create_holdout_model(df: pd.DataFrame, class_type: str = '4cls',
                        model_name: str = "beomi/KcELECTRA-base",
                        loss_type: str = 'weighted_ce',
                        augment_ratio: float = 1.2,
                        minority_only: bool = True,
                        demo_csv: Optional[str] = None,
                        output_dir: str = "./sentiment_model") -> Dict[str, Any]:
    """ì‹œì—°ìš© 4í´ë˜ìŠ¤ ëª¨ë¸ ìƒì„± (Holdout ë°©ì‹)"""
    
    print(f"ğŸ¯ {class_type} ì‹œì—°ìš© ëª¨ë¸ ìƒì„± (Holdout)")
    
    # ë¼ë²¨ ì»¬ëŸ¼ ì„ íƒ
    label_col = 'ê°ì •íƒœê·¸' if class_type == '7cls' else 'ê°ì •íƒœê·¸_4cls'
    
    # ë¼ë²¨ ì¸ì½”ë”©
    label_encoder = LabelEncoder()
    df['label_encoded'] = label_encoder.fit_transform(df[label_col])
    
    label_to_id = {label: idx for idx, label in enumerate(label_encoder.classes_)}
    id_to_label = {idx: label for label, idx in label_to_id.items()}
    
    # í›ˆë ¨/ê²€ì¦ ë¶„í•  (stratified)
    train_df, val_df = train_test_split(
        df, test_size=0.15, random_state=RANDOM_SEED,
        stratify=df['label_encoded']
    )
    
    print(f"ğŸ“Š ë°ì´í„° ë¶„í• : í›ˆë ¨ {len(train_df)}, ê²€ì¦ {len(val_df)}")
    
    # ë°ì´í„° ì¦ê°•
    augmenter = DemoAwareAugmentation(demo_csv)
    train_texts, train_labels = augmenter.augment_with_demo_awareness(
        train_df['ë©”ëª¨'].tolist(),
        train_df[label_col].tolist(),
        augment_ratio=augment_ratio,
        minority_only=minority_only
    )
    
    # ë¼ë²¨ ì¸ì½”ë”©
    train_labels_encoded = [label_to_id[label] for label in train_labels]
    val_labels_encoded = val_df['label_encoded'].tolist()
    
    # ëª¨ë¸ ì´ˆê¸°í™”
    tokenizer = AutoTokenizer.from_pretrained(model_name)
    model = AutoModelForSequenceClassification.from_pretrained(
        model_name,
        num_labels=len(label_to_id),
        hidden_dropout_prob=0.2,
        attention_probs_dropout_prob=0.2
    )
    
    # ë°ì´í„°ì…‹ ìƒì„±
    train_dataset = InvestmentEmotionDataset(train_texts, train_labels_encoded, tokenizer)
    val_dataset = InvestmentEmotionDataset(val_df['ë©”ëª¨'].tolist(), val_labels_encoded, tokenizer)
    
    # í´ë˜ìŠ¤ ê°€ì¤‘ì¹˜ ê³„ì‚°
    class_weights = compute_class_weights(train_labels)
    samples_per_class = [train_labels.count(label) for label in label_encoder.classes_]
    
    # í›ˆë ¨ ì„¤ì •
    model_output_dir = os.path.join(output_dir, class_type)
    os.makedirs(model_output_dir, exist_ok=True)
    
    training_args = TrainingArguments(
        output_dir=model_output_dir,
        num_train_epochs=6,
        per_device_train_batch_size=8,
        per_device_eval_batch_size=16,
        warmup_ratio=0.1,
        weight_decay=0.01,
        learning_rate=2e-5,
        logging_steps=50,
        eval_strategy="steps",
        eval_steps=100,
        save_strategy="steps",
        save_steps=100,
        load_best_model_at_end=True,
        metric_for_best_model="f1_weighted",
        greater_is_better=True,
        save_total_limit=2,
        remove_unused_columns=False,
        dataloader_num_workers=0,
        fp16=torch.cuda.is_available(),
        gradient_accumulation_steps=2,
        label_smoothing_factor=0.05,
        report_to=None,
    )
    
    def compute_metrics(eval_pred):
        predictions, labels = eval_pred
        predictions = np.argmax(predictions, axis=1)
        
        accuracy = accuracy_score(labels, predictions)
        f1_macro = f1_score(labels, predictions, average='macro')
        f1_weighted = f1_score(labels, predictions, average='weighted')
        
        return {
            'accuracy': accuracy,
            'f1_macro': f1_macro,
            'f1_weighted': f1_weighted
        }
    
    # íŠ¸ë ˆì´ë„ˆ ì´ˆê¸°í™”
    trainer = CustomTrainer(
        loss_type=loss_type,
        class_weights=class_weights,
        samples_per_class=samples_per_class,
        model=model,
        args=training_args,
        train_dataset=train_dataset,
        eval_dataset=val_dataset,
        tokenizer=tokenizer,
        compute_metrics=compute_metrics,
        callbacks=[EarlyStoppingCallback(early_stopping_patience=3)]
    )
    
    # í›ˆë ¨
    print("ğŸƒâ€â™‚ï¸ ëª¨ë¸ í›ˆë ¨ ì‹œì‘...")
    trainer.train()
    
    # ìµœì¢… í‰ê°€
    eval_results = trainer.evaluate()
    print(f"âœ… ìµœì¢… ì„±ëŠ¥:")
    print(f"   ì •í™•ë„: {eval_results['eval_accuracy']:.4f}")
    print(f"   F1 Macro: {eval_results['eval_f1_macro']:.4f}")
    print(f"   F1 Weighted: {eval_results['eval_f1_weighted']:.4f}")
    
    # ëª¨ë¸ ì €ì¥
    trainer.save_model()
    tokenizer.save_pretrained(model_output_dir)
    
    # ëª¨ë¸ ì •ë³´ ì €ì¥
    model_info = {
        'class_type': class_type,
        'model_name': model_name,
        'loss_type': loss_type,
        'label_to_id': label_to_id,
        'id_to_label': {str(k): v for k, v in id_to_label.items()},
        'num_labels': len(label_to_id),
        'training_date': time.strftime('%Y-%m-%d %H:%M:%S'),
        'augment_ratio': augment_ratio,
        'minority_only': minority_only,
        'performance': {
            'accuracy': eval_results['eval_accuracy'],
            'f1_macro': eval_results['eval_f1_macro'],
            'f1_weighted': eval_results['eval_f1_weighted']
        },
        'data_stats': {
            'train_size': len(train_texts),
            'val_size': len(val_df),
            'original_train_size': len(train_df)
        }
    }
    
    with open(os.path.join(model_output_dir, 'model_info.json'), 'w', encoding='utf-8') as f:
        json.dump(model_info, f, ensure_ascii=False, indent=2)
    
    # ê²€ì¦ ì˜ˆì¸¡
    val_predictions = trainer.predict(val_dataset)
    val_pred_probs = torch.softmax(torch.from_numpy(val_predictions.predictions), dim=-1).numpy()
    val_pred_labels = np.argmax(val_pred_probs, axis=1)
    
    return {
        'model': model,
        'tokenizer': tokenizer,
        'predictions': val_pred_labels,
        'probabilities': val_pred_probs,
        'true_labels': val_labels_encoded,
        'label_to_id': label_to_id,
        'id_to_label': id_to_label,
        'performance': model_info['performance'],
        'output_dir': model_output_dir
    }

def create_visualizations(results: Dict[str, Any], output_dir: str, class_type: str,
                         reject_threshold: float = 0.45):
    """ì„±ëŠ¥ ì‹œê°í™” ë° ë¦¬í¬íŠ¸ ìƒì„±"""
    
    print(f"ğŸ“Š {class_type} ì‹œê°í™” ìƒì„± ì¤‘...")
    
    os.makedirs(output_dir, exist_ok=True)
    
    # ê¸°ë³¸ ë³€ìˆ˜ ì„¤ì •
    predictions = results['predictions']
    probabilities = results['probabilities']
    true_labels = results['true_labels']
    id_to_label = results['id_to_label']
    
    # 1. Confusion Matrix
    plt.figure(figsize=(10, 8))
    cm = confusion_matrix(true_labels, predictions)
    
    labels = [id_to_label[i] for i in range(len(id_to_label))]
    sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', 
                xticklabels=labels, yticklabels=labels)
    plt.title(f'{class_type} Confusion Matrix')
    plt.ylabel('True Label')
    plt.xlabel('Predicted Label')
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, f'{class_type}_confusion_matrix.png'), dpi=300)
    plt.close()
    
    # 2. ë¼ë²¨ë³„ F1 Score
    f1_scores = f1_score(true_labels, predictions, average=None)
    
    plt.figure(figsize=(12, 6))
    bars = plt.bar(labels, f1_scores, alpha=0.7)
    plt.title(f'{class_type} F1 Scores by Label')
    plt.ylabel('F1 Score')
    plt.xticks(rotation=45)
    
    # ë§‰ëŒ€ ìœ„ì— ê°’ í‘œì‹œ
    for bar, score in zip(bars, f1_scores):
        plt.text(bar.get_x() + bar.get_width()/2, bar.get_height() + 0.01,
                f'{score:.3f}', ha='center', va='bottom')
    
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, f'{class_type}_f1_by_label.png'), dpi=300)
    plt.close()
    
    # 3. ì‹ ë¢°ë„ ë¶„í¬
    max_probs = np.max(probabilities, axis=1)
    
    plt.figure(figsize=(10, 6))
    plt.hist(max_probs, bins=50, alpha=0.7, edgecolor='black')
    plt.axvline(reject_threshold, color='red', linestyle='--', 
                label=f'Reject Threshold ({reject_threshold})')
    plt.title(f'{class_type} Confidence Distribution')
    plt.xlabel('Max Probability')
    plt.ylabel('Frequency')
    plt.legend()
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, f'{class_type}_confidence_dist.png'), dpi=300)
    plt.close()
    
    # 4. ì„ê³„ê°’ë³„ ì •í™•ë„-ì»¤ë²„ë¦¬ì§€ ê³¡ì„ 
    thresholds = np.arange(0.1, 1.0, 0.05)
    accuracies = []
    coverages = []
    
    for threshold in thresholds:
        # ì„ê³„ê°’ ì´ìƒì˜ ì˜ˆì¸¡ë§Œ ê³ ë ¤
        confident_mask = max_probs >= threshold
        if np.sum(confident_mask) == 0:
            accuracies.append(0)
            coverages.append(0)
            continue
        
        confident_preds = predictions[confident_mask]
        confident_true = true_labels[confident_mask]
        
        acc = accuracy_score(confident_true, confident_preds)
        cov = np.mean(confident_mask)
        
        accuracies.append(acc)
        coverages.append(cov)
    
    plt.figure(figsize=(10, 6))
    plt.plot(thresholds, accuracies, 'b-', label='Accuracy', linewidth=2)
    plt.plot(thresholds, coverages, 'r-', label='Coverage', linewidth=2)
    plt.axvline(reject_threshold, color='green', linestyle='--', 
                label=f'Selected Threshold ({reject_threshold})')
    
    plt.title(f'{class_type} Accuracy-Coverage Trade-off')
    plt.xlabel('Confidence Threshold')
    plt.ylabel('Score')
    plt.legend()
    plt.grid(True, alpha=0.3)
    plt.tight_layout()
    plt.savefig(os.path.join(output_dir, f'{class_type}_threshold_curve.png'), dpi=300)
    plt.close()
    
    # 5. ì„±ëŠ¥ ë©”íŠ¸ë¦­ JSON ì €ì¥
    rejection_rate = np.mean(max_probs < reject_threshold)
    confident_mask = max_probs >= reject_threshold
    
    if np.sum(confident_mask) > 0:
        confident_acc = accuracy_score(true_labels[confident_mask], predictions[confident_mask])
        confident_f1 = f1_score(true_labels[confident_mask], predictions[confident_mask], average='weighted')
    else:
        confident_acc = 0.0
        confident_f1 = 0.0
    
    metrics = {
        'overall_performance': {
            'accuracy': float(accuracy_score(true_labels, predictions)),
            'f1_macro': float(f1_score(true_labels, predictions, average='macro')),
            'f1_weighted': float(f1_score(true_labels, predictions, average='weighted'))
        },
        'confidence_analysis': {
            'reject_threshold': reject_threshold,
            'rejection_rate': float(rejection_rate),
            'coverage': float(1 - rejection_rate),
            'confident_accuracy': float(confident_acc),
            'confident_f1_weighted': float(confident_f1)
        },
        'label_wise_f1': {
            id_to_label[i]: float(score) 
            for i, score in enumerate(f1_scores)
        },
        'confusion_matrix': cm.tolist()
    }
    
    with open(os.path.join(output_dir, f'{class_type}_metrics.json'), 'w', encoding='utf-8') as f:
        json.dump(metrics, f, ensure_ascii=False, indent=2)
    
    print(f"âœ… {class_type} ì‹œê°í™” ì™„ë£Œ: {output_dir}")
    
    return metrics

def predict_with_model(text: str, model_dir: str, reject_threshold: float = 0.45) -> Dict[str, Any]:
    """ë‹¨ì¼ í…ìŠ¤íŠ¸ ì˜ˆì¸¡ (ë³´ë¥˜ ê¸°ëŠ¥ í¬í•¨)"""
    
    # ëª¨ë¸ ì •ë³´ ë¡œë“œ
    with open(os.path.join(model_dir, 'model_info.json'), 'r', encoding='utf-8') as f:
        model_info = json.load(f)
    
    id_to_label = {int(k): v for k, v in model_info['id_to_label'].items()}
    
    # ëª¨ë¸ ë¡œë“œ
    tokenizer = AutoTokenizer.from_pretrained(model_dir)
    model = AutoModelForSequenceClassification.from_pretrained(model_dir)
    model.eval()
    
    # ì˜ˆì¸¡
    inputs = tokenizer(text, return_tensors="pt", truncation=True, max_length=192)
    
    with torch.no_grad():
        outputs = model(**inputs)
        probabilities = torch.softmax(outputs.logits, dim=-1).squeeze().numpy()
        predicted_id = np.argmax(probabilities)
        max_prob = np.max(probabilities)
    
    # ë³´ë¥˜ íŒë‹¨
    if max_prob < reject_threshold:
        predicted_label = "ë³´ë¥˜"
        confidence = max_prob
        all_probs = {id_to_label[i]: float(prob) for i, prob in enumerate(probabilities)}
    else:
        predicted_label = id_to_label[predicted_id]
        confidence = max_prob
        all_probs = {id_to_label[i]: float(prob) for i, prob in enumerate(probabilities)}
    
    return {
        'text': text,
        'predicted_label': predicted_label,
        'confidence': float(confidence),
        'all_probabilities': all_probs,
        'rejected': max_prob < reject_threshold,
        'reject_threshold': reject_threshold
    }

def batch_predict(csv_path: str, model_dir: str, reject_threshold: float = 0.45) -> str:
    """ë°°ì¹˜ ì˜ˆì¸¡ (CSV ì…ë ¥/ì¶œë ¥)"""
    
    # ì…ë ¥ CSV ë¡œë“œ
    df = pd.read_csv(csv_path)
    if 'text' not in df.columns:
        raise ValueError("CSV íŒŒì¼ì— 'text' ì»¬ëŸ¼ì´ í•„ìš”í•©ë‹ˆë‹¤.")
    
    results = []
    for _, row in df.iterrows():
        result = predict_with_model(row['text'], model_dir, reject_threshold)
        results.append(result)
    
    # ê²°ê³¼ DataFrame ìƒì„±
    result_df = pd.DataFrame([
        {
            'text': r['text'],
            'predicted_label': r['predicted_label'],
            'confidence': r['confidence'],
            'rejected': r['rejected']
        }
        for r in results
    ])
    
    # ì¶œë ¥ íŒŒì¼ëª… ìƒì„±
    output_path = csv_path.replace('.csv', '_predictions.csv')
    result_df.to_csv(output_path, index=False, encoding='utf-8')
    
    print(f"âœ… ë°°ì¹˜ ì˜ˆì¸¡ ì™„ë£Œ: {output_path}")
    print(f"   ì „ì²´: {len(result_df)}ê°œ")
    print(f"   ë³´ë¥˜: {result_df['rejected'].sum()}ê°œ ({result_df['rejected'].mean():.1%})")
    
    return output_path

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    parser = argparse.ArgumentParser(description='KB Reflex íˆ¬ì ì‹¬ë¦¬ ë¶„ì„ ëª¨ë¸ (ì‹œì—°ìš©)')
    
    # ê¸°ë³¸ ì˜µì…˜
    parser.add_argument('--model_name', type=str, default='beomi/KcELECTRA-base',
                       help='ì‚¬ìš©í•  ë°±ë³¸ ëª¨ë¸ (ê¸°ë³¸: beomi/KcELECTRA-base)')
    parser.add_argument('--output_dir', type=str, default='./sentiment_model',
                       help='ëª¨ë¸ ì €ì¥ ë””ë ‰í† ë¦¬')
    
    # í›ˆë ¨ ì˜µì…˜
    parser.add_argument('--train_4cls', action='store_true',
                       help='4í´ë˜ìŠ¤ ëª¨ë¸ë„ í•¨ê»˜ í›ˆë ¨')
    parser.add_argument('--loss_type', type=str, default='weighted_ce',
                       choices=['weighted_ce', 'focal', 'cbloss'],
                       help='ì†ì‹¤ í•¨ìˆ˜ íƒ€ì…')
    parser.add_argument('--augment_ratio', type=float, default=1.2,
                       help='ë°ì´í„° ì¦ê°• ë¹„ìœ¨ (ìµœëŒ€ 1.4 ê¶Œì¥)')
    parser.add_argument('--minority_only', action='store_true', default=True,
                       help='ì†Œìˆ˜ í´ë˜ìŠ¤ë§Œ ì¦ê°•')
    parser.add_argument('--demo_csv', type=str, default=None,
                       help='ì‹œì—° í›„ë³´ ë¬¸ì¥ CSV íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--reject_threshold', type=float, default=0.45,
                       help='ë¶ˆí™•ì‹¤ì„± ê±°ë¶€ ì„ê³„ê°’ (ê¸°ë³¸: 0.45)')
    
    # ì¶”ë¡  ì˜µì…˜
    parser.add_argument('--predict', type=str, default=None,
                       help='ë‹¨ì¼ í…ìŠ¤íŠ¸ ì˜ˆì¸¡')
    parser.add_argument('--batch_predict', type=str, default=None,
                       help='ë°°ì¹˜ ì˜ˆì¸¡ CSV íŒŒì¼ ê²½ë¡œ')
    parser.add_argument('--model_path', type=str, default=None,
                       help='ì¶”ë¡ ì— ì‚¬ìš©í•  ëª¨ë¸ ê²½ë¡œ')
    
    args = parser.parse_args()
    
    # ì‹œë“œ ê³ ì •
    torch.manual_seed(RANDOM_SEED)
    np.random.seed(RANDOM_SEED)
    random.seed(RANDOM_SEED)
    
    # ì¶”ë¡  ëª¨ë“œ
    if args.predict or args.batch_predict:
        if not args.model_path:
            model_path = os.path.join(args.output_dir, '4cls')  # ê¸°ë³¸ì ìœ¼ë¡œ 4í´ë˜ìŠ¤ ëª¨ë¸ ì‚¬ìš©
            if not os.path.exists(model_path):
                model_path = os.path.join(args.output_dir, '7cls')
        else:
            model_path = args.model_path
        
        if not os.path.exists(model_path):
            print(f"âŒ ëª¨ë¸ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤: {model_path}")
            return
        
        if args.predict:
            result = predict_with_model(args.predict, model_path, args.reject_threshold)
            print(f"\nğŸ¯ ì˜ˆì¸¡ ê²°ê³¼:")
            print(f"   í…ìŠ¤íŠ¸: {result['text']}")
            print(f"   ì˜ˆì¸¡: {result['predicted_label']}")
            print(f"   ì‹ ë¢°ë„: {result['confidence']:.3f}")
            print(f"   ë³´ë¥˜ ì—¬ë¶€: {result['rejected']}")
            if not result['rejected']:
                print(f"   ì „ì²´ í™•ë¥ :")
                for label, prob in sorted(result['all_probabilities'].items(), 
                                        key=lambda x: x[1], reverse=True):
                    print(f"     {label}: {prob:.3f}")
        
        if args.batch_predict:
            output_path = batch_predict(args.batch_predict, model_path, args.reject_threshold)
            print(f"âœ… ë°°ì¹˜ ì˜ˆì¸¡ ê²°ê³¼: {output_path}")
        
        return
    
    # í›ˆë ¨ ëª¨ë“œ
    print("ğŸš€ KB Reflex íˆ¬ì ì‹¬ë¦¬ ë¶„ì„ ëª¨ë¸ í›ˆë ¨ ì‹œì‘ (ì‹œì—°ìš© ê³ ë„í™” ë²„ì „)")
    print("=" * 80)
    print(f"âš™ï¸ ì„¤ì •:")
    print(f"   ëª¨ë¸: {args.model_name}")
    print(f"   ì†ì‹¤í•¨ìˆ˜: {args.loss_type}")
    print(f"   ì¦ê°•ë¹„ìœ¨: {args.augment_ratio}")
    print(f"   ì‹œì—°CSV: {args.demo_csv}")
    print(f"   ê±°ë¶€ì„ê³„ê°’: {args.reject_threshold}")
    print(f"   4í´ë˜ìŠ¤ í›ˆë ¨: {args.train_4cls}")
    print("=" * 80)
    
    try:
        # 1. ë°ì´í„° ë¡œë“œ
        print("\nğŸ“Š ë°ì´í„° ë¡œë“œ ì¤‘...")
        df = load_data_from_central_manager()
        
        # í•„ìˆ˜ ì»¬ëŸ¼ í™•ì¸
        required_columns = ['ë©”ëª¨', 'ê°ì •íƒœê·¸']
        missing_columns = [col for col in required_columns if col not in df.columns]
        if missing_columns:
            raise ValueError(f"í•„ìˆ˜ ì»¬ëŸ¼ì´ ì—†ìŠµë‹ˆë‹¤: {missing_columns}")
        
        # username ì»¬ëŸ¼ì´ ì—†ìœ¼ë©´ ìƒì„±
        if 'username' not in df.columns:
            df['username'] = 'user_' + (df.index // 10 + 1).astype(str)  # 10ê°œì”© ë¬¶ì–´ì„œ ì‚¬ìš©ì í• ë‹¹
            print("âš ï¸ username ì»¬ëŸ¼ì´ ì—†ì–´ì„œ ìë™ ìƒì„±í–ˆìŠµë‹ˆë‹¤.")
        
        # ë°ì´í„° ì •ì œ
        initial_len = len(df)
        df = df.dropna(subset=['ë©”ëª¨', 'ê°ì •íƒœê·¸'])
        df = df[df['ë©”ëª¨'].str.strip() != '']
        df = df[df['ê°ì •íƒœê·¸'].str.strip() != '']
        df['ê°ì •íƒœê·¸'] = df['ê°ì •íƒœê·¸'].str.replace('#', '', regex=False)
        
        print(f"ğŸ“Š ë°ì´í„° ì •ì œ ì™„ë£Œ: {initial_len} â†’ {len(df)}ê°œ")
        
        # 7í´ë˜ìŠ¤ ë¶„í¬ í™•ì¸
        print(f"ğŸ·ï¸ 7í´ë˜ìŠ¤ ë¶„í¬:")
        for emotion, count in df['ê°ì •íƒœê·¸'].value_counts().items():
            print(f"   {emotion}: {count}ê°œ")
        
        # 4í´ë˜ìŠ¤ ë§¤í•‘
        df = create_7_to_4_mapping(df)
        print(f"ğŸ·ï¸ 4í´ë˜ìŠ¤ ë¶„í¬:")
        for emotion, count in df['ê°ì •íƒœê·¸_4cls'].value_counts().items():
            print(f"   {emotion}: {count}ê°œ")
        
        # 2. 7í´ë˜ìŠ¤ OOF í‰ê°€
        print(f"\nğŸ”„ 7í´ë˜ìŠ¤ GroupKFold OOF í‰ê°€...")
        oof_7cls = create_oof_predictions(
            df, class_type='7cls',
            model_name=args.model_name,
            loss_type=args.loss_type,
            augment_ratio=args.augment_ratio,
            minority_only=args.minority_only,
            demo_csv=args.demo_csv
        )
        
        # 7í´ë˜ìŠ¤ ì‹œê°í™”
        output_7cls = os.path.join(args.output_dir, '7cls')
        create_visualizations(oof_7cls, output_7cls, '7cls', args.reject_threshold)
        
        # 3. 4í´ë˜ìŠ¤ ëª¨ë¸ í›ˆë ¨ (ì„ íƒì‚¬í•­)
        if args.train_4cls:
            print(f"\nğŸ¯ 4í´ë˜ìŠ¤ ì‹œì—°ìš© ëª¨ë¸ í›ˆë ¨...")
            
            # OOF í‰ê°€
            oof_4cls = create_oof_predictions(
                df, class_type='4cls',
                model_name=args.model_name,
                loss_type=args.loss_type,
                augment_ratio=args.augment_ratio,
                minority_only=args.minority_only,
                demo_csv=args.demo_csv
            )
            
            # Holdout ëª¨ë¸ ìƒì„± (ì‹¤ì œ ë°°í¬ìš©)
            holdout_4cls = create_holdout_model(
                df, class_type='4cls',
                model_name=args.model_name,
                loss_type=args.loss_type,
                augment_ratio=args.augment_ratio,
                minority_only=args.minority_only,
                demo_csv=args.demo_csv,
                output_dir=args.output_dir
            )
            
            # 4í´ë˜ìŠ¤ ì‹œê°í™” (OOF ê¸°ì¤€)
            output_4cls = os.path.join(args.output_dir, '4cls')
            create_visualizations(oof_4cls, output_4cls, '4cls_oof', args.reject_threshold)
            
            # Holdout ì‹œê°í™”
            create_visualizations(holdout_4cls, output_4cls, '4cls_holdout', args.reject_threshold)
        
        # 4. ìµœì¢… ë¦¬í¬íŠ¸
        print(f"\nğŸ‰ í›ˆë ¨ ì™„ë£Œ!")
        print("=" * 80)
        print(f"ğŸ“ˆ 7í´ë˜ìŠ¤ OOF ì„±ëŠ¥:")
        print(f"   ì •í™•ë„: {oof_7cls['overall_scores']['accuracy']:.4f}")
        print(f"   F1 Macro: {oof_7cls['overall_scores']['f1_macro']:.4f}")
        print(f"   F1 Weighted: {oof_7cls['overall_scores']['f1_weighted']:.4f}")
        
        if args.train_4cls:
            print(f"ğŸ“ˆ 4í´ë˜ìŠ¤ OOF ì„±ëŠ¥:")
            print(f"   ì •í™•ë„: {oof_4cls['overall_scores']['accuracy']:.4f}")
            print(f"   F1 Macro: {oof_4cls['overall_scores']['f1_macro']:.4f}")
            print(f"   F1 Weighted: {oof_4cls['overall_scores']['f1_weighted']:.4f}")
            
            print(f"ğŸ“ˆ 4í´ë˜ìŠ¤ Holdout ì„±ëŠ¥:")
            print(f"   ì •í™•ë„: {holdout_4cls['performance']['accuracy']:.4f}")
            print(f"   F1 Macro: {holdout_4cls['performance']['f1_macro']:.4f}")
            print(f"   F1 Weighted: {holdout_4cls['performance']['f1_weighted']:.4f}")
        
        print(f"\nğŸ“ ì €ì¥ ìœ„ì¹˜:")
        print(f"   7í´ë˜ìŠ¤: {output_7cls}")
        if args.train_4cls:
            print(f"   4í´ë˜ìŠ¤: {output_4cls}")
        
        print(f"\nğŸ§ª ëª¨ë¸ í…ŒìŠ¤íŠ¸:")
        if args.train_4cls:
            test_texts = [
                "ì½”ìŠ¤í”¼ê°€ ë„ˆë¬´ ë–¨ì–´ì ¸ì„œ ë¬´ì„œì›Œì„œ ì „ëŸ‰ ë§¤ë„í–ˆì–´ìš”",
                "ê¸°ìˆ ì  ë¶„ì„ ê²°ê³¼ ì ì • ë§¤ìˆ˜ íƒ€ì´ë°ìœ¼ë¡œ íŒë‹¨ë¨",
                "ëª¨ë“  ì‚¬ëŒë“¤ì´ ì‚¬ë¼ê³  í•´ì„œ ë”°ë¼ì„œ ì¶”ê°€ ë§¤ìˆ˜í–ˆì–´ìš”"
            ]
            
            for text in test_texts:
                result = predict_with_model(text, holdout_4cls['output_dir'], args.reject_threshold)
                print(f"ğŸ“ '{text[:30]}...'")
                print(f"ğŸ¯ ì˜ˆì¸¡: {result['predicted_label']} (ì‹ ë¢°ë„: {result['confidence']:.3f})")
        
        print("=" * 80)
        print("âœ… ëª¨ë“  ê³¼ì •ì´ ì„±ê³µì ìœ¼ë¡œ ì™„ë£Œë˜ì—ˆìŠµë‹ˆë‹¤!")
        
    except Exception as e:
        print(f"âŒ ì˜¤ë¥˜ ë°œìƒ: {str(e)}")
        import traceback
        traceback.print_exc()
        raise

if __name__ == "__main__":
    main()