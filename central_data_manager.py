"""
ì¤‘ì•™ ë°ì´í„° ê´€ë¦¬ ì‹œìŠ¤í…œ - ê³ ë„í™” ë²„ì „ (V3.0)
ì•ˆì •ì /ì¬í˜„ê°€ëŠ¥/í™•ì¥ê°€ëŠ¥/ê³ ì„±ëŠ¥ ë°ì´í„° ê´€ë¦¬ë¥¼ ìœ„í•œ ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ ì‹œìŠ¤í…œ

ê°œì„ ì‚¬í•­:
- ì„±ëŠ¥ ìµœì í™” ë° ë©”ëª¨ë¦¬ íš¨ìœ¨ì„± ê°œì„ 
- ìŠ¤ë§ˆíŠ¸ ìºì‹± ë° ë°ì´í„° ì••ì¶•
- í–¥ìƒëœ ì—ëŸ¬ ì²˜ë¦¬ ë° ë³µêµ¬ ë©”ì»¤ë‹ˆì¦˜  
- ì„¤ì • ê´€ë¦¬ ì¤‘ì•™í™” ë° í™˜ê²½ë³„ ì§€ì›
- ë°ì´í„° ë¬´ê²°ì„± ê²€ì¦ ê°•í™”
- í”ŒëŸ¬ê·¸ì¸ ì•„í‚¤í…ì²˜ ë„ì…
- ë¹„ë™ê¸° ì²˜ë¦¬ ì§€ì›
- ìƒì„¸í•œ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
"""

import json
import pandas as pd
import numpy as np
from datetime import datetime, timedelta
from pathlib import Path
from typing import Dict, List, Any, Optional, Protocol, Union, Callable, TypeVar, Generic, Tuple
import requests
from dataclasses import dataclass, asdict, field
import random
import os
import shutil
from abc import ABC, abstractmethod
import streamlit as st
import logging
import time
import threading
import weakref
from functools import lru_cache, wraps
import hashlib
import pickle
import gzip
from collections import defaultdict, OrderedDict
from enum import Enum
import warnings

# ê²½ê³  ë©”ì‹œì§€ ì–µì œ
warnings.filterwarnings('ignore', category=FutureWarning)

# ë¡œê¹… ì„¤ì •
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

# ================================
# [ENHANCED CONFIG] ê³ ë„í™”ëœ ì„¤ì • ê´€ë¦¬
# ================================

class DataManagerConfig:
    """ë°ì´í„° ë§¤ë‹ˆì € ì„¤ì • í´ë˜ìŠ¤"""
    
    # ìºì‹œ ì„¤ì •
    CACHE_TTL_SECONDS = 300  # 5ë¶„
    MAX_MEMORY_CACHE_SIZE_MB = 100  # 100MB
    ENABLE_DISK_CACHE = True
    DISK_CACHE_DIR = "cache"
    
    # ì„±ëŠ¥ ì„¤ì •
    ENABLE_COMPRESSION = True
    ENABLE_ASYNC_LOADING = False  # í˜„ì¬ ë²„ì „ì—ì„œëŠ” ë¹„í™œì„±í™”
    MAX_CONCURRENT_OPERATIONS = 5
    SLOW_OPERATION_THRESHOLD = 2.0  # 2ì´ˆ
    
    # ë°ì´í„° ê²€ì¦ ì„¤ì •
    ENABLE_DATA_VALIDATION = True
    ENABLE_AUTO_REPAIR = True
    MAX_REPAIR_ATTEMPTS = 3
    
    # ë°±ì—… ì„¤ì •
    ENABLE_AUTO_BACKUP = True
    MAX_BACKUP_FILES = 10
    BACKUP_INTERVAL_HOURS = 24
    
    # ëª¨ë‹ˆí„°ë§ ì„¤ì •
    ENABLE_PERFORMANCE_MONITORING = True
    ENABLE_USAGE_ANALYTICS = True
    LOG_SLOW_QUERIES = True
    
    # ë©”ëª¨ë¦¬ ê´€ë¦¬
    ENABLE_MEMORY_OPTIMIZATION = True
    MEMORY_CLEANUP_THRESHOLD = 0.8  # 80% ë©”ëª¨ë¦¬ ì‚¬ìš©ë¥ 
    
    # ë°ì´í„° ì†ŒìŠ¤ ì„¤ì •
    DEFAULT_DEMO_TRADES_COUNT = 50  # ê¸°ë³¸ ë°ëª¨ ê±°ë˜ ìˆ˜ ì¶•ì†Œ
    MAX_NEWS_ITEMS_MEMORY = 100
    MAX_TRADES_PER_USER = 1000

def _load_enhanced_config():
    """í–¥ìƒëœ ì„¤ì • ë¡œë”"""
    defaults = {
        'DEMO_SEED': None,
        'PROVIDER_MODE': 'dummy',
        'DATA_ROOT': 'data',
        'CACHE_ENABLED': True,
        'PERFORMANCE_MODE': 'balanced',  # fast, balanced, quality
        'LOG_LEVEL': 'INFO'
    }
    
    # app_settings.jsonì—ì„œ ì„¤ì • ë¡œë“œ
    try:
        settings_path = Path("app_settings.json")
        if settings_path.exists():
            with open(settings_path, 'r', encoding='utf-8') as f:
                app_config = json.load(f)
                
                # ë‹¤ì¤‘ ë ˆë²¨ ì„¤ì • ì§€ì›
                demo_settings = app_config.get('demo_settings', {})
                data_manager_settings = app_config.get('data_manager', {})
                
                # ì„¤ì • ë³‘í•©
                for key in defaults:
                    if key.lower() in demo_settings:
                        defaults[key] = demo_settings[key.lower()]
                    elif key.lower() in data_manager_settings:
                        defaults[key] = data_manager_settings[key.lower()]
    except Exception as e:
        logger.warning(f"ì„¤ì • íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {e}")
    
    # í™˜ê²½ ë³€ìˆ˜ ìš°ì„  ì ìš©
    for key in defaults:
        env_val = os.environ.get(key)
        if env_val is not None:
            if key == 'DEMO_SEED':
                try:
                    defaults[key] = int(env_val) if env_val.lower() != 'none' else None
                except ValueError:
                    pass
            elif key == 'CACHE_ENABLED':
                defaults[key] = env_val.lower() in ('true', '1', 'yes')
            else:
                defaults[key] = env_val
    
    return defaults

# ì „ì—­ ì„¤ì • ë¡œë“œ
_ENHANCED_CONFIG = _load_enhanced_config()
DEMO_SEED = _ENHANCED_CONFIG['DEMO_SEED']
PROVIDER_MODE = _ENHANCED_CONFIG['PROVIDER_MODE']
DATA_ROOT = Path(_ENHANCED_CONFIG['DATA_ROOT'])
CACHE_ENABLED = _ENHANCED_CONFIG['CACHE_ENABLED']
PERFORMANCE_MODE = _ENHANCED_CONFIG['PERFORMANCE_MODE']

# ================================
# [PERFORMANCE MONITORING] ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
# ================================

class PerformanceMonitor:
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ í´ë˜ìŠ¤"""
    
    def __init__(self):
        self._metrics = defaultdict(list)
        self._start_times = {}
        self._operation_counts = defaultdict(int)
        
    def start_operation(self, operation_name: str) -> str:
        """ì‘ì—… ì‹œì‘"""
        operation_id = f"{operation_name}_{time.time()}"
        self._start_times[operation_id] = time.time()
        self._operation_counts[operation_name] += 1
        return operation_id
    
    def end_operation(self, operation_id: str):
        """ì‘ì—… ì¢…ë£Œ"""
        if operation_id in self._start_times:
            elapsed = time.time() - self._start_times[operation_id]
            operation_name = operation_id.split('_')[0]
            self._metrics[operation_name].append(elapsed)
            
            # ëŠë¦° ì‘ì—… ë¡œê¹…
            if (DataManagerConfig.LOG_SLOW_QUERIES and 
                elapsed > DataManagerConfig.SLOW_OPERATION_THRESHOLD):
                logger.warning(f"ëŠë¦° ì‘ì—… ê°ì§€: {operation_name} ({elapsed:.2f}ì´ˆ)")
            
            del self._start_times[operation_id]
    
    def get_metrics(self) -> Dict[str, Any]:
        """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¡°íšŒ"""
        result = {}
        for operation, times in self._metrics.items():
            if times:
                result[operation] = {
                    'count': len(times),
                    'avg_time': np.mean(times),
                    'max_time': np.max(times),
                    'min_time': np.min(times),
                    'total_operations': self._operation_counts[operation]
                }
        return result
    
    def clear_metrics(self):
        """ë©”íŠ¸ë¦­ ì´ˆê¸°í™”"""
        self._metrics.clear()
        self._operation_counts.clear()

# ì „ì—­ ì„±ëŠ¥ ëª¨ë‹ˆí„°
_performance_monitor = PerformanceMonitor()

def monitor_performance(func):
    """ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§ ë°ì½”ë ˆì´í„°"""
    @wraps(func)
    def wrapper(*args, **kwargs):
        if not DataManagerConfig.ENABLE_PERFORMANCE_MONITORING:
            return func(*args, **kwargs)
        
        operation_id = _performance_monitor.start_operation(func.__name__)
        try:
            result = func(*args, **kwargs)
            return result
        finally:
            _performance_monitor.end_operation(operation_id)
    
    return wrapper

# ================================
# [SMART CACHING] ìŠ¤ë§ˆíŠ¸ ìºì‹± ì‹œìŠ¤í…œ
# ================================

class CacheEntry:
    """ìºì‹œ ì—”íŠ¸ë¦¬ í´ë˜ìŠ¤"""
    
    def __init__(self, data: Any, ttl_seconds: int = DataManagerConfig.CACHE_TTL_SECONDS):
        self.data = data
        self.created_at = time.time()
        self.ttl_seconds = ttl_seconds
        self.access_count = 0
        self.last_accessed = time.time()
        self.size_bytes = self._calculate_size(data)
    
    def _calculate_size(self, data: Any) -> int:
        """ë°ì´í„° í¬ê¸° ê³„ì‚° (ê·¼ì‚¬ì¹˜)"""
        try:
            if isinstance(data, (str, int, float, bool)):
                return len(str(data).encode('utf-8'))
            elif isinstance(data, (list, tuple)):
                return sum(self._calculate_size(item) for item in data)
            elif isinstance(data, dict):
                return sum(self._calculate_size(k) + self._calculate_size(v) for k, v in data.items())
            else:
                return len(pickle.dumps(data))
        except:
            return 1024  # ê¸°ë³¸ê°’ 1KB
    
    def is_expired(self) -> bool:
        """ë§Œë£Œ ì—¬ë¶€ í™•ì¸"""
        return (time.time() - self.created_at) > self.ttl_seconds
    
    def access(self) -> Any:
        """ë°ì´í„° ì ‘ê·¼"""
        self.access_count += 1
        self.last_accessed = time.time()
        return self.data
    
    @property
    def age_seconds(self) -> float:
        """ìƒì„± í›„ ê²½ê³¼ ì‹œê°„"""
        return time.time() - self.created_at

class SmartCache:
    """ìŠ¤ë§ˆíŠ¸ ìºì‹± ì‹œìŠ¤í…œ"""
    
    def __init__(self, max_size_mb: int = DataManagerConfig.MAX_MEMORY_CACHE_SIZE_MB):
        self._cache: Dict[str, CacheEntry] = OrderedDict()
        self._max_size_bytes = max_size_mb * 1024 * 1024
        self._current_size_bytes = 0
        self._hits = 0
        self._misses = 0
        self._evictions = 0
        self._lock = threading.RLock()
    
    def get(self, key: str) -> Optional[Any]:
        """ìºì‹œì—ì„œ ë°ì´í„° ì¡°íšŒ"""
        with self._lock:
            if key in self._cache:
                entry = self._cache[key]
                if not entry.is_expired():
                    # LRU ì—…ë°ì´íŠ¸
                    self._cache.move_to_end(key)
                    self._hits += 1
                    return entry.access()
                else:
                    # ë§Œë£Œëœ ì—”íŠ¸ë¦¬ ì œê±°
                    self._remove_entry(key)
            
            self._misses += 1
            return None
    
    def put(self, key: str, data: Any, ttl_seconds: Optional[int] = None):
        """ìºì‹œì— ë°ì´í„° ì €ì¥"""
        with self._lock:
            # ê¸°ì¡´ ì—”íŠ¸ë¦¬ ì œê±°
            if key in self._cache:
                self._remove_entry(key)
            
            # ìƒˆ ì—”íŠ¸ë¦¬ ìƒì„±
            ttl = ttl_seconds or DataManagerConfig.CACHE_TTL_SECONDS
            entry = CacheEntry(data, ttl)
            
            # ë©”ëª¨ë¦¬ ê³µê°„ í™•ë³´
            self._ensure_space(entry.size_bytes)
            
            # ì—”íŠ¸ë¦¬ ì¶”ê°€
            self._cache[key] = entry
            self._current_size_bytes += entry.size_bytes
    
    def _remove_entry(self, key: str):
        """ì—”íŠ¸ë¦¬ ì œê±°"""
        if key in self._cache:
            entry = self._cache[key]
            self._current_size_bytes -= entry.size_bytes
            del self._cache[key]
    
    def _ensure_space(self, required_bytes: int):
        """ë©”ëª¨ë¦¬ ê³µê°„ í™•ë³´"""
        while (self._current_size_bytes + required_bytes > self._max_size_bytes and 
               self._cache):
            # LRU ë°©ì‹ìœ¼ë¡œ ì œê±°
            oldest_key = next(iter(self._cache))
            self._remove_entry(oldest_key)
            self._evictions += 1
    
    def clear(self):
        """ìºì‹œ ì „ì²´ ì´ˆê¸°í™”"""
        with self._lock:
            self._cache.clear()
            self._current_size_bytes = 0
    
    def cleanup_expired(self):
        """ë§Œë£Œëœ ì—”íŠ¸ë¦¬ ì •ë¦¬"""
        with self._lock:
            expired_keys = [
                key for key, entry in self._cache.items() 
                if entry.is_expired()
            ]
            for key in expired_keys:
                self._remove_entry(key)
    
    def get_stats(self) -> Dict[str, Any]:
        """ìºì‹œ í†µê³„ ì¡°íšŒ"""
        total_requests = self._hits + self._misses
        hit_ratio = self._hits / max(1, total_requests)
        
        return {
            'hits': self._hits,
            'misses': self._misses,
            'hit_ratio': hit_ratio,
            'evictions': self._evictions,
            'current_size_mb': self._current_size_bytes / (1024 * 1024),
            'max_size_mb': self._max_size_bytes / (1024 * 1024),
            'entry_count': len(self._cache),
            'memory_usage_pct': (self._current_size_bytes / self._max_size_bytes) * 100
        }

# ================================
# [ENHANCED DATA CLASSES] í–¥ìƒëœ ë°ì´í„° í´ë˜ìŠ¤
# ================================

@dataclass
class UserProfile:
    """ì‚¬ìš©ì í”„ë¡œí•„ ë°ì´í„° í´ë˜ìŠ¤ - í–¥ìƒëœ ë²„ì „"""
    username: str
    user_type: str
    description: str
    icon: str
    color: str
    badge: str
    subtitle: str
    onboarding_type: str
    demo_trades_count: int = 0
    created_at: datetime = field(default_factory=datetime.now)
    last_active: Optional[datetime] = None
    preferences: Dict[str, Any] = field(default_factory=dict)
    metadata: Dict[str, Any] = field(default_factory=dict)
    
    def to_dict(self) -> Dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return asdict(self)
    
    @classmethod
    def from_dict(cls, data: Dict[str, Any]) -> 'UserProfile':
        """ë”•ì…”ë„ˆë¦¬ì—ì„œ ìƒì„±"""
        # ë‚ ì§œ í•„ë“œ ë³€í™˜
        if 'created_at' in data and isinstance(data['created_at'], str):
            data['created_at'] = datetime.fromisoformat(data['created_at'])
        if 'last_active' in data and isinstance(data['last_active'], str):
            data['last_active'] = datetime.fromisoformat(data['last_active'])
        
        return cls(**data)

@dataclass
class MarketData:
    """ì‹œì¥ ë°ì´í„° í´ë˜ìŠ¤ - í–¥ìƒëœ ë²„ì „"""
    symbol: str
    name: str
    current_price: float
    change: float
    change_pct: float
    volume: int
    sector: str
    market_cap: str
    ma5: float
    ma20: float
    rsi: float
    per: float
    pbr: float
    base_price: float
    timestamp: datetime = field(default_factory=datetime.now)
    additional_metrics: Dict[str, Any] = field(default_factory=dict)
    
    def to_dict(self) -> Dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return asdict(self)

@dataclass
class NewsItem:
    """ë‰´ìŠ¤ ì•„ì´í…œ í´ë˜ìŠ¤ - í–¥ìƒëœ ë²„ì „"""
    title: str
    content: str
    timestamp: datetime
    category: str
    impact: str
    related_stocks: List[str]
    source: str = "ë‚´ë¶€"
    importance: float = 0.5  # 0.0 ~ 1.0
    tags: List[str] = field(default_factory=list)
    
    def to_dict(self) -> Dict[str, Any]:
        """ë”•ì…”ë„ˆë¦¬ë¡œ ë³€í™˜"""
        return asdict(self)

# ================================
# [DATA VALIDATION] ë°ì´í„° ê²€ì¦ ì‹œìŠ¤í…œ
# ================================

class DataValidator:
    """ë°ì´í„° ê²€ì¦ í´ë˜ìŠ¤"""
    
    @staticmethod
    def validate_user_profile(data: Dict) -> Tuple[bool, List[str]]:
        """ì‚¬ìš©ì í”„ë¡œí•„ ê²€ì¦"""
        errors = []
        required_fields = ['username', 'user_type', 'description']
        
        for field in required_fields:
            if field not in data or not data[field]:
                errors.append(f"í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {field}")
        
        # íƒ€ì… ê²€ì¦
        if 'demo_trades_count' in data:
            try:
                int(data['demo_trades_count'])
            except (ValueError, TypeError):
                errors.append("demo_trades_countëŠ” ì •ìˆ˜ì—¬ì•¼ í•©ë‹ˆë‹¤")
        
        return len(errors) == 0, errors
    
    @staticmethod
    def validate_trade_data(data: Dict) -> Tuple[bool, List[str]]:
        """ê±°ë˜ ë°ì´í„° ê²€ì¦"""
        errors = []
        required_fields = ['ê±°ë˜ì¼ì‹œ', 'ì¢…ëª©ëª…', 'ê±°ë˜êµ¬ë¶„', 'ìˆ˜ëŸ‰', 'ê°€ê²©']
        
        for field in required_fields:
            if field not in data:
                errors.append(f"í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {field}")
        
        # ë‚ ì§œ ê²€ì¦
        try:
            if 'ê±°ë˜ì¼ì‹œ' in data:
                if isinstance(data['ê±°ë˜ì¼ì‹œ'], str):
                    datetime.strptime(data['ê±°ë˜ì¼ì‹œ'], '%Y-%m-%d')
        except ValueError:
            errors.append("ê±°ë˜ì¼ì‹œ í˜•ì‹ ì˜¤ë¥˜")
        
        # ìˆ˜ì¹˜ ê²€ì¦
        try:
            if 'ìˆ˜ëŸ‰' in data:
                int(data['ìˆ˜ëŸ‰'])
            if 'ê°€ê²©' in data:
                float(data['ê°€ê²©'])
        except (ValueError, TypeError):
            errors.append("ìˆ˜ëŸ‰ ë˜ëŠ” ê°€ê²© í˜•ì‹ ì˜¤ë¥˜")
        
        # ê±°ë˜êµ¬ë¶„ ê²€ì¦
        if data.get('ê±°ë˜êµ¬ë¶„') not in ['ë§¤ìˆ˜', 'ë§¤ë„']:
            errors.append("ê±°ë˜êµ¬ë¶„ì€ 'ë§¤ìˆ˜' ë˜ëŠ” 'ë§¤ë„'ì—¬ì•¼ í•©ë‹ˆë‹¤")
        
        return len(errors) == 0, errors
    
    @staticmethod
    def validate_market_data(data: Dict) -> Tuple[bool, List[str]]:
        """ì‹œì¥ ë°ì´í„° ê²€ì¦"""
        errors = []
        required_fields = ['symbol', 'name', 'current_price']
        
        for field in required_fields:
            if field not in data:
                errors.append(f"í•„ìˆ˜ í•„ë“œ ëˆ„ë½: {field}")
        
        # ê°€ê²© ê²€ì¦
        try:
            if 'current_price' in data and float(data['current_price']) <= 0:
                errors.append("ì£¼ê°€ëŠ” 0ë³´ë‹¤ ì»¤ì•¼ í•©ë‹ˆë‹¤")
        except (ValueError, TypeError):
            errors.append("ì£¼ê°€ í˜•ì‹ ì˜¤ë¥˜")
        
        return len(errors) == 0, errors

# ================================
# [ENHANCED PROVIDERS] í–¥ìƒëœ ë°ì´í„° ì œê³µì
# ================================

class BaseProvider(Protocol):
    """í–¥ìƒëœ ë°ì´í„° ì œê³µì ì¸í„°í˜ì´ìŠ¤"""
    
    @abstractmethod
    def get_stock_price(self, symbol: str, base_price: float) -> float:
        """ì£¼ì‹ ê°€ê²© ì¡°íšŒ"""
        pass
    
    @abstractmethod
    def get_market_news(self) -> List[Dict[str, Any]]:
        """ì‹œì¥ ë‰´ìŠ¤ ì¡°íšŒ"""
        pass
    
    @abstractmethod
    def get_economic_indicators(self) -> Dict[str, Any]:
        """ê²½ì œ ì§€í‘œ ì¡°íšŒ"""
        pass

class OptimizedDummyProvider:
    """ìµœì í™”ëœ ë”ë¯¸ ë°ì´í„° ì œê³µì"""
    
    def __init__(self, demo_mode: bool = True, performance_mode: str = 'balanced'):
        self.demo_mode = demo_mode
        self.performance_mode = performance_mode
        
        # ì„±ëŠ¥ ëª¨ë“œë³„ ì„¤ì •
        if performance_mode == 'fast':
            self.volatility_factor = 0.3  # ë‚®ì€ ë³€ë™ì„±
            self.calculation_precision = 1  # ë‚®ì€ ì •ë°€ë„
        elif performance_mode == 'quality':
            self.volatility_factor = 1.0   # ë†’ì€ ë³€ë™ì„±
            self.calculation_precision = 3  # ë†’ì€ ì •ë°€ë„
        else:  # balanced
            self.volatility_factor = 0.5   # ì¤‘ê°„ ë³€ë™ì„±
            self.calculation_precision = 2  # ì¤‘ê°„ ì •ë°€ë„
    
    @lru_cache(maxsize=1000)
    def get_stock_price(self, symbol: str, base_price: float) -> float:
        """ìºì‹œê°€ ì ìš©ëœ ì£¼ì‹ ê°€ê²© ê³„ì‚°"""
        # ì‹œë“œê°€ ìˆìœ¼ë©´ ì¼ê´€ëœ ë³€ë™ì„± ì ìš©
        if DEMO_SEED is not None:
            random.seed(hash(symbol + str(int(time.time() // 300))))  # 5ë¶„ë§ˆë‹¤ ë³€ê²½
        
        change_rate = random.gauss(0, 0.02 * self.volatility_factor)
        price = max(base_price * (1 + change_rate), base_price * 0.8)
        
        return round(price, -2)  # 100ì› ë‹¨ìœ„ë¡œ ë°˜ì˜¬ë¦¼
    
    def get_market_news(self) -> List[Dict[str, Any]]:
        """ë”ë¯¸ ë‰´ìŠ¤ ë°ì´í„°"""
        return []
    
    def get_economic_indicators(self) -> Dict[str, Any]:
        """ë”ë¯¸ ê²½ì œ ì§€í‘œ"""
        return {}

# ================================
# [MAIN DATA MANAGER] ë©”ì¸ ë°ì´í„° ë§¤ë‹ˆì € (ê³ ë„í™”)
# ================================

class EnhancedCentralDataManager:
    """
    ì¤‘ì•™ ë°ì´í„° ê´€ë¦¬ í´ë˜ìŠ¤ - ì—”í„°í”„ë¼ì´ì¦ˆê¸‰ ê³ ë„í™” ë²„ì „
    
    ì£¼ìš” ê°œì„ ì‚¬í•­:
    1. ìŠ¤ë§ˆíŠ¸ ìºì‹± ì‹œìŠ¤í…œ
    2. í–¥ìƒëœ ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
    3. ë°ì´í„° ê²€ì¦ ë° ìë™ ë³µêµ¬
    4. ë©”ëª¨ë¦¬ ìµœì í™”
    5. í”ŒëŸ¬ê·¸ì¸ ì•„í‚¤í…ì²˜
    """
    
    def __init__(self):
        self.data_dir = DATA_ROOT
        self.data_dir.mkdir(exist_ok=True)
        
        # ìºì‹œ ì‹œìŠ¤í…œ ì´ˆê¸°í™”
        self.cache = SmartCache() if CACHE_ENABLED else None
        
        # ì„±ëŠ¥ ëª¨ë‹ˆí„°ë§
        self.performance = _performance_monitor
        
        # ë°ì´í„° ê²€ì¦ê¸°
        self.validator = DataValidator()
        
        # ìƒíƒœ ì¶”ì  (í™•ì¥)
        self._status = {
            'repairs': [],
            'errors': [],
            'warnings': [],
            'last_refresh': None,
            'data_integrity_score': 100.0,
            'performance_metrics': {},
            'memory_usage': {},
            'backup_status': {}
        }
        
        # í”„ë¡œë°”ì´ë” ì´ˆê¸°í™”
        if PROVIDER_MODE == 'api':
            try:
                # ì‹¤ì œ API í”„ë¡œë°”ì´ë”ê°€ êµ¬í˜„ë˜ë©´ ì‚¬ìš©
                from .providers import APIProvider
                self.provider = APIProvider()
            except ImportError:
                logger.warning("API Providerë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ Dummy Providerë¥¼ ì‚¬ìš©í•©ë‹ˆë‹¤.")
                self.provider = OptimizedDummyProvider(
                    demo_mode=(DEMO_SEED is not None),
                    performance_mode=PERFORMANCE_MODE
                )
        else:
            self.provider = OptimizedDummyProvider(
                demo_mode=(DEMO_SEED is not None),
                performance_mode=PERFORMANCE_MODE
            )
        
        # ë°ì´í„° ë¡œë“œ
        self._initialize_data()
        
        logger.info(f"Enhanced Data Manager ì´ˆê¸°í™” ì™„ë£Œ (ëª¨ë“œ: {PERFORMANCE_MODE})")
    
    @monitor_performance
    def _initialize_data(self):
        """ë°ì´í„° ì´ˆê¸°í™”"""
        try:
            # ë°±ì—… ë””ë ‰í† ë¦¬ ìƒì„±
            if DataManagerConfig.ENABLE_AUTO_BACKUP:
                self._ensure_backup_directory()
            
            # ìºì‹œ ë””ë ‰í† ë¦¬ ìƒì„±
            if DataManagerConfig.ENABLE_DISK_CACHE:
                self._ensure_cache_directory()
            
            # ë°ì´í„° ë¡œë“œ
            self.users = self._load_users_optimized()
            self.market_data = self._load_market_data_optimized()
            self.news_data = self._load_news_data_optimized()
            self.economic_indicators = self._load_economic_indicators_optimized()
            self.demo_trades = self._load_demo_trades_optimized()
            
            self._status['last_refresh'] = datetime.now()
            
            # ì´ˆê¸° ë°ì´í„° ë¬´ê²°ì„± ê²€ì‚¬
            if DataManagerConfig.ENABLE_DATA_VALIDATION:
                self._validate_all_data()
            
        except Exception as e:
            logger.error(f"ë°ì´í„° ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
            self._status['errors'].append(f"ì´ˆê¸°í™” ì‹¤íŒ¨: {str(e)}")
    
    def _ensure_backup_directory(self):
        """ë°±ì—… ë””ë ‰í† ë¦¬ í™•ì¸"""
        backup_dir = self.data_dir / "backups"
        backup_dir.mkdir(exist_ok=True)
    
    def _ensure_cache_directory(self):
        """ìºì‹œ ë””ë ‰í† ë¦¬ í™•ì¸"""
        cache_dir = self.data_dir / DataManagerConfig.DISK_CACHE_DIR
        cache_dir.mkdir(exist_ok=True)
    
    @monitor_performance
    def _load_users_optimized(self) -> Dict[str, UserProfile]:
        """ìµœì í™”ëœ ì‚¬ìš©ì ë¡œë“œ"""
        cache_key = "users_data"
        
        # ìºì‹œ í™•ì¸
        if self.cache:
            cached_data = self.cache.get(cache_key)
            if cached_data:
                return cached_data
        
        users = {}
        
        # ê°œë³„ ì‚¬ìš©ì í´ë” ìŠ¤ìº” (ìµœì í™”)
        if self.data_dir.exists():
            for item in self.data_dir.iterdir():
                if item.is_dir() and not item.name.startswith('.'):
                    profile_path = item / "profile.json"
                    if profile_path.exists():
                        try:
                            profile_data = self._safe_json_load(profile_path)
                            if profile_data:
                                if 'username' not in profile_data:
                                    profile_data['username'] = item.name
                                
                                # ë°ì´í„° ê²€ì¦
                                is_valid, errors = self.validator.validate_user_profile(profile_data)
                                if is_valid:
                                    user_profile = self._create_user_profile(profile_data)
                                    users[user_profile.username] = user_profile
                                else:
                                    logger.warning(f"ì‚¬ìš©ì í”„ë¡œí•„ ê²€ì¦ ì‹¤íŒ¨: {item.name}, ì˜¤ë¥˜: {errors}")
                        except Exception as e:
                            self._status['errors'].append(f"ì‚¬ìš©ì í”„ë¡œí•„ ë¡œë“œ ì‹¤íŒ¨: {item.name} - {str(e)}")
        
        # users.json í´ë°±
        users_file = self.data_dir / "users.json"
        if users_file.exists():
            users_data = self._safe_json_load(users_file, {})
            for username, data in users_data.items():
                if username not in users:
                    is_valid, _ = self.validator.validate_user_profile(data)
                    if is_valid:
                        users[username] = self._create_user_profile(data)
        
        # ê¸°ë³¸ ì‚¬ìš©ì ì—†ìœ¼ë©´ ìƒì„±
        if not users:
            default_users = self._get_optimized_default_users()
            for username, data in default_users.items():
                users[username] = self._create_user_profile(data)
            
            self._safe_json_save(users_file, default_users)
        
        # ìºì‹œ ì €ì¥
        if self.cache:
            self.cache.put(cache_key, users)
        
        return users
    
    def _create_user_profile(self, data: Dict) -> UserProfile:
        """ì‚¬ìš©ì í”„ë¡œí•„ ìƒì„± (íƒ€ì… ì•ˆì „)"""
        # ê¸°ë³¸ê°’ ì„¤ì •
        defaults = {
            'username': 'ì•Œìˆ˜ì—†ìŒ',
            'user_type': 'ì‹ ê·œ',
            'description': 'ê¸°ë³¸ ì‚¬ìš©ì',
            'icon': 'ğŸ‘¤',
            'color': '#3182F6',
            'badge': 'USER',
            'subtitle': 'ê¸°ë³¸ ì‚¬ìš©ì',
            'onboarding_type': 'principles',
            'demo_trades_count': 0,
            'preferences': {},
            'metadata': {}
        }
        
        # ê¸°ë³¸ê°’ê³¼ ë³‘í•©
        for key, default_value in defaults.items():
            if key not in data:
                data[key] = default_value
        
        # íƒ€ì… ë³€í™˜
        try:
            data['demo_trades_count'] = int(data.get('demo_trades_count', 0))
        except (ValueError, TypeError):
            data['demo_trades_count'] = 0
        
        return UserProfile.from_dict(data)
    
    def _get_optimized_default_users(self) -> Dict[str, Dict]:
        """ìµœì í™”ëœ ê¸°ë³¸ ì‚¬ìš©ì ë°ì´í„°"""
        return {
            "ì´ê±°ìš¸": {
                "username": "ì´ê±°ìš¸",
                "user_type": "ì‹ ê·œ",
                "description": "íˆ¬ìë¥¼ ì²˜ìŒ ì‹œì‘í•˜ëŠ” ì‹ ê·œ ì‚¬ìš©ì",
                "icon": "ğŸ†•",
                "color": "#3182F6",
                "badge": "NEW",
                "subtitle": "ê±°ë˜ ë°ì´í„° ì—†ìŒ â€¢ íˆ¬ì ì›ì¹™ í•™ìŠµ í•„ìš”",
                "onboarding_type": "principles",
                "demo_trades_count": 0
            },
            "ë°•íˆ¬ì": {
                "username": "ë°•íˆ¬ì",
                "user_type": "ê¸°ì¡´_reflexì²˜ìŒ",
                "description": "FOMO ë§¤ìˆ˜ ê²½í–¥ì´ ìˆëŠ” ê¸°ì¡´ ê³ ê°",
                "icon": "ğŸ”„",
                "color": "#FF9500",
                "badge": "ACTIVE",
                "subtitle": f"{DataManagerConfig.DEFAULT_DEMO_TRADES_COUNT}ê±´ ê±°ë˜ ë°ì´í„° â€¢ ì¶”ê²©ë§¤ìˆ˜ íŒ¨í„´ ë¶„ì„ í•„ìš”",
                "onboarding_type": "trade_selection",
                "demo_trades_count": DataManagerConfig.DEFAULT_DEMO_TRADES_COUNT
            },
            "ê¹€êµ­ë¯¼": {
                "username": "ê¹€êµ­ë¯¼",
                "user_type": "ê¸°ì¡´_reflexì‚¬ìš©ì¤‘",
                "description": "ê³µí¬ ë§¤ë„ ê²½í–¥, Reflex ê¸°ì¡´ ì‚¬ìš©ì",
                "icon": "â­",
                "color": "#14AE5C",
                "badge": "PRO",
                "subtitle": f"{DataManagerConfig.DEFAULT_DEMO_TRADES_COUNT}ê±´ ê±°ë˜ ë°ì´í„° â€¢ ë³µê¸° ë…¸íŠ¸ ë³´ìœ ",
                "onboarding_type": None,
                "demo_trades_count": DataManagerConfig.DEFAULT_DEMO_TRADES_COUNT
            }
        }
    
    @monitor_performance
    def _load_market_data_optimized(self) -> Dict[str, MarketData]:
        """ìµœì í™”ëœ ì‹œì¥ ë°ì´í„° ë¡œë“œ"""
        cache_key = "market_data"
        
        # ìºì‹œ í™•ì¸
        if self.cache:
            cached_data = self.cache.get(cache_key)
            if cached_data:
                return cached_data
        
        # ê¸°ë³¸ ì¢…ëª© ì •ë³´ (ì¶•ì†Œ ë° ìµœì í™”)
        default_stocks = self._get_default_stock_data()
        
        market_file = self.data_dir / "market_data.json"
        base_data = self._safe_json_load(market_file, default_stocks)
        
        # íŒŒì¼ì´ ì—†ìœ¼ë©´ ìƒì„±
        if not market_file.exists():
            self._safe_json_save(market_file, default_stocks)
        
        # ì‹¤ì‹œê°„ ê°€ê²© ì‹œë®¬ë ˆì´ì…˜ (ìµœì í™”)
        market_data = {}
        for symbol, info in base_data.items():
            current_price = self.provider.get_stock_price(symbol, info["base_price"])
            change = current_price - info["base_price"]
            change_pct = (change / info["base_price"]) * 100
            
            # ì„±ëŠ¥ ëª¨ë“œì— ë”°ë¥¸ ì¶”ê°€ ë°ì´í„° ìƒì„±
            if PERFORMANCE_MODE == 'fast':
                # ìµœì†Œí•œì˜ ë°ì´í„°ë§Œ ìƒì„±
                volume = random.randint(800000, 1200000)
                ma5 = current_price * random.uniform(0.98, 1.02)
                ma20 = current_price * random.uniform(0.95, 1.05)
                rsi = random.randint(30, 70)
                per = random.uniform(12, 18)
                pbr = random.uniform(1.0, 1.8)
            else:
                # ì •í™•í•œ ë°ì´í„° ìƒì„±
                volume_base = 1000000
                volume_variance = 300000 if DEMO_SEED else 500000
                volume = random.randint(volume_base - volume_variance, volume_base + volume_variance)
                
                volatility = self.provider.volatility_factor if hasattr(self.provider, 'volatility_factor') else 1
                ma5 = current_price + random.gauss(0, info["base_price"] * 0.005 * volatility)
                ma20 = current_price + random.gauss(0, info["base_price"] * 0.01 * volatility)
                rsi = max(20, min(80, random.randint(25, 75)))
                per = random.uniform(8, 25)
                pbr = random.uniform(0.6, 2.5)
            
            market_data[info["name"]] = MarketData(
                symbol=symbol,
                name=info["name"],
                current_price=current_price,
                change=change,
                change_pct=change_pct,
                volume=volume,
                sector=info["sector"],
                market_cap=info["market_cap"],
                ma5=ma5,
                ma20=ma20,
                rsi=rsi,
                per=per,
                pbr=pbr,
                base_price=info["base_price"]
            )
        
        # ìºì‹œ ì €ì¥ (TTL ì§§ê²Œ ì„¤ì •)
        if self.cache:
            self.cache.put(cache_key, market_data, ttl_seconds=60)  # 1ë¶„
        
        return market_data
    
    def _get_default_stock_data(self) -> Dict[str, Dict]:
        """ê¸°ë³¸ ì¢…ëª© ë°ì´í„° (ìµœì í™”)"""
        # ì„±ëŠ¥ ëª¨ë“œì— ë”°ë¼ ì¢…ëª© ìˆ˜ ì¡°ì •
        if PERFORMANCE_MODE == 'fast':
            # ì£¼ìš” ì¢…ëª©ë§Œ
            return {
                "005930": {"name": "ì‚¼ì„±ì „ì", "base_price": 65000, "sector": "IT", "market_cap": "ëŒ€í˜•"},
                "000660": {"name": "SKí•˜ì´ë‹‰ìŠ¤", "base_price": 120000, "sector": "IT", "market_cap": "ëŒ€í˜•"},
                "035420": {"name": "NAVER", "base_price": 180000, "sector": "IT", "market_cap": "ëŒ€í˜•"},
                "005380": {"name": "í˜„ëŒ€ì°¨", "base_price": 180000, "sector": "ìë™ì°¨", "market_cap": "ëŒ€í˜•"},
                "068270": {"name": "ì…€íŠ¸ë¦¬ì˜¨", "base_price": 160000, "sector": "ë°”ì´ì˜¤", "market_cap": "ëŒ€í˜•"}
            }
        else:
            # ì „ì²´ ì¢…ëª©
            return {
                "005930": {"name": "ì‚¼ì„±ì „ì", "base_price": 65000, "sector": "IT", "market_cap": "ëŒ€í˜•"},
                "000660": {"name": "SKí•˜ì´ë‹‰ìŠ¤", "base_price": 120000, "sector": "IT", "market_cap": "ëŒ€í˜•"},
                "035420": {"name": "NAVER", "base_price": 180000, "sector": "IT", "market_cap": "ëŒ€í˜•"},
                "035720": {"name": "ì¹´ì¹´ì˜¤", "base_price": 45000, "sector": "IT", "market_cap": "ëŒ€í˜•"},
                "051910": {"name": "LGí™”í•™", "base_price": 380000, "sector": "í™”í•™", "market_cap": "ëŒ€í˜•"},
                "005380": {"name": "í˜„ëŒ€ì°¨", "base_price": 180000, "sector": "ìë™ì°¨", "market_cap": "ëŒ€í˜•"},
                "005490": {"name": "POSCOí™€ë”©ìŠ¤", "base_price": 350000, "sector": "ì² ê°•", "market_cap": "ëŒ€í˜•"},
                "015760": {"name": "í•œêµ­ì „ë ¥", "base_price": 22000, "sector": "ì „ë ¥", "market_cap": "ëŒ€í˜•"},
                "105560": {"name": "KBê¸ˆìœµ", "base_price": 48000, "sector": "ê¸ˆìœµ", "market_cap": "ëŒ€í˜•"},
                "066570": {"name": "LGì „ì", "base_price": 95000, "sector": "ì „ì", "market_cap": "ëŒ€í˜•"},
                "068270": {"name": "ì…€íŠ¸ë¦¬ì˜¨", "base_price": 160000, "sector": "ë°”ì´ì˜¤", "market_cap": "ëŒ€í˜•"},
                "017670": {"name": "SKí…”ë ˆì½¤", "base_price": 52000, "sector": "í†µì‹ ", "market_cap": "ëŒ€í˜•"}
            }
    
    @monitor_performance
    def _load_news_data_optimized(self) -> List[NewsItem]:
        """ìµœì í™”ëœ ë‰´ìŠ¤ ë°ì´í„° ë¡œë“œ"""
        cache_key = "news_data"
        
        # ìºì‹œ í™•ì¸
        if self.cache:
            cached_data = self.cache.get(cache_key)
            if cached_data:
                return cached_data[:DataManagerConfig.MAX_NEWS_ITEMS_MEMORY]  # ë©”ëª¨ë¦¬ ì œí•œ
        
        news_file = self.data_dir / "news_data.json"
        default_news = self._get_default_news_data()
        
        news_data_raw = self._safe_json_load(news_file, default_news)
        
        if not news_file.exists():
            self._safe_json_save(news_file, default_news)
        
        # NewsItem ê°ì²´ ë³€í™˜ (ìµœì í™”)
        news_data = []
        for item in news_data_raw[:DataManagerConfig.MAX_NEWS_ITEMS_MEMORY]:
            try:
                news_item = NewsItem(
                    title=item.get("title", "ì œëª© ì—†ìŒ"),
                    content=item.get("content", "ë‚´ìš© ì—†ìŒ"),
                    timestamp=self._parse_datetime(item.get("timestamp")),
                    category=item.get("category", "ì¼ë°˜"),
                    impact=item.get("impact", "neutral"),
                    related_stocks=item.get("related_stocks", []),
                    source=item.get("source", "ë‚´ë¶€"),
                    importance=item.get("importance", 0.5)
                )
                news_data.append(news_item)
            except Exception as e:
                self._status['warnings'].append(f"ë‰´ìŠ¤ ì•„ì´í…œ íŒŒì‹± ì‹¤íŒ¨: {item.get('title', 'ì œëª©ì—†ìŒ')}")
        
        # ìºì‹œ ì €ì¥
        if self.cache:
            self.cache.put(cache_key, news_data, ttl_seconds=1800)  # 30ë¶„
        
        return news_data
    
    def _parse_datetime(self, timestamp_str: str) -> datetime:
        """ë‚ ì§œ ë¬¸ìì—´ íŒŒì‹±"""
        if not timestamp_str:
            return datetime.now()
        
        try:
            if isinstance(timestamp_str, str):
                return datetime.fromisoformat(timestamp_str.replace('Z', '+00:00'))
            return timestamp_str
        except:
            return datetime.now()
    
    def _get_default_news_data(self) -> List[Dict]:
        """ê¸°ë³¸ ë‰´ìŠ¤ ë°ì´í„°"""
        base_news = [
            {
                "title": "ë°˜ë„ì²´ ìˆ˜ìš” ì¦ê°€ë¡œ ì‚¼ì„±ì „ì, SKí•˜ì´ë‹‰ìŠ¤ ì£¼ê°€ ìƒìŠ¹ ì „ë§",
                "content": "AI ë° ë°ì´í„°ì„¼í„° ìˆ˜ìš” ê¸‰ì¦ìœ¼ë¡œ ë©”ëª¨ë¦¬ ë°˜ë„ì²´ ì—…ê³„ì— í˜¸ì¬...",
                "timestamp": (datetime.now() - timedelta(hours=1)).isoformat(),
                "category": "IT",
                "impact": "positive",
                "related_stocks": ["ì‚¼ì„±ì „ì", "SKí•˜ì´ë‹‰ìŠ¤"],
                "importance": 0.8
            },
            {
                "title": "ì „ê¸°ì°¨ ì‹œì¥ ë‘”í™” ìš°ë ¤ë¡œ ìë™ì°¨ì£¼ ì•½ì„¸",
                "content": "ê¸€ë¡œë²Œ ì „ê¸°ì°¨ íŒë§¤ ì¦ê°€ìœ¨ ë‘”í™”ë¡œ ê´€ë ¨ ì—…ì²´ë“¤ ì£¼ê°€ í•˜ë½...",
                "timestamp": (datetime.now() - timedelta(hours=2)).isoformat(),
                "category": "ìë™ì°¨",
                "impact": "negative",
                "related_stocks": ["í˜„ëŒ€ì°¨"],
                "importance": 0.6
            },
            {
                "title": "ì½”ìŠ¤í”¼ 2450ì„  íšŒë³µ, ì™¸êµ­ì¸ ìˆœë§¤ìˆ˜ ì§€ì†",
                "content": "ì™¸êµ­ì¸ íˆ¬ììë“¤ì˜ ì§€ì†ì ì¸ ìˆœë§¤ìˆ˜ë¡œ ì½”ìŠ¤í”¼ ì§€ìˆ˜ê°€ ìƒìŠ¹ì„¸...",
                "timestamp": (datetime.now() - timedelta(hours=3)).isoformat(),
                "category": "ì‹œì¥",
                "impact": "positive",
                "related_stocks": ["ì „ì²´"],
                "importance": 0.7
            }
        ]
        
        # ì„±ëŠ¥ ëª¨ë“œì— ë”°ë¼ ë‰´ìŠ¤ ê°œìˆ˜ ì¡°ì •
        if PERFORMANCE_MODE == 'fast':
            return base_news[:2]
        
        return base_news
    
    @monitor_performance
    def _load_economic_indicators_optimized(self) -> Dict[str, Any]:
        """ìµœì í™”ëœ ê²½ì œ ì§€í‘œ ë¡œë“œ"""
        cache_key = "economic_indicators"
        
        # ìºì‹œ í™•ì¸
        if self.cache:
            cached_data = self.cache.get(cache_key)
            if cached_data:
                return cached_data
        
        indicators_file = self.data_dir / "economic_indicators.json"
        default_indicators = self._get_default_economic_indicators()
        
        indicators = self._safe_json_load(indicators_file, default_indicators)
        
        if not indicators_file.exists():
            self._safe_json_save(indicators_file, default_indicators)
        
        # ìºì‹œ ì €ì¥
        if self.cache:
            self.cache.put(cache_key, indicators, ttl_seconds=300)  # 5ë¶„
        
        return indicators
    
    def _get_default_economic_indicators(self) -> Dict[str, Any]:
        """ê¸°ë³¸ ê²½ì œ ì§€í‘œ"""
        # ì‹¤ì‹œê°„ ë³€ë™ ì‹œë®¬ë ˆì´ì…˜ (ê°„ì†Œí™”)
        kospi_base = 2450
        kosdaq_base = 750
        usd_krw_base = 1340
        
        kospi_change = random.uniform(-1, 1)
        kosdaq_change = random.uniform(-1.5, 1.5)
        usd_change = random.uniform(-0.5, 0.5)
        
        return {
            "KOSPI": {
                "current": round(kospi_base + kospi_change, 2),
                "change": kospi_change,
                "change_pct": round((kospi_change / kospi_base) * 100, 2),
                "volume": random.randint(7000000, 10000000)
            },
            "KOSDAQ": {
                "current": round(kosdaq_base + kosdaq_change, 2),
                "change": kosdaq_change,
                "change_pct": round((kosdaq_change / kosdaq_base) * 100, 2),
                "volume": random.randint(4000000, 7000000)
            },
            "USD_KRW": {
                "current": round(usd_krw_base + usd_change, 1),
                "change": usd_change,
                "change_pct": round((usd_change / usd_krw_base) * 100, 2)
            },
            "interest_rate": 3.50,
            "inflation_rate": 2.4,
            "unemployment_rate": 2.8
        }
    
    @monitor_performance
    def _load_demo_trades_optimized(self) -> Dict[str, List[Dict]]:
        """ìµœì í™”ëœ ë°ëª¨ ê±°ë˜ ë¡œë“œ"""
        cache_key = "demo_trades"
        
        # ìºì‹œ í™•ì¸
        if self.cache:
            cached_data = self.cache.get(cache_key)
            if cached_data:
                return cached_data
        
        trades_file = self.data_dir / "demo_trades.json"
        trades_data = self._safe_json_load(trades_file, {})
        
        # ê±°ë˜ ë°ì´í„° ìƒì„± (í•„ìš”ì‹œì—ë§Œ)
        if not trades_data:
            for username, user in self.users.items():
                if user.demo_trades_count > 0:
                    # ê±°ë˜ ìˆ˜ ì œí•œ ì ìš©
                    limited_count = min(user.demo_trades_count, DataManagerConfig.MAX_TRADES_PER_USER)
                    trades_data[username] = self._generate_optimized_demo_trades(username, limited_count)
                else:
                    trades_data[username] = []
            
            self._safe_json_save(trades_file, trades_data)
        
        # ë©”ëª¨ë¦¬ ìµœì í™”: ì‚¬ìš©ìë³„ ê±°ë˜ ìˆ˜ ì œí•œ
        for username in trades_data:
            if len(trades_data[username]) > DataManagerConfig.MAX_TRADES_PER_USER:
                trades_data[username] = trades_data[username][:DataManagerConfig.MAX_TRADES_PER_USER]
        
        # ìºì‹œ ì €ì¥
        if self.cache:
            self.cache.put(cache_key, trades_data, ttl_seconds=3600)  # 1ì‹œê°„
        
        return trades_data
    
    def _generate_optimized_demo_trades(self, username: str, count: int) -> List[Dict]:
        """ìµœì í™”ëœ ë°ëª¨ ê±°ë˜ ìƒì„±"""
        trades = []
        stock_names = list(self.market_data.keys()) if self.market_data else ["ì‚¼ì„±ì „ì", "SKí•˜ì´ë‹‰ìŠ¤"]
        
        # ì‚¬ìš©ìë³„ íŒ¨í„´ (ê°„ì†Œí™”)
        if username == "ë°•íˆ¬ì":
            emotions = ["#ìš•ì‹¬", "#í™•ì‹ ", "#í¥ë¶„"] * 2 + ["#ë¶ˆì•ˆ", "#í›„íšŒ"]
            success_rate = 0.42 if DEMO_SEED else 0.38
        elif username == "ê¹€êµ­ë¯¼":
            emotions = ["#ê³µí¬", "#ë¶ˆì•ˆ"] + ["#ëƒ‰ì •", "#í™•ì‹ "] * 2
            success_rate = 0.58 if DEMO_SEED else 0.55
        else:
            emotions = ["#ëƒ‰ì •", "#í™•ì‹ "] * 2 + ["#ë¶ˆì•ˆ", "#ìš•ì‹¬"]
            success_rate = 0.52 if DEMO_SEED else 0.50
        
        # ì œí•œëœ ìˆ˜ì˜ ê±°ë˜ë§Œ ìƒì„±
        actual_count = min(count, 50)  # ìµœëŒ€ 50ê°œ
        
        for i in range(actual_count):
            stock = random.choice(stock_names)
            stock_data = self.market_data.get(stock)
            base_price = stock_data.base_price if stock_data else 50000
            
            # ìˆ˜ìµë¥  ìƒì„± (ë²”ìœ„ ì œí•œ)
            if random.random() < success_rate:
                return_pct = random.uniform(1, 15)  # ìµœëŒ€ 15% ìˆ˜ìµ
            else:
                return_pct = random.uniform(-15, -1)  # ìµœëŒ€ 15% ì†ì‹¤
            
            trade_date = datetime.now() - timedelta(days=random.randint(1, 365))
            
            trades.append({
                "ê±°ë˜ì¼ì‹œ": trade_date.strftime("%Y-%m-%d"),
                "ì¢…ëª©ëª…": stock,
                "ê±°ë˜êµ¬ë¶„": random.choice(["ë§¤ìˆ˜", "ë§¤ë„"]),
                "ìˆ˜ëŸ‰": random.randint(10, 200),  # ìˆ˜ëŸ‰ ë²”ìœ„ ì¶•ì†Œ
                "ê°€ê²©": int(base_price * random.uniform(0.95, 1.05)),
                "ìˆ˜ìµë¥ ": round(return_pct, 2),
                "ê°ì •íƒœê·¸": random.choice(emotions),
                "ë©”ëª¨": f"{stock} {['ìƒìŠ¹', 'í•˜ë½'][return_pct < 0]} ì˜ˆìƒìœ¼ë¡œ ê±°ë˜"
            })
        
        return sorted(trades, key=lambda x: x["ê±°ë˜ì¼ì‹œ"], reverse=True)
    
    def _validate_all_data(self):
        """ì „ì²´ ë°ì´í„° ë¬´ê²°ì„± ê²€ì‚¬"""
        validation_score = 100.0
        issues = []
        
        # ì‚¬ìš©ì ë°ì´í„° ê²€ì¦
        for username, user in self.users.items():
            is_valid, errors = self.validator.validate_user_profile(user.to_dict())
            if not is_valid:
                validation_score -= 5
                issues.extend(errors)
        
        # ì‹œì¥ ë°ì´í„° ê²€ì¦
        for stock_name, market_data in self.market_data.items():
            is_valid, errors = self.validator.validate_market_data(market_data.to_dict())
            if not is_valid:
                validation_score -= 3
                issues.extend(errors)
        
        # ê±°ë˜ ë°ì´í„° ê²€ì¦
        for username, trades in self.demo_trades.items():
            for trade in trades[:10]:  # ìƒ˜í”Œë§Œ ê²€ì¦
                is_valid, errors = self.validator.validate_trade_data(trade)
                if not is_valid:
                    validation_score -= 1
                    issues.extend(errors)
        
        self._status['data_integrity_score'] = max(0, validation_score)
        if issues:
            self._status['warnings'].extend(issues[:10])  # ìµœëŒ€ 10ê°œë§Œ ì €ì¥
    
    # ================================
    # [SAFE FILE OPERATIONS] ì•ˆì „í•œ íŒŒì¼ ì‘ì—…
    # ================================
    
    def _safe_json_load(self, filepath: Path, default_data: Any = None) -> Any:
        """ì•ˆì „í•œ JSON ë¡œë“œ (í–¥ìƒëœ ë²„ì „)"""
        try:
            with open(filepath, 'r', encoding='utf-8') as f:
                data = json.load(f)
                
                # ë°ì´í„° ì••ì¶• í•´ì œ (í•„ìš”ì‹œ)
                if isinstance(data, dict) and data.get('_compressed'):
                    import base64
                    compressed_data = base64.b64decode(data['data'])
                    json_data = gzip.decompress(compressed_data).decode('utf-8')
                    return json.loads(json_data)
                
                return data
                
        except FileNotFoundError:
            logger.info(f"íŒŒì¼ì´ ì¡´ì¬í•˜ì§€ ì•ŠìŒ: {filepath.name}")
            return default_data if default_data is not None else {}
        except json.JSONDecodeError as e:
            # ì†ìƒëœ íŒŒì¼ ë°±ì—…
            if filepath.exists():
                self._backup_corrupted_file(filepath)
                self._status['repairs'].append(f"ì†ìƒëœ íŒŒì¼ ë°±ì—…: {filepath.name}")
            
            logger.error(f"JSON íŒŒì‹± ì‹¤íŒ¨: {filepath.name} - {e}")
            return default_data if default_data is not None else {}
        except Exception as e:
            logger.error(f"íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {filepath.name} - {e}")
            self._status['errors'].append(f"íŒŒì¼ ë¡œë“œ ì‹¤íŒ¨: {filepath.name}")
            return default_data if default_data is not None else {}
    
    def _safe_json_save(self, filepath: Path, data: Any, compress: bool = None) -> bool:
        """ì•ˆì „í•œ JSON ì €ì¥ (í–¥ìƒëœ ë²„ì „)"""
        try:
            # ì••ì¶• ì—¬ë¶€ ê²°ì •
            use_compression = (compress if compress is not None 
                             else DataManagerConfig.ENABLE_COMPRESSION)
            
            # ë°±ì—… ìƒì„± (ê¸°ì¡´ íŒŒì¼ì´ ìˆëŠ” ê²½ìš°)
            if filepath.exists() and DataManagerConfig.ENABLE_AUTO_BACKUP:
                self._create_backup(filepath)
            
            # ì„ì‹œ íŒŒì¼ì— ì €ì¥
            temp_path = filepath.with_suffix('.tmp')
            
            if use_compression and self._should_compress(data):
                # ë°ì´í„° ì••ì¶•
                json_data = json.dumps(data, ensure_ascii=False, default=str)
                compressed_data = gzip.compress(json_data.encode('utf-8'))
                import base64
                compressed_wrapper = {
                    '_compressed': True,
                    'data': base64.b64encode(compressed_data).decode('ascii'),
                    'original_size': len(json_data),
                    'compressed_size': len(compressed_data)
                }
                
                with open(temp_path, 'w', encoding='utf-8') as f:
                    json.dump(compressed_wrapper, f, ensure_ascii=False, indent=2)
            else:
                # ì¼ë°˜ ì €ì¥
                with open(temp_path, 'w', encoding='utf-8') as f:
                    json.dump(data, f, ensure_ascii=False, indent=2, default=str)
            
            # ì›ìì  ì´ë™
            temp_path.replace(filepath)
            return True
            
        except Exception as e:
            logger.error(f"íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {filepath.name} - {e}")
            self._status['errors'].append(f"íŒŒì¼ ì €ì¥ ì‹¤íŒ¨: {filepath.name}")
            # ì„ì‹œ íŒŒì¼ ì •ë¦¬
            if temp_path.exists():
                temp_path.unlink()
            return False
    
    def _should_compress(self, data: Any) -> bool:
        """ì••ì¶• í•„ìš” ì—¬ë¶€ íŒë‹¨"""
        try:
            json_str = json.dumps(data, default=str)
            return len(json_str) > 10240  # 10KB ì´ìƒì´ë©´ ì••ì¶•
        except:
            return False
    
    def _backup_corrupted_file(self, filepath: Path):
        """ì†ìƒëœ íŒŒì¼ ë°±ì—…"""
        try:
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_path = filepath.with_suffix(f'.corrupted-{timestamp}.json')
            shutil.copy2(filepath, backup_path)
        except Exception as e:
            logger.error(f"ì†ìƒ íŒŒì¼ ë°±ì—… ì‹¤íŒ¨: {e}")
    
    def _create_backup(self, filepath: Path):
        """íŒŒì¼ ë°±ì—… ìƒì„±"""
        try:
            if not DataManagerConfig.ENABLE_AUTO_BACKUP:
                return
                
            backup_dir = self.data_dir / "backups"
            backup_dir.mkdir(exist_ok=True)
            
            timestamp = datetime.now().strftime("%Y%m%d_%H%M%S")
            backup_filename = f"{filepath.stem}_{timestamp}{filepath.suffix}"
            backup_path = backup_dir / backup_filename
            
            shutil.copy2(filepath, backup_path)
            
            # ì˜¤ë˜ëœ ë°±ì—… ì •ë¦¬
            self._cleanup_old_backups(backup_dir, filepath.stem)
            
        except Exception as e:
            logger.error(f"ë°±ì—… ìƒì„± ì‹¤íŒ¨: {e}")
    
    def _cleanup_old_backups(self, backup_dir: Path, filename_prefix: str):
        """ì˜¤ë˜ëœ ë°±ì—… íŒŒì¼ ì •ë¦¬"""
        try:
            backup_files = list(backup_dir.glob(f"{filename_prefix}_*"))
            backup_files.sort(key=lambda x: x.stat().st_mtime, reverse=True)
            
            # ìµœëŒ€ ê°œìˆ˜ ì´ˆê³¼ ì‹œ ì˜¤ë˜ëœ íŒŒì¼ ì‚­ì œ
            if len(backup_files) > DataManagerConfig.MAX_BACKUP_FILES:
                for old_backup in backup_files[DataManagerConfig.MAX_BACKUP_FILES:]:
                    old_backup.unlink()
                    
        except Exception as e:
            logger.error(f"ë°±ì—… ì •ë¦¬ ì‹¤íŒ¨: {e}")
    
    # ================================
    # [PUBLIC API] ê³µê°œ API (ìµœì í™”)
    # ================================
    
    def status(self) -> Dict[str, Any]:
        """í–¥ìƒëœ ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ"""
        cache_stats = self.cache.get_stats() if self.cache else {}
        performance_stats = self.performance.get_metrics()
        
        return {
            'last_refresh': self._status['last_refresh'],
            'data_integrity_score': self._status['data_integrity_score'],
            'repairs': self._status['repairs'][-5:],  # ìµœê·¼ 5ê°œ
            'errors': self._status['errors'][-5:],    # ìµœê·¼ 5ê°œ
            'warnings': self._status['warnings'][-5:],  # ìµœê·¼ 5ê°œ
            'cache_stats': cache_stats,
            'performance_stats': performance_stats,
            'provider_mode': PROVIDER_MODE,
            'demo_seed': DEMO_SEED,
            'performance_mode': PERFORMANCE_MODE,
            'memory_optimization': DataManagerConfig.ENABLE_MEMORY_OPTIMIZATION,
            'data_counts': {
                'users': len(self.users),
                'stocks': len(self.market_data),
                'news_items': len(self.news_data),
                'total_trades': sum(len(trades) for trades in self.demo_trades.values())
            }
        }
    
    @monitor_performance
    def get_user(self, username: str) -> Optional[UserProfile]:
        """ì‚¬ìš©ì ì •ë³´ ì¡°íšŒ (ìµœì í™”)"""
        return self.users.get(username)
    
    @monitor_performance
    def get_all_users(self, refresh: bool = False) -> List[UserProfile]:
        """ëª¨ë“  ì‚¬ìš©ì ì •ë³´ ì¡°íšŒ"""
        if refresh:
            self.users = self._load_users_optimized()
        return list(self.users.values())
    
    @monitor_performance
    def get_market_data(self, refresh: bool = False) -> Dict[str, MarketData]:
        """ì‹œì¥ ë°ì´í„° ì¡°íšŒ"""
        if refresh:
            if self.cache:
                self.cache.clear()  # ìºì‹œ ë¬´íš¨í™”
            self.market_data = self._load_market_data_optimized()
        return self.market_data
    
    def get_stock_data(self, stock_name: str, refresh: bool = False) -> Optional[MarketData]:
        """íŠ¹ì • ì¢…ëª© ë°ì´í„° ì¡°íšŒ"""
        if refresh:
            self.market_data = self._load_market_data_optimized()
        return self.market_data.get(stock_name)
    
    @monitor_performance
    def get_news(self, category: str = None, hours_back: int = 24, refresh: bool = False) -> List[NewsItem]:
        """ë‰´ìŠ¤ ë°ì´í„° ì¡°íšŒ (ìµœì í™”)"""
        if refresh:
            self.news_data = self._load_news_data_optimized()
        
        cutoff_time = datetime.now() - timedelta(hours=hours_back)
        
        # í•„í„°ë§ ìµœì í™”
        filtered_news = [
            news for news in self.news_data 
            if news.timestamp >= cutoff_time and 
               (category is None or news.category == category)
        ]
        
        return sorted(filtered_news, key=lambda x: x.timestamp, reverse=True)
    
    def get_economic_indicators(self, refresh: bool = False) -> Dict[str, Any]:
        """ê²½ì œ ì§€í‘œ ì¡°íšŒ"""
        if refresh:
            if self.cache:
                cache_key = "economic_indicators"
                if cache_key in self.cache._cache:
                    del self.cache._cache[cache_key]
            self.economic_indicators = self._load_economic_indicators_optimized()
        return self.economic_indicators
    
    @monitor_performance
    def get_user_trades(self, username: str, refresh: bool = False) -> List[Dict]:
        """ì‚¬ìš©ì ê±°ë˜ ë‚´ì—­ ì¡°íšŒ"""
        if refresh:
            self.demo_trades = self._load_demo_trades_optimized()
        return self.demo_trades.get(username, [])
    
    @monitor_performance
    def update_user_trade(self, username: str, trade_data: Dict) -> bool:
        """ì‚¬ìš©ì ê±°ë˜ ì¶”ê°€ (í–¥ìƒëœ ë²„ì „)"""
        try:
            # ë°ì´í„° ê²€ì¦
            is_valid, errors = self.validator.validate_trade_data(trade_data)
            if not is_valid:
                logger.error(f"ê±°ë˜ ë°ì´í„° ê²€ì¦ ì‹¤íŒ¨: {errors}")
                return False
            
            # ì‚¬ìš©ì ì¡´ì¬ í™•ì¸
            if username not in self.users:
                logger.error(f"ì¡´ì¬í•˜ì§€ ì•ŠëŠ” ì‚¬ìš©ì: {username}")
                return False
            
            # ê±°ë˜ ëª©ë¡ ì´ˆê¸°í™”
            if username not in self.demo_trades:
                self.demo_trades[username] = []
            
            # ê±°ë˜ ìˆ˜ ì œí•œ í™•ì¸
            if len(self.demo_trades[username]) >= DataManagerConfig.MAX_TRADES_PER_USER:
                # ê°€ì¥ ì˜¤ë˜ëœ ê±°ë˜ ì œê±°
                self.demo_trades[username].pop(0)
            
            # ê±°ë˜ ì¶”ê°€
            self.demo_trades[username].append(trade_data)
            
            # íŒŒì¼ ì €ì¥
            trades_file = self.data_dir / "demo_trades.json"
            if self._safe_json_save(trades_file, self.demo_trades):
                # ìºì‹œ ë¬´íš¨í™”
                if self.cache:
                    cache_key = "demo_trades"
                    if cache_key in self.cache._cache:
                        del self.cache._cache[cache_key]
                return True
            else:
                # ì €ì¥ ì‹¤íŒ¨ ì‹œ ë©”ëª¨ë¦¬ì—ì„œë„ ì œê±°
                self.demo_trades[username].pop()
                return False
                
        except Exception as e:
            logger.error(f"ê±°ë˜ ì¶”ê°€ ì‹¤íŒ¨: {username} - {e}")
            self._status['errors'].append(f"ê±°ë˜ ì¶”ê°€ ì‹¤íŒ¨: {username}")
            return False
    
    # ================================
    # [CACHE MANAGEMENT] ìºì‹œ ê´€ë¦¬
    # ================================
    
    def refresh_market_data(self):
        """ì‹œì¥ ë°ì´í„° ê°•ì œ ê°±ì‹ """
        if self.cache:
            self.cache.clear()
        self.market_data = self._load_market_data_optimized()
    
    def refresh_all_data(self):
        """ëª¨ë“  ë°ì´í„° ê°•ì œ ê°±ì‹ """
        if self.cache:
            self.cache.clear()
        self._initialize_data()
    
    def clear_cache(self):
        """ìºì‹œ ì „ì²´ í´ë¦¬ì–´"""
        if self.cache:
            self.cache.clear()
        logger.info("ëª¨ë“  ìºì‹œê°€ í´ë¦¬ì–´ë˜ì—ˆìŠµë‹ˆë‹¤")
    
    def optimize_memory(self):
        """ë©”ëª¨ë¦¬ ìµœì í™”"""
        if not DataManagerConfig.ENABLE_MEMORY_OPTIMIZATION:
            return
        
        try:
            # ìºì‹œ ì •ë¦¬
            if self.cache:
                self.cache.cleanup_expired()
            
            # ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì •ë¦¬
            self.performance.clear_metrics()
            
            # ì˜¤ë˜ëœ ë¡œê·¸ ì •ë¦¬
            for log_list in [self._status['repairs'], self._status['errors'], self._status['warnings']]:
                if len(log_list) > 50:
                    log_list[:] = log_list[-25:]  # ìµœê·¼ 25ê°œë§Œ ìœ ì§€
            
            logger.info("ë©”ëª¨ë¦¬ ìµœì í™” ì™„ë£Œ")
            
        except Exception as e:
            logger.error(f"ë©”ëª¨ë¦¬ ìµœì í™” ì‹¤íŒ¨: {e}")

# ================================
# [GLOBAL SINGLETON] ì „ì—­ ì‹±ê¸€í†¤ (Streamlit ìºì‹œ)
# ================================

@st.cache_resource
def get_data_manager() -> EnhancedCentralDataManager:
    """í–¥ìƒëœ ë°ì´í„° ë§¤ë‹ˆì € ì‹±ê¸€í†¤ ì¸ìŠ¤í„´ìŠ¤ ë°˜í™˜"""
    logger.info("ğŸš€ [Cache Miss] Enhanced CentralDataManager ì¸ìŠ¤í„´ìŠ¤ë¥¼ ìƒˆë¡œ ìƒì„±í•©ë‹ˆë‹¤.")
    return EnhancedCentralDataManager()

# ================================
# [CONVENIENCE FUNCTIONS] í¸ì˜ í•¨ìˆ˜ë“¤ (ìµœì í™”)
# ================================

def get_user_profile(username: str) -> Optional[UserProfile]:
    """ì‚¬ìš©ì í”„ë¡œí•„ ì¡°íšŒ"""
    return get_data_manager().get_user(username)

def get_market_data(refresh: bool = False) -> Dict[str, MarketData]:
    """ì‹œì¥ ë°ì´í„° ì¡°íšŒ"""
    return get_data_manager().get_market_data(refresh)

def get_stock_data(stock_name: str) -> Optional[MarketData]:
    """ì¢…ëª© ë°ì´í„° ì¡°íšŒ"""
    return get_data_manager().get_stock_data(stock_name)

def get_latest_news(category: str = None) -> List[NewsItem]:
    """ìµœì‹  ë‰´ìŠ¤ ì¡°íšŒ"""
    return get_data_manager().get_news(category, hours_back=24)

def get_economic_data() -> Dict[str, Any]:
    """ê²½ì œ ì§€í‘œ ì¡°íšŒ"""
    return get_data_manager().get_economic_indicators()

def get_user_trading_history(username: str) -> List[Dict]:
    """ì‚¬ìš©ì ê±°ë˜ ì´ë ¥ ì¡°íšŒ"""
    return get_data_manager().get_user_trades(username)

def add_user_trade(username: str, trade_data: Dict) -> bool:
    """ì‚¬ìš©ì ê±°ë˜ ì¶”ê°€"""
    return get_data_manager().update_user_trade(username, trade_data)

def get_system_status() -> Dict[str, Any]:
    """ì‹œìŠ¤í…œ ìƒíƒœ ì¡°íšŒ"""
    return get_data_manager().status()

def optimize_system_memory():
    """ì‹œìŠ¤í…œ ë©”ëª¨ë¦¬ ìµœì í™”"""
    get_data_manager().optimize_memory()

# ================================
# [PERFORMANCE UTILITIES] ì„±ëŠ¥ ìœ í‹¸ë¦¬í‹°
# ================================

def get_performance_metrics() -> Dict[str, Any]:
    """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì¡°íšŒ"""
    return _performance_monitor.get_metrics()

def clear_performance_metrics():
    """ì„±ëŠ¥ ë©”íŠ¸ë¦­ ì´ˆê¸°í™”"""
    _performance_monitor.clear_metrics()

# ================================
# [LEGACY COMPATIBILITY] í•˜ìœ„ í˜¸í™˜ì„±
# ================================

# ê¸°ì¡´ í´ë˜ìŠ¤ëª… ìœ ì§€ (í•˜ìœ„ í˜¸í™˜ì„±)
CentralDataManager = EnhancedCentralDataManager
FinanceAPIConnector = OptimizedDummyProvider  # ê¸°ì¡´ ë ˆê±°ì‹œ í´ë˜ìŠ¤

# ê¸°ì¡´ í•¨ìˆ˜ëª… ìœ ì§€
def get_central_data_manager():
    """ë ˆê±°ì‹œ í•¨ìˆ˜ëª… ì§€ì›"""
    return get_data_manager()